<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>个人博客</title>
  
  <subtitle>记录工作中的点点滴滴</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yongnights.github.io/"/>
  <updated>2020-04-28T03:40:35.565Z</updated>
  <id>https://yongnights.github.io/</id>
  
  <author>
    <name>永夜初晗凝碧天</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>为Elasticsearch启动https访问</title>
    <link href="https://yongnights.github.io/2020/04/28/%E4%B8%BAElasticsearch%E5%90%AF%E5%8A%A8https%E8%AE%BF%E9%97%AE%20/"/>
    <id>https://yongnights.github.io/2020/04/28/为Elasticsearch启动https访问 /</id>
    <published>2020-04-28T01:06:00.870Z</published>
    <updated>2020-04-28T03:40:35.565Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 28 2020 11:42:02 GMT+0800 (GMT+08:00) --><h1 id="导语"><a href="#导语" class="headerlink" title="导语"></a>导语</h1><p>介绍如何使我们的 Elasticsearch 启动 https 服务。这个在很多的场合是非常有用的。特别是在 Elastic SIEM 的安全领域，我们需要把 Elasticsearch 的访问变为https的访问，这样使得我们的数据更加安全可靠。</p><h1 id="安装Elastic-Stack"><a href="#安装Elastic-Stack" class="headerlink" title="安装Elastic Stack"></a>安装Elastic Stack</h1><p>安装Elasticsearch 及 Kibana。等我们安装好Elasticsearch和Kibana后，我们可以分别在 localhost:9200 及 localhost:5601 看到我们想要的输出</p><h1 id="为Elasticsearch启动安全"><a href="#为Elasticsearch启动安全" class="headerlink" title="为Elasticsearch启动安全"></a>为Elasticsearch启动安全</h1><p>设置 Elastic 账户安全”为我们的 Elasticsearch 设置安全。我们可以不创建新的用户，只使用默认的 super 用户 elastic。</p><h1 id="生产p12证书"><a href="#生产p12证书" class="headerlink" title="生产p12证书"></a>生产p12证书</h1><p>在 Elasticsearch 的安装目录下，使用如下的命令：</p><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch-certutil ca</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ pwd</span><br><span class="line">/Users/liuxg/elastic9/elasticsearch-7.6.0</span><br><span class="line">liuxg:elasticsearch-7.6.0 liuxg$ ./bin/elasticsearch-certutil ca</span><br><span class="line">WARNING: An illegal reflective access operation has occurred</span><br><span class="line">WARNING: Illegal reflective access by org.bouncycastle.jcajce.provider.drbg.DRBG (file:/Users/liuxg/elastic9/elasticsearch-7.6.0/lib/tools/security-cli/bcprov-jdk15on-1.61.jar) to constructor sun.security.provider.Sun()</span><br><span class="line">WARNING: Please consider reporting this to the maintainers of org.bouncycastle.jcajce.provider.drbg.DRBG</span><br><span class="line">WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations</span><br><span class="line">WARNING: All illegal access operations will be denied in a future release</span><br><span class="line">This tool assists you in the generation of X.509 certificates and certificate</span><br><span class="line">signing requests for use with SSL/TLS in the Elastic stack.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">The &apos;ca&apos; mode generates a new &apos;certificate authority&apos;</span><br><span class="line">This will create a new X.509 certificate and private key that can be used</span><br><span class="line">to sign certificate when running in &apos;cert&apos; mode.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Use the &apos;ca-dn&apos; option if you wish to configure the &apos;distinguished name&apos;</span><br><span class="line">of the certificate authority</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">By default the &apos;ca&apos; mode produces a single PKCS#12 output file which holds:</span><br><span class="line">    * The CA certificate</span><br><span class="line">    * The CA&apos;s private key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">If you elect to generate PEM format certificates (the -pem option), then the output will</span><br><span class="line">be a zip file containing individual files for the CA certificate and private key</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please enter the desired output file [elastic-stack-ca.p12]: </span><br><span class="line">Enter password for elastic-stack-ca.p12 :</span><br></pre></td></tr></table></figure><p>在上面我们接受缺省的文件名，并输入一个自己熟悉的密码（针对我的情况，我接受空）。我们在 Elasticsearch 的安装目录下，我们可以看见一个生产的证书文件：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ls</span><br><span class="line">LICENSE.txt          config               lib</span><br><span class="line">NOTICE.txt           data                 logs</span><br><span class="line">README.asciidoc      elastic-stack-ca.p12 modules</span><br><span class="line">bin                  jdk.app              plugins</span><br></pre></td></tr></table></figure><p></p><p>我们接着运行如下的命令来生成一个证书：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12</span><br></pre></td></tr></table></figure><p></p><p>上面的命令将使用我们的 CA 来生成一个证书 elastic-certificates.p12:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ pwd</span><br><span class="line">/Users/liuxg/elastic9/elasticsearch-7.6.0</span><br><span class="line">liuxg:elasticsearch-7.6.0 liuxg$ ls</span><br><span class="line">LICENSE.txt              data                     logs</span><br><span class="line">NOTICE.txt               elastic-certificates.p12 modules</span><br><span class="line">README.asciidoc          elastic-stack-ca.p12     plugins</span><br><span class="line">bin                      jdk.app</span><br><span class="line">config                   lib</span><br></pre></td></tr></table></figure><p></p><p>我们把上面的 elastic-certificates.p12 证书拷入到 Elasticsearch 安装目录下的 config 子目录。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ pwd</span><br><span class="line">/Users/liuxg/elastic9/elasticsearch-7.6.0</span><br><span class="line">liuxg:elasticsearch-7.6.0 liuxg$ ls config/</span><br><span class="line">elastic-certificates.p12 jvm.options              roles.yml</span><br><span class="line">elasticsearch.keystore   log4j2.properties        users</span><br><span class="line">elasticsearch.yml        role_mapping.yml         users_roles</span><br></pre></td></tr></table></figure><p></p><p>我们使用如下的命令：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -in elastic-stack-ca.p12 -out newfile.crt.pem -clcerts -nokeys</span><br></pre></td></tr></table></figure><p></p><p>它将生成一个叫做 newfile.crt.pem 的文件。我们把这个文件拷入到 Kibana 安装目录下的 config 子目录中：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ pwd</span><br><span class="line">/Users/liuxg/elastic9/kibana-7.6.0-darwin-x86_64</span><br><span class="line">liuxg:kibana-7.6.0-darwin-x86_64 liuxg$ ls config/</span><br><span class="line">apm.js                   kibana.yml</span><br><span class="line">elastic-certificates.p12 newfile.crt.pem</span><br></pre></td></tr></table></figure><p></p><h1 id="配置Elasticsearch"><a href="#配置Elasticsearch" class="headerlink" title="配置Elasticsearch"></a>配置Elasticsearch</h1><p>接下来配置在 Elasticsearch 中的config/elasticsearch.yml。我们参照 Elastic 官方文档“Encrypting communication in Elasticsearch”，我们添加如下的配置：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line">xpack.security.http.ssl.enabled: true</span><br><span class="line">xpack.security.authc.api_key.enabled: true</span><br><span class="line">xpack.security.http.ssl.keystore.path: /Users/liuxg/elastic9/elasticsearch-7.6.0/config/elastic-certificates.p12</span><br><span class="line">xpack.security.http.ssl.truststore.path: /Users/liuxg/elastic9/elasticsearch-7.6.0/config/elastic-certificates.p12</span><br></pre></td></tr></table></figure><p></p><p>重新启动 Elasticsearch：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch</span><br></pre></td></tr></table></figure><p></p><p>这样我们的 Elasticsearch 已经成功地运行于 https 模式。我们在 chrome 中打入地址 <a href="https://localhost:9200,输入之前在创建安全账号时的用户名" target="_blank" rel="noopener">https://localhost:9200,输入之前在创建安全账号时的用户名</a> elastic及密码，那么我们就可以访问 Elasticsearch：</p><p>如果我们使用 Postman，我们可以通过在 “Settings” 里做如下的配置来避免证书的检查：<br>“File”,”Settings”,”SSL certificate verification”,关掉上面的 SSL certificate verification 开关<br>经过上面的设置后，我们可以在 Postman 中访问具有 https 的Elasticsearch。</p><h1 id="配置Kibana"><a href="#配置Kibana" class="headerlink" title="配置Kibana"></a>配置Kibana</h1><p>为了能够使我们的 Kibana 能够顺利地访问带有 https 的Elasticsearch。我们也需要做相应的配置。我们打开 config/kibana.yml。添加如下的设置：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">elasticsearch.hosts: [&quot;https://localhost:9200&quot;]</span><br><span class="line">elasticsearch.ssl.certificateAuthorities: [&quot;/Users/liuxg/elastic9/kibana-7.6.0-darwin-x86_64/config/newfile.crt.pem&quot;]</span><br><span class="line">elasticsearch.ssl.verificationMode: none</span><br></pre></td></tr></table></figure><p></p><p>在上面我们把之前生成的newfile.crt.pem的证书填入到上面的路径中，同时为了我们能够方便地访问，我们针对kibana不启用verificationMode。</p><p>等我们配置完后，我们重新启动 kibana,输入 elastic 用户的密码，我们就可以进入到 Kibana 的界面中</p><h1 id="把Beats数据传入到https的Elasticsearch中"><a href="#把Beats数据传入到https的Elasticsearch中" class="headerlink" title="把Beats数据传入到https的Elasticsearch中"></a>把Beats数据传入到https的Elasticsearch中</h1><p>在导入数据时，我们必须把证书配置到 beats 的配置文件中。我们就以 filebeat 为例。我们在Elasticsearch 的安装目录中，打入如下的命令：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch-certutil cert --pem elastic-stack-ca.p12</span><br></pre></td></tr></table></figure><p></p><p>上面的命令将会生成一个叫做“certificate-bundle.zip”的文件。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ pwd</span><br><span class="line">/Users/liuxg/elastic9/elasticsearch-7.6.0</span><br><span class="line">liuxg:elasticsearch-7.6.0 liuxg$ ls</span><br><span class="line">LICENSE.txt            certificate-bundle.zip lib</span><br><span class="line">NOTICE.txt             config                 logs</span><br><span class="line">README.asciidoc        data                   modules</span><br><span class="line">bin                    jdk.app                plugins</span><br></pre></td></tr></table></figure><p></p><p>我们可以把这个文件的一个进行解压，并把里面的 ca.crt 解压到 filebeat 的安装子目录中。</p><h2 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h2><p>打开 filebeat 的配置文件 filebeat.yml，并添加证书信息：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># filebeat.yml</span><br><span class="line"></span><br><span class="line">output.elasticsearch:</span><br><span class="line">  # Array of hosts to connect to.</span><br><span class="line">  hosts: [&quot;localhost:9200&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  # Protocol - either `http` (default) or `https`.</span><br><span class="line">  protocol: &quot;https&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  # Authentication credentials - either API key or username/password.</span><br><span class="line">  #api_key: &quot;id:api_key&quot;</span><br><span class="line">  username: &quot;elastic&quot;</span><br><span class="line">  password: &quot;123456&quot;</span><br><span class="line">  ssl.certificate_authorities: [&quot;/Users/liuxg/elastic9/filebeat-7.6.0-darwin-x86_64/ca.crt&quot;]</span><br><span class="line">  ssl.verification_mode: none</span><br></pre></td></tr></table></figure><p></p><p>在上面，你需要填入自己的 username 及 password，同时也需要把上面的路径换成自己的证书路径。</p><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>也可以用如下的命令来生产自己的证书。我们在 Elasticsearch 的安装目录下，在已经生成上面的 elastic-stack-ca.p12 前提下，运行如下的命令：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -in elastic-stack-ca.p12 -out newfile.crt.pem -clcerts -nokeys</span><br></pre></td></tr></table></figure><p></p><p>上面的命令将生成一个叫做 newfile.crt.pem 的文件。我们把这个文件拷贝到filebeat的安装目录下，并修改我们的 filebeat.yml 如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">output.elasticsearch:</span><br><span class="line">  # Array of hosts to connect to.</span><br><span class="line">  hosts: [&quot;localhost:9200&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  # Protocol - either `http` (default) or `https`.</span><br><span class="line">  protocol: &quot;https&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  # Authentication credentials - either API key or username/password.</span><br><span class="line">  #api_key: &quot;id:api_key&quot;</span><br><span class="line">  username: &quot;elastic&quot;</span><br><span class="line">  password: &quot;123456&quot;</span><br><span class="line">  ssl.certificate_authorities: [&quot;/Users/liuxg/elastic9/filebeat-7.6.0-darwin-x86_64/newfile.crt.pem&quot;]</span><br><span class="line">  ssl.verification_mode: none</span><br></pre></td></tr></table></figure><p></p><h1 id="运行Filebeat"><a href="#运行Filebeat" class="headerlink" title="运行Filebeat"></a>运行Filebeat</h1><p>修改完上面的配置后，我们启动 system 模块：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">./filebeat modules enable system</span><br><span class="line">./filebeat setup</span><br><span class="line">$ ./filebeat setup</span><br><span class="line">Overwriting ILM policy is disabled. Set `setup.ilm.overwrite:true` for enabling.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Index setup finished.</span><br><span class="line">Loading dashboards (Kibana must be running and reachable)</span><br><span class="line">Loaded dashboards</span><br><span class="line">Setting up ML using setup --machine-learning is going to be removed in 8.0.0. Please use the ML app instead.</span><br><span class="line">See more: https://www.elastic.co/guide/en/elastic-stack-overview/current/xpack-ml.html</span><br><span class="line">Loaded machine learning job configurations</span><br><span class="line">Loaded Ingest pipelines</span><br></pre></td></tr></table></figure><p></p><p>可以通过如下的命令来运行 filebeat:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./filebeat -e</span><br></pre></td></tr></table></figure><p></p><p>打开 Kibana,点击上面的[Filebeat System] Syslog dashboard ECS,可以看到 filebeat 的数据成功地传入到 Elasticsearch中了。</p><p>转载自：<a href="https://mp.weixin.qq.com/s/uy-LvGlttnNxXA2jNEuCwQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/uy-LvGlttnNxXA2jNEuCwQ</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 28 2020 11:42:02 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;导语&quot;&gt;&lt;a href=&quot;#导语&quot; class=&quot;headerlink&quot; title=&quot;导语&quot;&gt;&lt;/a&gt;导语&lt;/h1&gt;&lt;p&gt;介绍如何使我们的 Elasticsearch 启动 https 服务。这个在很多的场合是非常有用的。特别是在 Elastic SIEM 的安全领域，我们需要把 Elasticsearch 的访问变为https的访问，这样使得我们的数据更加安全可靠。&lt;/p&gt;&lt;h1 id=&quot;安装Elastic-Stack&quot;&gt;&lt;a href=&quot;#安装Elastic-Stack&quot; class=&quot;headerlink&quot; title=&quot;安装Elastic Stack&quot;&gt;&lt;/a&gt;安装Elastic Stack&lt;/h1&gt;&lt;p&gt;安装Elasticsearch 及 Kibana。等我们安装好Elasticsearch和Kibana后，我们可以分别在 localhost:9200 及 localhost:5601 看到我们想要的输出&lt;/p&gt;&lt;h1 id=&quot;为Elasticsearch启动安全&quot;&gt;&lt;a href=&quot;#为Elasticsearch启动安全&quot; class=&quot;headerlink&quot; title=&quot;为Elasticsearch启动安全&quot;&gt;&lt;/a&gt;为Elasticsearch启动安全&lt;/h1&gt;&lt;p&gt;设置 Elastic 账户安全”为我们的 Elasticsearch 设置安全。我们可以不创建新的用户，只使用默认的 super 用户 elastic。&lt;/p&gt;&lt;h1 id=&quot;生产p12证书&quot;&gt;&lt;a href=&quot;#生产p12证书&quot; class=&quot;headerlink&quot; title=&quot;生产p12证书&quot;&gt;&lt;/a&gt;生产p12证书&lt;/h1&gt;&lt;p&gt;在 Elasticsearch 的安装目录下，使用如下的命令：&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/categories/elk/Elasticsearch/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>FastAPI框架入门 基本使用, 模版渲染, form表单数据交互, 上传文件, 静态文件配置</title>
    <link href="https://yongnights.github.io/2020/04/26/FastAPI%E6%A1%86%E6%9E%B6%E5%85%A5%E9%97%A8%20%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8,%20%E6%A8%A1%E7%89%88%E6%B8%B2%E6%9F%93,%20form%E8%A1%A8%E5%8D%95%E6%95%B0%E6%8D%AE%E4%BA%A4%E4%BA%92,%20%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6,%20%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE/"/>
    <id>https://yongnights.github.io/2020/04/26/FastAPI框架入门 基本使用, 模版渲染, form表单数据交互, 上传文件, 静态文件配置/</id>
    <published>2020-04-26T09:53:10.697Z</published>
    <updated>2020-04-26T09:54:01.146Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Apr 26 2020 17:54:28 GMT+0800 (GMT+08:00) --><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install fastapi[all]</span><br><span class="line">pip install unicorn</span><br></pre></td></tr></table></figure><h1 id="基本使用-不能同时支持，get-post方法等要分开写"><a href="#基本使用-不能同时支持，get-post方法等要分开写" class="headerlink" title="基本使用(不能同时支持，get, post方法等要分开写)"></a>基本使用(不能同时支持，get, post方法等要分开写)</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line">@app.get(&apos;/&apos;)  # 点get就支持get请求</span><br><span class="line">def read_root():</span><br><span class="line">    return &#123;&quot;hello&quot;:&apos;world&apos;&#125;</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    import uvicorn</span><br><span class="line">    uvicorn.run(app,host=&apos;127.0.0.1&apos;,port=8080)</span><br></pre></td></tr></table></figure><a id="more"></a><h1 id="模版渲染"><a href="#模版渲染" class="headerlink" title="模版渲染"></a>模版渲染</h1><p>fastapi本身是没有模版渲染功能的，需要你借助于第三方的模版工具</p><p>该框架默认情况下也是借助于jinja2来做模版渲染(flask也是使用jinja2, 如果用过flask, 默认是装过jinja2)<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># 安装</span><br><span class="line">pip install jinja2</span><br><span class="line"></span><br><span class="line"># 基本使用</span><br><span class="line">from starlette.requests import Request</span><br><span class="line">from fastapi import FastAPI</span><br><span class="line">from starlette.templating import Jinja2Templates</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"># 挂载模版文件夹</span><br><span class="line">tmp = Jinja2Templates(directory=&apos;templates&apos;)</span><br><span class="line"></span><br><span class="line">@app.get(&apos;/&apos;)</span><br><span class="line">async def get_tmp(request:Request):  # async加了就支持异步  把Request赋值给request</span><br><span class="line">    return tmp.TemplateResponse(&apos;index.html&apos;,</span><br><span class="line">                                &#123;&apos;request&apos;:request,  # 一定要返回request</span><br><span class="line">                                 &apos;args&apos;:&apos;hello world&apos;  # 额外的参数可有可无</span><br><span class="line">                                 &#125;</span><br><span class="line">                                )</span><br><span class="line"></span><br><span class="line">@app.get(&apos;/&#123;item_id&#125;/&apos;)  # url后缀 </span><br><span class="line">async def get_item(request:Request,item_id):</span><br><span class="line">    return tmp.TemplateResponse(&apos;index.html&apos;,</span><br><span class="line">                                &#123;&apos;request&apos;:request,</span><br><span class="line">                                 &apos;kw&apos;:item_id</span><br><span class="line">                                 &#125;)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    import uvicorn</span><br><span class="line">    uvicorn.run(app,host=&apos;127.0.0.1&apos;,port=8080)</span><br><span class="line"></span><br><span class="line"># index.html文件内容</span><br><span class="line">&#123;#  index.html  #&#125;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;index页面&lt;/h1&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; args &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; kw &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;/body&gt;</span><br></pre></td></tr></table></figure><p></p><h1 id="form表单数据交互"><a href="#form表单数据交互" class="headerlink" title="form表单数据交互"></a>form表单数据交互</h1><p>注意： 如果要使用request.form（）支持表单“解析”，则为必需 python-multipart 。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"># 安装</span><br><span class="line">pip install python-multipart</span><br><span class="line"></span><br><span class="line">from starlette.requests import Request</span><br><span class="line">from fastapi import FastAPI,Form</span><br><span class="line">from starlette.templating import Jinja2Templates</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line">tmp = Jinja2Templates(directory=&apos;templates&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&apos;/&apos;)  # 接受get请求</span><br><span class="line">async def get_user(request:Request):</span><br><span class="line">    return tmp.TemplateResponse(&apos;form.html&apos;,&#123;&apos;request&apos;:request&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.post(&apos;/user/&apos;)  # 接受post请求</span><br><span class="line">async def get_user(request:Request,</span><br><span class="line">                   username:str=Form(...),  # 直接去请求体里面获取username键对应的值并自动转化成字符串类型</span><br><span class="line">                   pwd:int=Form(...)  # 直接去请求体里面获取pwd键对应的值并自动转化成整型</span><br><span class="line">                   ):</span><br><span class="line">    print(username,type(username))</span><br><span class="line">    print(pwd,type(pwd))</span><br><span class="line">    return tmp.TemplateResponse(&apos;form.html&apos;,&#123;</span><br><span class="line">        &apos;request&apos;:request,</span><br><span class="line">        &apos;username&apos;:username,</span><br><span class="line">        &apos;pwd&apos;:pwd</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    import uvicorn</span><br><span class="line">    uvicorn.run(app,host=&apos;127.0.0.1&apos;,port=8080)</span><br><span class="line"></span><br><span class="line"># form.html文件内容</span><br><span class="line">&#123;#  form.html  #&#125;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;form action=&quot;/user/&quot; method=&quot;post&quot;&gt;</span><br><span class="line">    &lt;p&gt;username&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;/p&gt;</span><br><span class="line">    &lt;p&gt;password&lt;input type=&quot;password&quot; name=&quot;pwd&quot;&gt;&lt;/p&gt;</span><br><span class="line">    &lt;input type=&quot;submit&quot;&gt;</span><br><span class="line">&lt;/form&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; username &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; pwd &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;/body&gt;</span><br></pre></td></tr></table></figure><p></p><h1 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">from starlette.requests import Request</span><br><span class="line">from fastapi import FastAPI, Form, File, UploadFile</span><br><span class="line">from starlette.templating import Jinja2Templates</span><br><span class="line">from typing import List</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"># 挂载模板文件夹</span><br><span class="line">tmp = Jinja2Templates(directory=&apos;templates&apos;)</span><br><span class="line"></span><br><span class="line">@app.get(&apos;/&apos;)  # 接受get请求</span><br><span class="line">async def get_file(request: Request):</span><br><span class="line">    return tmp.TemplateResponse(&apos;file.html&apos;, &#123;&apos;request&apos;: request&#125;)</span><br><span class="line"></span><br><span class="line"># 单个文件</span><br><span class="line">@app.post(&apos;/file/&apos;)  # 接受post请求</span><br><span class="line">async def get_user(request: Request,</span><br><span class="line">                   file: bytes = File(...),       # # 把文件对象转为bytes类型,这种类型的文件无法保存</span><br><span class="line">                   file_obj: UploadFile = File(...),    # UploadFile转为文件对象，可以保存文件到本地</span><br><span class="line">                   info: str = Form(...)    # 获取普通键值对</span><br><span class="line">                   ):</span><br><span class="line"></span><br><span class="line">    # 保存上传的文件</span><br><span class="line">    contents = await file_obj.read()</span><br><span class="line">    with open(&quot;static/file/&quot; + file_obj.filename, &quot;wb&quot;) as f:</span><br><span class="line">        f.write(contents)</span><br><span class="line"></span><br><span class="line">    return tmp.TemplateResponse(&apos;index.html&apos;, &#123;</span><br><span class="line">        &apos;request&apos;: request,</span><br><span class="line">        &apos;file_size&apos;: len(file),</span><br><span class="line">        &apos;file_name&apos;: file_obj.filename,</span><br><span class="line">        &apos;info&apos;:info,</span><br><span class="line">        &apos;file_content_type&apos;:file_obj.content_type</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"># 多个文件</span><br><span class="line">@app.post(&apos;/files/&apos;)</span><br><span class="line">async def get_files(request:Request,    </span><br><span class="line">                    files_list:List[bytes] = File(...),  # [文件1的二进制数据,文件2的二进制数据]</span><br><span class="line">                    files_obj_list:List[UploadFile]=File(...)  # [file_obj1,file_obj2,....] # 文件框里可以同时上传多个文件</span><br><span class="line">                    ):</span><br><span class="line"></span><br><span class="line">    # 保存上传的多个文件</span><br><span class="line">    for file in files_obj_list:</span><br><span class="line">        contents = await file.read()</span><br><span class="line">        filename = file.filename</span><br><span class="line">        with open(&quot;static/file/&quot; + filename, &quot;wb&quot;) as f:</span><br><span class="line">            f.write(contents)</span><br><span class="line"></span><br><span class="line">    return tmp.TemplateResponse(&apos;index.html&apos;,</span><br><span class="line">                                &#123;&apos;request&apos;:request,</span><br><span class="line">                                 &apos;file_sizes&apos;:[len(file) for file in files_list],</span><br><span class="line">                                 &apos;file_names&apos;:[file_obj.filename for file_obj in files_obj_list]</span><br><span class="line">                                 &#125;</span><br><span class="line">                                )</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    import uvicorn</span><br><span class="line"></span><br><span class="line">    uvicorn.run(app, host=&apos;127.0.0.1&apos;, port=8080)</span><br><span class="line"></span><br><span class="line"># html页面文件内容，有俩html文件</span><br><span class="line">&#123;#  file.html  #&#125;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;单个文件&lt;/h1&gt;</span><br><span class="line">&lt;form action=&quot;/file/&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;</span><br><span class="line">    &lt;input type=&quot;file&quot; name=&quot;file&quot;&gt;</span><br><span class="line">    &lt;input type=&quot;file&quot; name=&quot;file_obj&quot;&gt;</span><br><span class="line">    &lt;input type=&quot;text&quot; name=&quot;info&quot;&gt;</span><br><span class="line">    &lt;input type=&quot;submit&quot;&gt;</span><br><span class="line">&lt;/form&gt;</span><br><span class="line"></span><br><span class="line">&lt;h1&gt;多份个文件&lt;/h1&gt;</span><br><span class="line">&lt;form action=&quot;/files/&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;</span><br><span class="line">    &lt;input type=&quot;file&quot; name=&quot;files_list&quot; multiple&gt;   &#123;# multiple参数支持一次性传多个文件 #&#125;</span><br><span class="line">    &lt;input type=&quot;file&quot; name=&quot;files_obj_list&quot; multiple&gt;</span><br><span class="line">    &lt;input type=&quot;submit&quot;&gt;</span><br><span class="line">&lt;/form&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line"></span><br><span class="line">&#123;#  index.html  #&#125;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h2&gt;单个文件&lt;/h2&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; file_size &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; file_name &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; info &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; file_content_type &#125;&#125;&lt;/h1&gt;</span><br><span class="line"></span><br><span class="line">&lt;h2&gt;多个文件&lt;/h2&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; file_sizes &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;h1&gt;&#123;&#123; file_names &#125;&#125;&lt;/h1&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><h1 id="静态文件配置"><a href="#静态文件配置" class="headerlink" title="静态文件配置"></a>静态文件配置</h1><p>需要安装aiofiles模块<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 安装</span><br><span class="line">pip install aiofiles</span><br><span class="line"></span><br><span class="line">from starlette.staticfiles import StaticFiles</span><br><span class="line"># 挂载静态文件夹</span><br><span class="line">app.mount(&apos;/static&apos;,StaticFiles(directory=&apos;static&apos;),name=&apos;static&apos;)    # mount挂载 第一个参数为应用的前缀，第二个为路径，第三个为别名</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 前端</span><br><span class="line">&lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;&#123; url_for(&apos;static&apos;,path=&apos;/css/111.css&apos;) &#125;&#125;&quot;&gt;    &#123;# url_for后的第一个参数为别名 #&#125;</span><br><span class="line">&lt;script src=&quot;&#123;&#123; url_for(&apos;static&apos;,path=&apos;/js/111.js&apos;) &#125;&#125;&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure><p></p><p>示例文件下载：<a href="https://files.cnblogs.com/files/sanduzxcvbnm/project_statis_html_2.7z" target="_blank" rel="noopener">https://files.cnblogs.com/files/sanduzxcvbnm/project_statis_html_2.7z</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Sun Apr 26 2020 17:54:28 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip install fastapi[all]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install unicorn&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h1 id=&quot;基本使用-不能同时支持，get-post方法等要分开写&quot;&gt;&lt;a href=&quot;#基本使用-不能同时支持，get-post方法等要分开写&quot; class=&quot;headerlink&quot; title=&quot;基本使用(不能同时支持，get, post方法等要分开写)&quot;&gt;&lt;/a&gt;基本使用(不能同时支持，get, post方法等要分开写)&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;from fastapi import FastAPI&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;app = FastAPI()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;@app.get(&amp;apos;/&amp;apos;)  # 点get就支持get请求&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;def read_root():&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return &amp;#123;&amp;quot;hello&amp;quot;:&amp;apos;world&amp;apos;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;if __name__ == &amp;apos;__main__&amp;apos;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    import uvicorn&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    uvicorn.run(app,host=&amp;apos;127.0.0.1&amp;apos;,port=8080)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Python" scheme="https://yongnights.github.io/categories/Python/"/>
    
      <category term="FastAPI" scheme="https://yongnights.github.io/categories/Python/FastAPI/"/>
    
    
      <category term="Python" scheme="https://yongnights.github.io/tags/Python/"/>
    
      <category term="FastAPI" scheme="https://yongnights.github.io/tags/FastAPI/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch：使用_update_by_query更新文档</title>
    <link href="https://yongnights.github.io/2020/04/17/Elasticsearch%EF%BC%9A%E4%BD%BF%E7%94%A8_update_by_query%E6%9B%B4%E6%96%B0%E6%96%87%E6%A1%A3/"/>
    <id>https://yongnights.github.io/2020/04/17/Elasticsearch：使用_update_by_query更新文档/</id>
    <published>2020-04-17T06:02:05.891Z</published>
    <updated>2020-04-17T06:12:21.711Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Apr 17 2020 14:15:41 GMT+0800 (GMT+08:00) --><p>在很多的情况下，我们我们想更新我们所有的文档：</p><ul><li>添加一个新的field或者是一个字段变成一个multi-field</li><li>用一个值更新所有的文档，或者更新复合查询条件的所有文档</li></ul><p>在今天的文章中，我们来讲一下_update_by_query的这几个用法。</p><h1 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h1><p>我们来创建一个叫做twitter的索引：</p><a id="more"></a><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">PUT twitter</span><br><span class="line">&#123;</span><br><span class="line">  "mappings": &#123;</span><br><span class="line">    "properties": &#123;</span><br><span class="line">      "DOB": &#123;</span><br><span class="line">        "type": "date"</span><br><span class="line">      &#125;,</span><br><span class="line">      "address": &#123;</span><br><span class="line">        "type": "keyword"</span><br><span class="line">      &#125;,</span><br><span class="line">      "city": &#123;</span><br><span class="line">        "type": "text"</span><br><span class="line">      &#125;,</span><br><span class="line">      "country": &#123;</span><br><span class="line">        "type": "keyword"</span><br><span class="line">      &#125;,</span><br><span class="line">      "uid": &#123;</span><br><span class="line">        "type": "long"</span><br><span class="line">      &#125;,</span><br><span class="line">      "user": &#123;</span><br><span class="line">        "type": "keyword"</span><br><span class="line">      &#125;,</span><br><span class="line">      "province": &#123;</span><br><span class="line">        "type": "keyword"</span><br><span class="line">      &#125;,</span><br><span class="line">      "message": &#123;</span><br><span class="line">        "type": "text"</span><br><span class="line">      &#125;,</span><br><span class="line">      "location": &#123;</span><br><span class="line">        "type": "geo_point"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们使用如下的bulk API来把数据导入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">POST _bulk</span><br><span class="line">&#123; "index" : &#123; "_index" : "twitter", "_id": 1&#125; &#125;</span><br><span class="line">&#123;"user":"张三","message":"今儿天气不错啊，出去转转去","uid":2,"city":"北京","province":"北京","country":"中国","address":"中国北京市海淀区","location":&#123;"lat":"39.970718","lon":"116.325747"&#125;, "DOB":"1980-12-01"&#125;</span><br><span class="line">&#123; "index" : &#123; "_index" : "twitter", "_id": 2 &#125;&#125;</span><br><span class="line">&#123;"user":"老刘","message":"出发，下一站云南！","uid":3,"city":"北京","province":"北京","country":"中国","address":"中国北京市东城区台基厂三条3号","location":&#123;"lat":"39.904313","lon":"116.412754"&#125;, "DOB":"1981-12-01"&#125;</span><br><span class="line">&#123; "index" : &#123; "_index" : "twitter", "_id": 3&#125; &#125;</span><br><span class="line">&#123;"user":"李四","message":"happy birthday!","uid":4,"city":"北京","province":"北京","country":"中国","address":"中国北京市东城区","location":&#123;"lat":"39.893801","lon":"116.408986"&#125;, "DOB":"1982-12-01"&#125;</span><br><span class="line">&#123; "index" : &#123; "_index" : "twitter", "_id": 4&#125; &#125;</span><br><span class="line">&#123;"user":"老贾","message":"123,gogogo","uid":5,"city":"北京","province":"北京","country":"中国","address":"中国北京市朝阳区建国门","location":&#123;"lat":"39.718256","lon":"116.367910"&#125;, "DOB":"1983-12-01"&#125;</span><br><span class="line">&#123; "index" : &#123; "_index" : "twitter", "_id": 5&#125; &#125;</span><br><span class="line">&#123;"user":"老王","message":"Happy BirthDay My Friend!","uid":6,"city":"北京","province":"北京","country":"中国","address":"中国北京市朝阳区国贸","location":&#123;"lat":"39.918256","lon":"116.467910"&#125;, "DOB":"1984-12-01"&#125;</span><br><span class="line">&#123; "index" : &#123; "_index" : "twitter", "_id": 6&#125; &#125;</span><br><span class="line">&#123;"user":"老吴","message":"好友来了都今天我生日，好友来了,什么 birthday happy 就成!","uid":7,"city":"上海","province":"上海","country":"中国","address":"中国上海市闵行区","location":&#123;"lat":"31.175927","lon":"121.383328"&#125;, "DOB":"1985-12-01"&#125;</span><br></pre></td></tr></table></figure><h2 id="把一个字段变为multi-field"><a href="#把一个字段变为multi-field" class="headerlink" title="把一个字段变为multi-field"></a>把一个字段变为multi-field</h2><p>在上面，我们有意识地把city字段设置为text，但是在实际的应用中city一般来说是keyword类型。比如我们想对city这个字段来进行aggregation。那么我们该如何纠正这个错误呢？我们需要把我们之前的index删除，并使用新的mapping再次重建吗？这在我们的实际的是使用中可能并不现实。这是因为你的数据可能是非常大的，而且这种改动可能会造成很多的问题。那么我们该如何解决这个问题呢？</p><p>一种办法是在不删除之前索引的情况下，我们把city变成为一个mulit-field的字段，这样它既可以是一个keyword的类型，也可以同样是一个text类型的字段。为此，我们来修改twitter的mapping:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">PUT twitter/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  "properties": &#123;</span><br><span class="line">    "DOB": &#123;</span><br><span class="line">      "type": "date"</span><br><span class="line">    &#125;,</span><br><span class="line">    "address": &#123;</span><br><span class="line">      "type": "keyword"</span><br><span class="line">    &#125;,</span><br><span class="line">    "city": &#123;</span><br><span class="line">      "type": "text",</span><br><span class="line">      "fields": &#123;</span><br><span class="line">        "keyword": &#123;</span><br><span class="line">          "type": "keyword",</span><br><span class="line">          "ignore_above": 256</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    "country": &#123;</span><br><span class="line">      "type": "keyword"</span><br><span class="line">    &#125;,</span><br><span class="line">    "uid": &#123;</span><br><span class="line">      "type": "long"</span><br><span class="line">    &#125;,</span><br><span class="line">    "user": &#123;</span><br><span class="line">      "type": "keyword"</span><br><span class="line">    &#125;,</span><br><span class="line">    "province": &#123;</span><br><span class="line">      "type": "keyword"</span><br><span class="line">    &#125;,</span><br><span class="line">    "message": &#123;</span><br><span class="line">      "type": "text"</span><br><span class="line">    &#125;,</span><br><span class="line">    "location": &#123;</span><br><span class="line">      "type": "geo_point"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请注意在上面，我们把message的字段变为一个mult-field的字段。即便我们已经把mapping修改了，但是我们的索引并没有把我们的message字段进行分词。为了达到这个目的，我们可以进行如下的操作：</p><p><code>POST twitter/_update_by_query</code></p><p>经过上面的操作后，message字段将会被重新被索引，并可以被我们搜索。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "city.keyword": "北京"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面显示的结果为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">  "hits" : &#123;</span><br><span class="line">    "total" : &#123;</span><br><span class="line">      "value" : 5,</span><br><span class="line">      "relation" : "eq"</span><br><span class="line">    &#125;,</span><br><span class="line">    "max_score" : 0.21357408,</span><br><span class="line">    "hits" : [</span><br><span class="line">      &#123;</span><br><span class="line">        "_index" : "twitter",</span><br><span class="line">        "_type" : "_doc",</span><br><span class="line">        "_id" : "1",</span><br><span class="line">        "_score" : 0.21357408,</span><br><span class="line">        "_source" : &#123;</span><br><span class="line">          "user" : "张三",</span><br><span class="line">          "message" : "今儿天气不错啊，出去转转去",</span><br><span class="line">          "uid" : 2,</span><br><span class="line">          "city" : "北京",</span><br><span class="line">          "province" : "北京",</span><br><span class="line">          "country" : "中国",</span><br><span class="line">          "address" : "中国北京市海淀区",</span><br><span class="line">          "location" : &#123;</span><br><span class="line">            "lat" : "39.970718",</span><br><span class="line">            "lon" : "116.325747"</span><br><span class="line">          &#125;,</span><br><span class="line">          "DOB" : "1980-12-01"</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然由于这个字段变为multi-field的字段，它含有city.keyword，我们可以对它进行聚合搜索：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/_search</span><br><span class="line">&#123;</span><br><span class="line">  "size": 0,</span><br><span class="line">  "aggs": &#123;</span><br><span class="line">    "city_distribution": &#123;</span><br><span class="line">      "terms": &#123;</span><br><span class="line">        "field": "city.keyword",</span><br><span class="line">        "size": 5</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面我们对city进行统计，上面显示结果为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">"aggregations" : &#123;</span><br><span class="line">  "city_distribution" : &#123;</span><br><span class="line">    "doc_count_error_upper_bound" : 0,</span><br><span class="line">    "sum_other_doc_count" : 0,</span><br><span class="line">    "buckets" : [</span><br><span class="line">      &#123;</span><br><span class="line">        "key" : "北京",</span><br><span class="line">        "doc_count" : 5</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        "key" : "上海",</span><br><span class="line">        "doc_count" : 1</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果我们不修改city为multi-field，我们将不能对这个字段进行统计了。</p><h2 id="增加一个新的字段"><a href="#增加一个新的字段" class="headerlink" title="增加一个新的字段"></a>增加一个新的字段</h2><p>同样我们可以通过script的方法来为我们的twitter增加一个新的字段，比如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST twitter/_update_by_query</span><br><span class="line">&#123;</span><br><span class="line">  "script": &#123;</span><br><span class="line">    "source": "ctx._source['contact'] = \"139111111111\""</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上面的方法，我们把所有的文档都添加一个新的字段contact，并赋予它一个同样的值：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match_all": &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的命令显示结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">  "hits" : &#123;</span><br><span class="line">    "total" : &#123;</span><br><span class="line">      "value" : 6,</span><br><span class="line">      "relation" : "eq"</span><br><span class="line">    &#125;,</span><br><span class="line">    "max_score" : 1.0,</span><br><span class="line">    "hits" : [</span><br><span class="line">      &#123;</span><br><span class="line">        "_index" : "twitter",</span><br><span class="line">        "_type" : "_doc",</span><br><span class="line">        "_id" : "1",</span><br><span class="line">        "_score" : 1.0,</span><br><span class="line">        "_source" : &#123;</span><br><span class="line">          "uid" : 2,</span><br><span class="line">          "country" : "中国",</span><br><span class="line">          "address" : "中国北京市海淀区",</span><br><span class="line">          "province" : "北京",</span><br><span class="line">          "city" : "北京",</span><br><span class="line">          "DOB" : "1980-12-01",</span><br><span class="line">          "contact" : "139111111111",</span><br><span class="line">          "location" : &#123;</span><br><span class="line">            "lon" : "116.325747",</span><br><span class="line">            "lat" : "39.970718"</span><br><span class="line">          &#125;,</span><br><span class="line">          "message" : "今儿天气不错啊，出去转转去",</span><br><span class="line">          "user" : "张三"</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面我们可以看出来，有增加一个新的字段contact。</p><h2 id="修改已有的字段"><a href="#修改已有的字段" class="headerlink" title="修改已有的字段"></a>修改已有的字段</h2><p>假如我们想对所有在北京的文档里的uid都加1，那么我么有通过如下的方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">POST twitter/_update_by_query</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "city.keyword": "北京"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "script": &#123;</span><br><span class="line">    "source": "ctx._source['uid'] += params['one']",</span><br><span class="line">    "params": &#123;</span><br><span class="line">      "one": 1</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在执行上面的命令后，我们进行查询：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "city.keyword": "北京"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显示结果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">  "hits" : &#123;</span><br><span class="line">    "total" : &#123;</span><br><span class="line">      "value" : 5,</span><br><span class="line">      "relation" : "eq"</span><br><span class="line">    &#125;,</span><br><span class="line">    "max_score" : 0.24116206,</span><br><span class="line">    "hits" : [</span><br><span class="line">      &#123;</span><br><span class="line">        "_index" : "twitter",</span><br><span class="line">        "_type" : "_doc",</span><br><span class="line">        "_id" : "1",</span><br><span class="line">        "_score" : 0.24116206,</span><br><span class="line">        "_source" : &#123;</span><br><span class="line">          "uid" : 3,</span><br><span class="line">          "country" : "中国",</span><br><span class="line">          "address" : "中国北京市海淀区",</span><br><span class="line">          "province" : "北京",</span><br><span class="line">          "city" : "北京",</span><br><span class="line">          "DOB" : "1980-12-01",</span><br><span class="line">          "contact" : "139111111111",</span><br><span class="line">          "location" : &#123;</span><br><span class="line">            "lon" : "116.325747",</span><br><span class="line">            "lat" : "39.970718"</span><br><span class="line">          &#125;,</span><br><span class="line">          "message" : "今儿天气不错啊，出去转转去",</span><br><span class="line">          "user" : "张三"</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">   ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面显示city为北京的所有的文档的uid的数值都被加1了。上面_id为1的原来的uid值为2，现在变为3。</p><h2 id="没有动态mapping时，reindex索引"><a href="#没有动态mapping时，reindex索引" class="headerlink" title="没有动态mapping时，reindex索引"></a>没有动态mapping时，reindex索引</h2><p>假设您创建了一个没有动态mapping的索引，将其填充了数据，然后添加了一个mapping值以从数据中获取更多字段：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">PUT test</span><br><span class="line">&#123;</span><br><span class="line">  "mappings": &#123;</span><br><span class="line">    "dynamic": false,   </span><br><span class="line">    "properties": &#123;</span><br><span class="line">      "text": &#123;"type": "text"&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">POST test/_doc?refresh</span><br><span class="line">&#123;</span><br><span class="line">  "text": "words words",</span><br><span class="line">  "flag": "bar"</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">POST test/_doc?refresh</span><br><span class="line">&#123;</span><br><span class="line">  "text": "words words",</span><br><span class="line">  "flag": "foo"</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">PUT test/_mapping   </span><br><span class="line">&#123;</span><br><span class="line">  "properties": &#123;</span><br><span class="line">    "text": &#123;"type": "text"&#125;,</span><br><span class="line">    "flag": &#123;"type": "text", "analyzer": "keyword"&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面我们创建一个叫做test的索引。首先它的动态mapping被禁止了，也就是在索引时凡是不在mapping定义的字段将被自动识别，它们仅仅存在于source里，我们不能对它进行搜索。为了纠正这个错误，我们在上面的最后一步尝试来修改它的mapping来解决这个问题。那么在新的mapping下，我们之前导入的文档能进行搜索吗？我们尝试如下的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">POST test/_search?filter_path=hits.total</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "flag": "foo"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们尝试搜索所有flag中含有foo的文档，但是上面的返回结果是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  "hits" : &#123;</span><br><span class="line">    "total" : &#123;</span><br><span class="line">      "value" : 0,</span><br><span class="line">      "relation" : "eq"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么问题出现在哪里呢？其实在我们修改完mapping以后，我们没有更新我们之前已经导入的文档。我们需要使用_update_by_query来做类似reindex的工作。我们使用如下的命令：</p><p>POST test/_update_by_query?refresh&amp;conflicts=proceed</p><p>我们重新来搜索我们的文档：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">POST test/_search?filter_path=hits.total</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "flag": "foo"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的查询显示的结果是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  "hits" : &#123;</span><br><span class="line">    "total" : &#123;</span><br><span class="line">      "value" : 1,</span><br><span class="line">      "relation" : "eq"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显然，在运行完_update_by_query后，我们可以找到我们的文档了。</p><h2 id="针对大量数据的reindex"><a href="#针对大量数据的reindex" class="headerlink" title="针对大量数据的reindex"></a>针对大量数据的reindex</h2><p>上面所有的_update_by_query针对少量的数据还是很不错的。但是在我们的实际应用中，我们可能遇到很大的数据量，那么万一在reindex的过程中发生意外，那我们还需要从头开始吗？或者我们已经处理过的数据还需要再做一遍吗？一种通用的解决办法就是在我们的mapping中定义一个字段，比如叫做reindexBatch，那么我们可以通过添加这个字段来跟踪我们的进度：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">POST blogs_fixed/_update_by_query</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "range": &#123;</span><br><span class="line">      "flag": &#123;</span><br><span class="line">        "lt": 1</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "script": &#123;</span><br><span class="line">    "source": "ctx._source['flag']=1"</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>即使在reindex的过程已经失败了，我们再次运行上面的_update_by_query时，之前已经处理过的文件将不再被处理了。</p><p>_update_by_query 除了上面的用法之外，我们也可以结合pipepline来对我们的索引数据进行加工。详细的用法请参阅我之前的文章“运用Elastic Stack分析COVID-19数据并进行可视化分析”。</p><p>更多阅读<a href="https://elasticstack.blog.csdn.net/article/details/100531645" target="_blank" rel="noopener">Elasticsearch: Reindex接口</a>。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Fri Apr 17 2020 14:15:41 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在很多的情况下，我们我们想更新我们所有的文档：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;添加一个新的field或者是一个字段变成一个multi-field&lt;/li&gt;&lt;li&gt;用一个值更新所有的文档，或者更新复合查询条件的所有文档&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在今天的文章中，我们来讲一下_update_by_query的这几个用法。&lt;/p&gt;&lt;h1 id=&quot;准备数据&quot;&gt;&lt;a href=&quot;#准备数据&quot; class=&quot;headerlink&quot; title=&quot;准备数据&quot;&gt;&lt;/a&gt;准备数据&lt;/h1&gt;&lt;p&gt;我们来创建一个叫做twitter的索引：&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>Solutions：安全的APM服务器访问</title>
    <link href="https://yongnights.github.io/2020/04/15/Solutions%EF%BC%9A%E5%AE%89%E5%85%A8%E7%9A%84APM%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%BF%E9%97%AE/"/>
    <id>https://yongnights.github.io/2020/04/15/Solutions：安全的APM服务器访问/</id>
    <published>2020-04-15T09:47:59.064Z</published>
    <updated>2020-04-15T09:53:12.804Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 15 2020 17:54:01 GMT+0800 (GMT+08:00) --><p>转载自：<br><a href="https://blog.csdn.net/UbuntuTouch/article/details/105527468" target="_blank" rel="noopener">https://blog.csdn.net/UbuntuTouch/article/details/105527468</a></p><p>APM Agents 访问APM server如果不做安全的设置，那么任何一个应用都有可能把数据传输到APM server中。<br>如果是恶意的软件，那么我们可能得到的数据是错误的。那么怎么保证我们的安全传输呢？<br>答案是在传输的时候使用secret token。</p><p><img src="/elk/apm1.png" alt></p><h1 id="Secret-token-是什么？"><a href="#Secret-token-是什么？" class="headerlink" title="Secret token 是什么？"></a>Secret token 是什么？</h1><p>您可以配置一个Secret token来授权对APM服务器的请求。 这样可以确保只有您的Agent才能将数据发送到您的APM服务器。<br>代理和APM服务器都必须配置相同的Secret toke，并且scecret token仅在与SSL/TLS结合使用时才提供安全性。</p><p>要使用Secret token 保护APM代理与APM服务器之间的通信安全：</p><ul><li>在APM服务器中启用SSL/TLS</li><li>在Agent和服务器中设置Secret token</li><li>在APM agent中启用HTTPS</li></ul><a id="more"></a><p><img src="/elk/apm2.png" alt></p><h1 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h1><p>在Elasticsearch安装的根目录下打入如下的命令：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch-certutil ca --pem</span><br><span class="line"></span><br><span class="line">This tool assists you in the generation of X.509 certificates and certificate</span><br><span class="line">signing requests for use with SSL/TLS in the Elastic stack.</span><br><span class="line"> </span><br><span class="line">The &apos;ca&apos; mode generates a new &apos;certificate authority&apos;</span><br><span class="line">This will create a new X.509 certificate and private key that can be used</span><br><span class="line">to sign certificate when running in &apos;cert&apos; mode.</span><br><span class="line"> </span><br><span class="line">Use the &apos;ca-dn&apos; option if you wish to configure the &apos;distinguished name&apos;</span><br><span class="line">of the certificate authority</span><br><span class="line"> </span><br><span class="line">By default the &apos;ca&apos; mode produces a single PKCS#12 output file which holds:</span><br><span class="line">    * The CA certificate</span><br><span class="line">    * The CA&apos;s private key</span><br><span class="line"> </span><br><span class="line">If you elect to generate PEM format certificates (the -pem option), then the output will</span><br><span class="line">be a zip file containing individual files for the CA certificate and private key</span><br><span class="line"> </span><br><span class="line">Please enter the desired output file [elastic-stack-ca.zip]:</span><br></pre></td></tr></table></figure><p></p><p>上面的命令将会生成一个名字叫做elastic-stack-ca.zip的文件。我们接着使用如下的命令把上面的文件进行解压：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">unzip elastic-stack-ca.zip </span><br><span class="line">Archive:  elastic-stack-ca.zip</span><br><span class="line">   creating: ca/</span><br><span class="line">  inflating: ca/ca.crt               </span><br><span class="line">  inflating: ca/ca.key</span><br></pre></td></tr></table></figure><p></p><p>在当前的目录下生成了一个新的目录ca，里面含有两个文件：ca.crt及ca.key。请注意这里的ca.crt证书将在我们一下的agent里将会被用到。 接下来，我们按照如下的命令来生成证书：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch-certutil cert --ca-cert ./ca/ca.crt --ca-key ./ca/ca.key --pem --name localhost</span><br><span class="line">This tool assists you in the generation of X.509 certificates and certificate</span><br><span class="line">signing requests for use with SSL/TLS in the Elastic stack.</span><br><span class="line"> </span><br><span class="line">The &apos;cert&apos; mode generates X.509 certificate and private keys.</span><br><span class="line">    * By default, this generates a single certificate and key for use</span><br><span class="line">       on a single instance.</span><br><span class="line">    * The &apos;-multiple&apos; option will prompt you to enter details for multiple</span><br><span class="line">       instances and will generate a certificate and key for each one</span><br><span class="line">    * The &apos;-in&apos; option allows for the certificate generation to be automated by describing</span><br><span class="line">       the details of each instance in a YAML file</span><br><span class="line"> </span><br><span class="line">    * An instance is any piece of the Elastic Stack that requires an SSL certificate.</span><br><span class="line">      Depending on your configuration, Elasticsearch, Logstash, Kibana, and Beats</span><br><span class="line">      may all require a certificate and private key.</span><br><span class="line">    * The minimum required value for each instance is a name. This can simply be the</span><br><span class="line">      hostname, which will be used as the Common Name of the certificate. A full</span><br><span class="line">      distinguished name may also be used.</span><br><span class="line">    * A filename value may be required for each instance. This is necessary when the</span><br><span class="line">      name would result in an invalid file or directory name. The name provided here</span><br><span class="line">      is used as the directory name (within the zip) and the prefix for the key and</span><br><span class="line">      certificate files. The filename is required if you are prompted and the name</span><br><span class="line">      is not displayed in the prompt.</span><br><span class="line">    * IP addresses and DNS names are optional. Multiple values can be specified as a</span><br><span class="line">      comma separated string. If no IP addresses or DNS names are provided, you may</span><br><span class="line">      disable hostname verification in your SSL configuration.</span><br><span class="line"> </span><br><span class="line">    * All certificates generated by this tool will be signed by a certificate authority (CA).</span><br><span class="line">    * The tool can automatically generate a new CA for you, or you can provide your own with the</span><br><span class="line">         -ca or -ca-cert command line options.</span><br><span class="line"> </span><br><span class="line">By default the &apos;cert&apos; mode produces a single PKCS#12 output file which holds:</span><br><span class="line">    * The instance certificate</span><br><span class="line">    * The private key for the instance certificate</span><br><span class="line">    * The CA certificate</span><br><span class="line"> </span><br><span class="line">If you specify any of the following options:</span><br><span class="line">    * -pem (PEM formatted output)</span><br><span class="line">    * -keep-ca-key (retain generated CA key)</span><br><span class="line">    * -multiple (generate multiple certificates)</span><br><span class="line">    * -in (generate certificates from an input file)</span><br><span class="line">then the output will be be a zip file containing individual certificate/key files</span><br><span class="line"> </span><br><span class="line">Please enter the desired output file [certificate-bundle.zip]: </span><br><span class="line"> </span><br><span class="line">Certificates written to /Users/liuxg/elastic3/elasticsearch-7.6.2/certificate-bundle.zip</span><br><span class="line"> </span><br><span class="line">This file should be properly secured as it contains the private key for </span><br><span class="line">your instance.</span><br><span class="line"> </span><br><span class="line">After unzipping the file, there will be a directory for each instance.</span><br><span class="line">Each instance has a certificate and private key.</span><br><span class="line">For each Elastic product that you wish to configure, you should copy</span><br><span class="line">the certificate, key, and CA certificate to the relevant configuration directory</span><br><span class="line">and then follow the SSL configuration instructions in the product guide.</span><br><span class="line"> </span><br><span class="line">For client applications, you may only need to copy the CA certificate and</span><br><span class="line">configure the client to trust this certificate.</span><br></pre></td></tr></table></figure><p></p><p>在上面的命令中，我们生产一个绑定localhost的证书，也即是说这个证书只能在当前的localhost中进行使用。就像上面显示的那样，它在当前的目录中生产一个叫做certificate-bundle.zip的文件。这文件含有我们所需要的证书信息。我们使用如下的命令来解压缩这个文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">unzip certificate-bundle.zip </span><br><span class="line">Archive:  certificate-bundle.zip</span><br><span class="line">   creating: localhost/</span><br><span class="line">  inflating: localhost/localhost.crt  </span><br><span class="line">  inflating: localhost/localhost.key</span><br></pre></td></tr></table></figure><p>它在localhost中生成了我们想要的证书文件localhost.crt及localhoset.key。我们把这两个文件拷入到我们的APM 服务器安装的根目录中。</p><p>另注：我们可以使用如下的命令把一个.crt的证书转换为一个.pem的证书：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -in mycert.crt -out mycert.pem -outform PEM</span><br></pre></td></tr></table></figure><p></p><h1 id="配置APM-服务器"><a href="#配置APM-服务器" class="headerlink" title="配置APM 服务器"></a>配置APM 服务器</h1><p>为我们的APM服务器配置SSL/TLS<br>打开apm-server.yml文件，并把如下的配置加到该文件的最后面：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">apm-server.ssl.enabled: true</span><br><span class="line">apm-server.secret_token: &quot;123456&quot;</span><br><span class="line">apm-server.ssl.key: &quot;localhost.key&quot;</span><br><span class="line">apm-server.ssl.certificate: &quot;ca.crt&quot;</span><br></pre></td></tr></table></figure><p></p><p>通过上面的配置后，我们重新启动我们的APM server:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./apm-server -e</span><br></pre></td></tr></table></figure><p></p><h1 id="测试APM-agent"><a href="#测试APM-agent" class="headerlink" title="测试APM agent"></a>测试APM agent</h1><p>把之前生成的ca.crt证书拷入到该应用的根目录中，然后再引用的配置中新增俩参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">serviceName: &apos;zipcode service&apos;,</span><br><span class="line">secretToken: &apos;1234561&apos;, # 修改</span><br><span class="line">serverUrl: &apos;http://localhost:8200&apos;</span><br><span class="line">verifyServerCert: true, # 新增</span><br><span class="line">serverCaCertFile: &quot;ca.crt&quot; # 新增，最好使用绝对路径</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed Apr 15 2020 17:54:01 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自：&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/UbuntuTouch/article/details/105527468&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://blog.csdn.net/UbuntuTouch/article/details/105527468&lt;/a&gt;&lt;/p&gt;&lt;p&gt;APM Agents 访问APM server如果不做安全的设置，那么任何一个应用都有可能把数据传输到APM server中。&lt;br&gt;如果是恶意的软件，那么我们可能得到的数据是错误的。那么怎么保证我们的安全传输呢？&lt;br&gt;答案是在传输的时候使用secret token。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;/elk/apm1.png&quot; alt&gt;&lt;/p&gt;&lt;h1 id=&quot;Secret-token-是什么？&quot;&gt;&lt;a href=&quot;#Secret-token-是什么？&quot; class=&quot;headerlink&quot; title=&quot;Secret token 是什么？&quot;&gt;&lt;/a&gt;Secret token 是什么？&lt;/h1&gt;&lt;p&gt;您可以配置一个Secret token来授权对APM服务器的请求。 这样可以确保只有您的Agent才能将数据发送到您的APM服务器。&lt;br&gt;代理和APM服务器都必须配置相同的Secret toke，并且scecret token仅在与SSL/TLS结合使用时才提供安全性。&lt;/p&gt;&lt;p&gt;要使用Secret token 保护APM代理与APM服务器之间的通信安全：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在APM服务器中启用SSL/TLS&lt;/li&gt;&lt;li&gt;在Agent和服务器中设置Secret token&lt;/li&gt;&lt;li&gt;在APM agent中启用HTTPS&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="apm" scheme="https://yongnights.github.io/categories/elk/apm/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="apm" scheme="https://yongnights.github.io/tags/apm/"/>
    
  </entry>
  
  <entry>
    <title>ELK Stack 日志平台性能优化</title>
    <link href="https://yongnights.github.io/2020/04/15/ELK%20Stack%20%E6%97%A5%E5%BF%97%E5%B9%B3%E5%8F%B0%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <id>https://yongnights.github.io/2020/04/15/ELK Stack 日志平台性能优化/</id>
    <published>2020-04-15T07:46:14.479Z</published>
    <updated>2020-04-15T07:46:44.869Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 15 2020 15:47:44 GMT+0800 (GMT+08:00) --><p>1、性能分析</p><p>2、关于收集日志的选择：logstash/filter</p><p>3、Logstash的优化相关配置</p><p>4、引入Redis的相关问题</p><p>5、Elasticsearch节点优化配置</p><p>6、性能检查</p><a id="more"></a><p><strong>1、性能分析</strong></p><p><strong>服务器硬件Linux：**</strong>1cpu4GRAM**</p><p>假设每条日志250Byte。</p><p>分析：</p><p>①logstash-Linux：1cpu 4GRAM</p><ul><li>每秒500条日志；</li><li>去掉ruby每秒660条日志；</li><li>去掉grok后每秒1000条数据。</li></ul><p>②filebeat-Linux：1cpu 4GRAM</p><ul><li>每秒2500-3500条数据；</li><li>每天每台机器可处理：24h<em>60min</em>60sec<em> 3000</em>250Byte=64,800,000,000Bytes，约64G。</li></ul><p><strong>③</strong>瓶颈在logstash从Redis中取数据存入ES，开启一个logstash，每秒约处理6000条数据；开启两个logstash，每秒约处理10000条数据（cpu已基本跑满）；</p><p><strong>④</strong>logstash的启动过程占用大量系统资源，因为脚本中要检查java、ruby以及其他环境变量，启动后资源占用会恢复到正常状态。</p><p><strong>2、关于收集日志的选择：**</strong>logstash/filter**</p><p>没有原则要求使用filebeat或logstash，两者作为shipper的功能是一样的。</p><p><strong>区别在于：</strong></p><ul><li>logstash由于集成了众多插件，如grok、ruby，所以相比beat是重量级的；</li><li>logstash启动后占用资源更多，如果硬件资源足够则无需考虑二者差异；</li><li>logstash基于JVM，支持跨平台；而beat使用golang编写，AIX不支持；</li><li>AIX 64bit平台上需要安装jdk（jre） 1.7 32bit，64bit的不支持；</li><li>filebeat可以直接输入到ES，但是系统中存在logstash直接输入到ES的情况，这将造成不同的索引类型造成检索复杂，最好统一输入到els 的源。</li></ul><p><strong>总结：</strong></p><p>logstash/filter总之各有千秋，但是我推荐选择：在每个需要收集的日志服务器上配置filebeat，因为轻量级，用于收集日志；再统一输出给logstash，做对日志的处理；最后统一由logstash输出给es。</p><p><strong>3、logstash的优化相关配置</strong></p><p><strong>可以优化的参数，可根据自己的硬件进行优化配置：</strong></p><p>①pipeline线程数，官方建议是等于CPU内核数</p><ul><li>默认配置 —&gt; pipeline.workers: 2；</li><li>可优化为 —&gt; pipeline.workers: CPU内核数（或几倍CPU内核数）。</li></ul><p>②实际output时的线程数</p><ul><li>默认配置 —&gt; pipeline.output.workers: 1；</li><li>可优化为 —&gt; pipeline.output.workers: 不超过pipeline线程数。</li></ul><p>③每次发送的事件数</p><ul><li>默认配置 —&gt; pipeline.batch.size: 125；</li><li>可优化为 —&gt; pipeline.batch.size: 1000。</li></ul><p>④发送延时</p><ul><li>默认配置 —&gt; pipeline.batch.delay: 5；</li><li>可优化为 —&gt; pipeline.batch.size: 10。</li></ul><p><strong>总结：</strong></p><ul><li>通过设置-w参数指定pipeline worker数量，也可直接修改配置文件logstash.yml。这会提高filter和output的线程数，如果需要的话，将其设置为cpu核心数的几倍是安全的，线程在I/O上是空闲的。</li><li>默认每个输出在一个pipeline worker线程上活动，可以在输出output中设置workers设置，不要将该值设置大于pipeline worker数。</li><li>还可以设置输出的batch_size数，例如ES输出与batch size一致。</li><li>filter设置multiline后，pipline worker会自动将为1，如果使用filebeat，建议在beat中就使用multiline，如果使用logstash作为shipper，建议在input中设置multiline，不要在filter中设置multiline。</li></ul><p><strong>Logstash中的JVM配置文件：</strong></p><p>Logstash是一个基于Java开发的程序，需要运行在JVM中，可以通过配置jvm.options来针对JVM进行设定。比如内存的最大最小、垃圾清理机制等等。JVM的内存分配不能太大不能太小，太大会拖慢操作系统。太小导致无法启动。默认如下：</p><ul><li>Xms256m#最小使用内存；</li><li>Xmx1g#最大使用内存。</li></ul><p><strong>4、引入Redis的相关问题</strong></p><p>filebeat可以直接输入到logstash（indexer），但logstash没有存储功能，如果需要重启需要先停所有连入的beat，再停logstash，造成运维麻烦；另外如果logstash发生异常则会丢失数据；引入Redis作为数据缓冲池，当logstash异常停止后可以从Redis的客户端看到数据缓存在Redis中；</p><p>Redis可以使用list(最长支持4,294,967,295条)或发布订阅存储模式；</p><p><strong>Redis做ELK缓冲队列的优化：</strong></p><ul><li><p>bind 0.0.0.0 #不要监听本地端口；</p></li><li><p>requirepass ilinux.io #加密码，为了安全运行；</p></li><li><p>只做队列，没必要持久存储，把所有持久化功能关掉：</p><p>快照（RDB文件）和追加式文件（AOF文件），性能更好；</p><p>save “” 禁用快照；</p><p>appendonly no 关闭RDB。</p></li><li><p>把内存的淘汰策略关掉，把内存空间最大</p><p>maxmemory 0 #maxmemory为0的时候表示我们对Redis的内存使用没有限制。</p></li></ul><p><strong>5、Elasticsearch节点优化配置</strong></p><p><strong>服务器硬件配置，OS参数：</strong></p><p>1）/etc/sysctl.conf 配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/sysctl.confvm.swappiness = 1   #ES 推荐将此参数设置为 1，大幅降低 swap 分区的大小，强制最大程度的使用内存，注意，这里不要设置为 0, 这会很可能会造成 OOMnet.core.somaxconn = 65535     #定义了每个端口最大的监听队列的长度vm.max_map_count= 262144    #限制一个进程可以拥有的VMA(虚拟内存区域)的数量。虚拟内存区域是一个连续的虚拟地址空间区域。当VMA 的数量超过这个值，OOMfs.file-max = 518144    #设置 Linux 内核分配的文件句柄的最大数量# sysctl -p    #生效一下</span><br></pre></td></tr></table></figure><p>2）limits.conf 配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/security/limits.confelasticsearch    soft    nofile          65535elasticsearch    hard    nofile          65535elasticsearch    soft    memlock         unlimitedelasticsearch    hard    memlock         unlimited</span><br></pre></td></tr></table></figure><p>3）为了使以上参数永久生效，还要设置两个地方：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/pam.d/common-session-noninteractive# vim /etc/pam.d/common-session</span><br></pre></td></tr></table></figure><p>添加如下属性：</p><p>session required pam_limits.so</p><p>可能需重启后生效。</p><p><strong>Elasticsearch中的JVM配置文件：</strong></p><p>-Xms2g</p><p>-Xmx2g</p><ul><li>将最小堆大小（Xms）和最大堆大小（Xmx）设置为彼此相等。</li><li>Elasticsearch可用的堆越多，可用于缓存的内存就越多。但请注意，太多的堆可能会使您长时间垃圾收集暂停。</li><li>设置Xmx为不超过物理RAM的50％，以确保有足够的物理内存留给内核文件系统缓存。</li><li>不要设置Xmx为JVM用于压缩对象指针的临界值以上；确切的截止值有所不同，但接近32 GB。不要超过32G，如果空间大，多跑几个实例，不要让一个实例太大内存。</li></ul><p><strong>Elasticsearch配置文件优化参数：</strong></p><p>1）主配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># vim elasticsearch.ymlbootstrap.memory_lock: true  #锁住内存，不使用swap#缓存、线程等优化如下bootstrap.mlockall: truetransport.tcp.compress: trueindices.fielddata.cache.size: 40%indices.cache.filter.size: 30%indices.cache.filter.terms.size: 1024mbthreadpool:    search:        type: cached        size: 100        queue_size: 2000</span><br></pre></td></tr></table></figure><p>2）设置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/profile.d/elasticsearch.sh export ES_HE AP _SIZE=2g #Heap Size不超过物理内存的一半，且小于32G。</span><br></pre></td></tr></table></figure><p><strong>集群的优化（我未使用集群）：</strong></p><ul><li>ES是分布式存储，当设置同样的cluster.name后会自动发现并加入集群；</li><li>集群会自动选举一个master，当master宕机后重新选举；</li><li>为防止”脑裂”，集群中个数最好为奇数个；</li><li>为有效管理节点，可关闭广播discovery. zen.ping.multicast.enabled: false，并设置单播节点组discovery.zen.ping.unicast.hosts: [“ip1”, “ip2”, “ip3”]。</li></ul><p><strong>6、性能的检查</strong></p><p><strong>检查输入和输出的性能：</strong></p><p>Logstash和其连接的服务运行速度一致，它可以和输入、输出的速度一样快。</p><p><strong>检查系统参数：</strong></p><p>1）CPU</p><ul><li>注意CPU是否过载。在Linux/Unix系统中可以使用top-H查看进程参数以及总计。</li><li>如果CPU使用过高，直接跳到检查JVM堆的章节并检查Logstash worker设置。</li></ul><p>2）Memory</p><ul><li>注意Logstash是运行在Java虚拟机中的，所以它只会用到你分配给它的最大内存。</li><li>检查其他应用使用大量内存的情况，这将造成Logstash使用硬盘swap，这种情况会在应用占用内存超出物理内存范围时。</li></ul><p>3）I/O监控磁盘I/O检查磁盘饱和度</p><ul><li>使用Logstash plugin（例如使用文件输出）磁盘会发生饱和。</li><li>当发生大量错误，Logstash生成大量错误日志时磁盘也会发生饱和。</li><li>在Linux中，可使用iostat，dstat或者其他命令监控磁盘I/O。</li></ul><p>4）监控网络I/O</p><ul><li>当使用大量网络操作的input、output时，会导致网络饱和。</li><li>在Linux中可使用dstat或iftop监控网络情况。</li></ul><p><strong>检查JVM heap：</strong></p><ul><li>heap设置太小会导致CPU使用率过高，这是因为JVM的垃圾回收机制导致的。</li><li>一个快速检查该设置的方法是将heap设置为两倍大小然后检测性能改进。不要将heap设置超过物理内存大小，保留至少1G内存给操作系统和其他进程。</li><li>你可以使用类似jmap命令行或VisualVM更加精确的计算JVM heap。</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed Apr 15 2020 15:47:44 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;1、性能分析&lt;/p&gt;&lt;p&gt;2、关于收集日志的选择：logstash/filter&lt;/p&gt;&lt;p&gt;3、Logstash的优化相关配置&lt;/p&gt;&lt;p&gt;4、引入Redis的相关问题&lt;/p&gt;&lt;p&gt;5、Elasticsearch节点优化配置&lt;/p&gt;&lt;p&gt;6、性能检查&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch集群规模和容量规划的底层逻辑</title>
    <link href="https://yongnights.github.io/2020/04/15/Elasticsearch%E9%9B%86%E7%BE%A4%E8%A7%84%E6%A8%A1%E5%92%8C%E5%AE%B9%E9%87%8F%E8%A7%84%E5%88%92%E7%9A%84%E5%BA%95%E5%B1%82%E9%80%BB%E8%BE%91/"/>
    <id>https://yongnights.github.io/2020/04/15/Elasticsearch集群规模和容量规划的底层逻辑/</id>
    <published>2020-04-15T07:36:11.081Z</published>
    <updated>2020-04-15T07:43:55.337Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 15 2020 15:44:08 GMT+0800 (GMT+08:00) --><p>转载自：<br><a href="https://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;mid=2247484628&amp;idx=1&amp;sn=666e416ae28b93e42c26f26b208dea84&amp;chksm=eaa82cfcdddfa5eacfcddb0cf54edcecb3ad86ca2cafd6f4f2d90cf8a4033d83eb16cb2a56f0&amp;mpshare=1&amp;scene=1&amp;srcid=1214DDMLBFx4TWeYblyDIWrG&amp;sharer_sharetime=1576338975283&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;mid=2247484628&amp;idx=1&amp;sn=666e416ae28b93e42c26f26b208dea84&amp;chksm=eaa82cfcdddfa5eacfcddb0cf54edcecb3ad86ca2cafd6f4f2d90cf8a4033d83eb16cb2a56f0&amp;mpshare=1&amp;scene=1&amp;srcid=1214DDMLBFx4TWeYblyDIWrG&amp;sharer_sharetime=1576338975283&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>Elasticsearch 集群规模和容量规划：是进行 Elasticsearch 集群部署前对所需资源类型和数量的规划。</p><p>通过本文，您将了解：<br>Elasticsearch 计算资源详解<br>Elasticsearch 架构、增删改查操作和资源需求<br>Elasticsearch 集群规模和容量规划的方法论</p><p>1、Elasticsearch 基础架构</p><h2 id="1-1-自顶向下的架构体系"><a href="#1-1-自顶向下的架构体系" class="headerlink" title="1.1 自顶向下的架构体系"></a>1.1 自顶向下的架构体系</h2><p><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415151901948-1231924385.png" alt></p><ul><li>Cluster—协同工作的节点组，以保障 Elasticsearch 的运行。</li><li>Node—运行 Elasticsearch 软件的 Java 进程。</li><li>Index—一组形成逻辑数据存储的分片的集合。</li><li>Shard—Lucene 索引，用于存储和处理 Elasticsearch 索引的一部分。</li><li>Segment—Lucene 段，存储了 Lucene 索引的一部分且不可变。</li><li>Document—条记录，用以写入 Elasticsearch 索引并从中检索数据。</li></ul><a id="more"></a><h2 id="1-2-节点角色划分及资源使用情况"><a href="#1-2-节点角色划分及资源使用情况" class="headerlink" title="1.2 节点角色划分及资源使用情况"></a>1.2 节点角色划分及资源使用情况</h2><p><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415151955230-141775710.png" alt><br>划重点：对资源利用率拿不准的，多结合业务实际看看这个表格。</p><h1 id="2、维系-Elasticsearch-高性能的资源组成"><a href="#2、维系-Elasticsearch-高性能的资源组成" class="headerlink" title="2、维系 Elasticsearch 高性能的资源组成"></a>2、维系 Elasticsearch 高性能的资源组成</h1><p>4 个基本的计算资源 存储、内存、计算、网络<br><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415152101211-389099791.png" alt></p><h2 id="2-1-存储资源"><a href="#2-1-存储资源" class="headerlink" title="2.1 存储资源"></a>2.1 存储资源</h2><h3 id="2-1-1-存储介质"><a href="#2-1-1-存储介质" class="headerlink" title="2.1.1 存储介质"></a>2.1.1 存储介质</h3><ul><li>固态硬盘（SSD） 提供最佳“热”工作负载的性能。</li><li>普通磁盘（HDD） 成本低，用于“暖”和“冷”数据存储。</li></ul><p>注意：RAID0 可以提高性能。RAID 是可选的，因为 Elastic 默认为 N + 1 分片复制策略。<br>为了追求硬件级别的高可用性，可以接受标准性能的 RAID 配置（例如 RAID 1/10/50 等）。</p><h3 id="2-1-2-存储建议"><a href="#2-1-2-存储建议" class="headerlink" title="2.1.2 存储建议"></a>2.1.2 存储建议</h3><ul><li>建议直接使用：附加存储（DAS）、存储区域网络（SAN）、超融合存储（建议最低〜3Gb / s，250Mb / s）</li><li>避免使用：网络附加存储（NAS）例如 SMB，NFS，AFP。使用时可能带来的性能问题：网络协议的开销，延迟大和昂贵的存储抽象层。</li></ul><h2 id="2-2-内存资源"><a href="#2-2-内存资源" class="headerlink" title="2.2 内存资源"></a>2.2 内存资源</h2><h3 id="2-2-1-JVM-Heap"><a href="#2-2-1-JVM-Heap" class="headerlink" title="2.2.1 JVM Heap"></a>2.2.1 JVM Heap</h3><p>存储有关集群索引、分片、段和 fielddata 数据。<br>建议：可用 RAM 的 50％，最多最大 30GB RAM，以避免垃圾回收。</p><p>官方文档最大指 32 GB：<a href="https://www.elastic.co/guide/en/elasticsearch/guide/master/heap-sizing.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/guide/master/heap-sizing.html</a></p><h3 id="2-2-2-操作系统缓存"><a href="#2-2-2-操作系统缓存" class="headerlink" title="2.2.2 操作系统缓存"></a>2.2.2 操作系统缓存</h3><p>Elasticsearch 将使用剩余的可用内存来缓存数据（Lucene 使用）， 通过避免在全文检索、文档聚合和排序环节的磁盘读取，极大地提高了性能。</p><h2 id="2-3-计算资源"><a href="#2-3-计算资源" class="headerlink" title="2.3 计算资源"></a>2.3 计算资源</h2><p>Elasticsearch 如何使用计算资源？<br>Elasticsearch 处理数据的方式多种多样，但计算成本较高。<br>可用的计算资源：线程池、线程队列。<br>CPU 内核的数量和性能：决定着计算平均速度和峰值吞吐量。</p><h2 id="2-4-网络资源"><a href="#2-4-网络资源" class="headerlink" title="2.4 网络资源"></a>2.4 网络资源</h2><p>Elasticsearch 如何使用网络？小带宽是限制 Elasticsearch 的资源。<br>针对大规模集群，ingest、搜索和副本复制相关的数据传输可能会导致网络饱和。<br>在这些情况下，网络连接可以考虑升级到更高的速度，或者 Elastic 部署可以分为两个或多个集群，然后使用跨集群（CCS）作为单个逻辑单元进行搜索。</p><h1 id="3、数据增删改查操作"><a href="#3、数据增删改查操作" class="headerlink" title="3、数据增删改查操作"></a>3、数据增删改查操作</h1><p>增、删、改、查是 Elasticsearch 中的四个基本数据操作。<br>每个操作都有其自己的资源需求。每个业务用例都利用其中一个操作，实际业务往往会侧重其中一个或多个操作。</p><ul><li>增：新增索引处理文档并将其存储在索引中，以备将来检索。</li><li>删：从索引中删除文档。</li><li>改：更新删除文档并为其替换的新文档建立索引。</li><li>查：搜索从一个或多个索引中检索或聚合一个或多个文档。</li></ul><h2 id="3-1-增-索引数据处理流程"><a href="#3-1-增-索引数据处理流程" class="headerlink" title="3.1 增/索引数据处理流程"></a>3.1 增/索引数据处理流程</h2><p><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415152418882-96700866.png" alt></p><p>如图所示，增/索引数据大致的处理流程如下：<br>1、客户端发起写入请求到协调节点；<br>2、协调节点根据请求类型的不同进行判断，如果是 Ingest 相关，提交给 Ingest 节点；如果不相关，则计算路由后提交给数据节点；<br>3、数据节点根据数据类型不同决定是否分词以索引化数据，最终落地磁盘存储；同时将副本分发给其他数据节点。</p><h2 id="3-2-删除数据处理流程"><a href="#3-2-删除数据处理流程" class="headerlink" title="3.2 删除数据处理流程"></a>3.2 删除数据处理流程</h2><p><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415152459219-1117674276.png" alt><br>如果所示，删除数据大致处理流程如下：<br>1、客户端发出删除文档请求到协调节点；<br>2、协调节点将请求路由给数据节点；<br>3、数据节点接收到请求后，将数据标记为 deleted 状态（注意，此处为逻辑删除）<br>4、待段合并时机，逻辑删除会变成物理删除。</p><h2 id="3-3-更新数据处理流程"><a href="#3-3-更新数据处理流程" class="headerlink" title="3.3 更新数据处理流程"></a>3.3 更新数据处理流程</h2><p>文档在 Elasticsearch 中是不可变的。当 Elasticsearch 更新文档时，它将删除原始文档并为新的待更新的文档建立索引。<br>这两步操作在每个 Lucene 分片是原子操作，操作会带来删除和索引（索引不调用任何 ingest pipeline 操作）操作的开销。<br>Update = Delete + (Index - Ingest Pipeline）</p><h2 id="3-4-检索操作处理流程"><a href="#3-4-检索操作处理流程" class="headerlink" title="3.4 检索操作处理流程"></a>3.4 检索操作处理流程</h2><p>“搜索”是信息检索的通用术语。Elasticsearch 具有多种检索功能，包括但不限于全文搜索、范围搜索、脚本搜索和聚合。<br>搜索速度和吞吐量受许多因素影响，包括集群的配置、索引、查询和硬件。<br>实际的容量规划取决于应用上述优化配置后的大量测试实践结果。<br>Elasticsearch 检索可以细化分为：scatter（分散）、 search（检索）、gather（收集）、merge（合并）四个阶段。<br><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415152612607-1167281145.png" alt></p><ul><li>scatter:将结果分发给各个相关的分片；</li><li>search：在各个分片执行检索；</li><li>gather：数据节点将检索结果汇集到协调节点；</li><li>merge：协调节点将数据结果进行合并，返回给客户端。</li></ul><h2 id="3-5-用例场景"><a href="#3-5-用例场景" class="headerlink" title="3.5 用例场景"></a>3.5 用例场景</h2><p>Elasticsearch 有一些常规的使用模式。大致可分类如下：</p><ul><li>写/索引（Index）密集型的业务场景：Logging, Metrics, Security, APM</li><li>检索（search）密集型的业务场景：App Search, Site Search, Analytics</li><li>更新（update）密集型的业务场景：Caching, Systems of Record</li><li>混合（hybrid）业务场景：支持多种操作的混合用例 Transactions Search</li></ul><h1 id="4、Elasticsearch-索引化流程"><a href="#4、Elasticsearch-索引化流程" class="headerlink" title="4、Elasticsearch 索引化流程"></a>4、Elasticsearch 索引化流程</h1><h2 id="4-0-概述"><a href="#4-0-概述" class="headerlink" title="4.0 概述"></a>4.0 概述</h2><p>以下过程适用于 ingest 节点处理数据流程。</p><ul><li>Json 数据转换——结构化或非结构化数据，转换为 json 落地存储。</li><li>数据索引化——数据以不同数据类型进行处理和索引。</li><li>数据压缩——提高存储效率。</li><li>副本复制——提高容错能力和搜索吞吐量。</li></ul><h2 id="4-1-Json-转换"><a href="#4-1-Json-转换" class="headerlink" title="4.1 Json 转换"></a>4.1 Json 转换</h2><p>结构化或非结构化数据转换成 json 格式，可通过<code>_source</code>控制是否展示。<br><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415152806918-1898682410.png" alt></p><h2 id="4-2-数据索引化"><a href="#4-2-数据索引化" class="headerlink" title="4.2 数据索引化"></a>4.2 数据索引化</h2><p>第一：数据结构 Elasticsearch 索引各种数据结构中的值。每种数据类型 有自己的存储特性。<br>第二：多种索引方法 某些值可以通过多种方式索引。字符串值通常是索引两次（借助 fields 实现）。</p><ul><li>一次作为聚合的 keyword 类型；</li><li>一次作为文本用于全文搜索的 text 类型。<br><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415152840801-401920655.png" alt></li></ul><h2 id="4-3-数据压缩"><a href="#4-3-数据压缩" class="headerlink" title="4.3 数据压缩"></a>4.3 数据压缩</h2><p>Elasticsearch 可以使用两种不同的压缩算法之一来压缩数据：LZ4（默认）和 DEFLATE。<br>与 LZ4 相比，DEFLATE 节省了多达 15％的额外空间，但以增加的计算时间为代价。<br>通常，Elasticsearch 可以将数据压缩 20 – 30％</p><h2 id="4-4-副本分片拷贝"><a href="#4-4-副本分片拷贝" class="headerlink" title="4.4 副本分片拷贝"></a>4.4 副本分片拷贝</h2><p>第一：存储 Elasticsearch 可以在数据节点之间复制分片一次或多次，以提高容错能力和搜索吞吐量。<br>每个副本分片都是其主分片的完整副本。<br>第二：索引和搜索吞吐量</p><ul><li>日志记录和指标用例场景（Logging and metrics）通常具有一个副本分片，这是确保出现故障的最小数量， 同时最大程度地减少了写入次数。</li><li>搜索用例通常具有更多的副本分片以提高搜索吞吐率。</li></ul><h2 id="4-5-完整示例"><a href="#4-5-完整示例" class="headerlink" title="4.5 完整示例"></a>4.5 完整示例</h2><p><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415152939559-1175956275.png" alt></p><h1 id="5、集群规模和容量规划预估方法"><a href="#5、集群规模和容量规划预估方法" class="headerlink" title="5、集群规模和容量规划预估方法"></a>5、集群规模和容量规划预估方法</h1><p>容量规划——预估集群中每个节点的分片数、内存及存储资源。<br>吞吐量规划——以预期的延迟和吞吐量估算处理预期操作所需的内存，计算和网络资源。</p><h2 id="5-1-数据量预估"><a href="#5-1-数据量预估" class="headerlink" title="5.1 数据量预估"></a>5.1 数据量预估</h2><p>第一，问自己几个问题：</p><ul><li>您每天将索引多少原始数据（GB）？</li><li>您将保留数据多少天？</li><li>每天增量数据是多少？</li><li>您将强制执行多少个副本分片？</li><li>您将为每个数据节点分配多少内存？</li><li>您的内存：数据比率是多少？</li></ul><p>第二，预留存储以备错误。(Elastic 官方推荐经验值）</p><ul><li>预留 15%警戒磁盘水位空间。</li><li>为错误余量和后台活动预留+ 5％。</li><li>保留等效的数据节点以处理故障。</li></ul><p>第三，容量预估计算方法如下：</p><ul><li>总数据量（GB） = 原始数据量（GB） /每天 X 保留天数 X 净膨胀系数 X （副本 + 1）</li><li>磁盘存储（GB） = 总数据量（GB）* ( 1 + 0.15 + 0.05)</li><li>数据节点 = 向上取证（磁盘存储（GB）/ 每个数据节点的内存量 / 内存：数据比率）+ 1</li></ul><p>Tips：腾讯云 在 2019 4 月的 meetup 分享中建议：磁盘容量大小 = 原始数据大小 * 3.38。</p><h2 id="5-2-分片预估"><a href="#5-2-分片预估" class="headerlink" title="5.2 分片预估"></a>5.2 分片预估</h2><p>第一，问自己几个问题：</p><ul><li>您将创建多少索引？</li><li>您将配置多少个主和副本分片？</li><li>您将在什么时间间隔旋转索引？</li><li>您将保留索引多长时间？</li><li>您将为每个数据节点分配多少内存？</li></ul><p>第二，经验值（Elastic 官方推荐）</p><ul><li>每 GB JVM 堆内存支持的分片数不超过 20 个。</li><li>每个分片大小不要超过 50GB。推荐阅读：<a href="https://www.elastic.co/cn/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster</a></li></ul><p>Tips：</p><ul><li>将小的每日索引整合为每周或每月的索引，以减少分片数。</li><li>将大型（&gt; 50GB）每日索引分拆分成小时索引或增加主分片的数量。</li></ul><p>第三，分片预估方法如下：</p><ul><li>总分片数 = 索引个数 X 主分片数 * （副本分片数 +1）X 保留间隔</li><li>总数据节点个数 = 向上取整（总分片数 / (20 X 每个节点内存大小））</li></ul><h2 id="5-3-搜索吞吐量预估"><a href="#5-3-搜索吞吐量预估" class="headerlink" title="5.3 搜索吞吐量预估"></a>5.3 搜索吞吐量预估</h2><p>搜索用例场景除了考虑搜索容量外，还要考虑如下目标：</p><ul><li>搜索响应时间；</li><li>搜索吞吐量。</li></ul><p>这些目标可能需要更多的内存和计算资源。</p><p>第一：问自己几个问题</p><ul><li>您期望每秒的峰值搜索量是多少？</li><li>您期望平均搜索响应时间是多少毫秒？</li><li>您期望的数据节点上几核 CPU，每核有多少个线程？</li></ul><p>第二：方法论 与其确定资源将如何影响搜索速度，不如通过在计划的固定硬件上进行测量，可以将搜索速度作为一个常数，</p><p>然后确定集群中要处理峰值搜索吞吐量需要多少个核。<br>最终目标是防止线程池排队的增长速度超过了 CPU 的处理能力。<br>如果计算资源不足，搜索请求可能会被拒绝掉。</p><p>第三：吞吐量预估方法</p><ul><li>峰值线程数 = 向上取整（每秒峰值检索请求数 _ 每个请求的平均响应时间（毫秒）/1000）</li><li>线程队列大小 = 向上取整（(每个节点的物理 cpu 核数 _ 每核的线程数 * 3 / 2）+ 1)</li><li>总数据节点个数 = 向上取整（峰值线程数 / 线程队列大小）</li></ul><h2 id="5-4-冷热集群架构"><a href="#5-4-冷热集群架构" class="headerlink" title="5.4 冷热集群架构"></a>5.4 冷热集群架构</h2><p>Elasticsearch 可以使用分片分配感知（shard allocation awareness）在特定硬件上分配分片。<br>索引密集型业务场景通常使用它在热节点、暖节点和冷（Frozen）节点上存储索引，<br>然后根据业务需要进行数据迁移（热节点-&gt;暖节点-&gt;冷节点），以完成数据的删除和存档需要。<br>这是优化集群性能的最经济方法之一，在容量规划期间，先确定每一类节点的数据规模，然后进行组合。<br>冷热集群架构推荐：<br><img src="https://img2020.cnblogs.com/blog/794174/202004/794174-20200415153242489-1003891227.png" alt></p><h2 id="5-5-集群节点角色划分"><a href="#5-5-集群节点角色划分" class="headerlink" title="5.5 集群节点角色划分"></a>5.5 集群节点角色划分</h2><p>Elasticsearch 节点执行一个或多个角色。通常，当集群规模大时，每个节点分配一个具体角色很有意义。<br>您可以针对每个角色优化硬件，并防止节点争夺资源。</p><h1 id="6、小结"><a href="#6、小结" class="headerlink" title="6、小结"></a>6、小结</h1><p>集群规模和容量规划的底层逻辑涉及到：</p><ul><li>Elasticsearch 的基础架构</li><li>维系 Elasticsearch 高效运转的计算资源（CPU、内存、磁盘、网络）</li><li>Elasticsearch 增删改查的业务流程及资源耗费情况</li><li>Elasticsearch 数据索引化的核心流程 基于以上四点的整合，才有了：集群规模和容量规划预估方法。</li></ul><p>评估所需资源需要执行以下步骤：</p><p>步骤1：确定集群的节点类型；<br>步骤2：对于不同节点类型（热，暖，冷），确定以下规模的最大值：</p><ul><li>数据量</li><li>分片数量</li><li>索引吞吐量</li><li>搜索吞吐量</li></ul><p>步骤3：合并每一类型节点所需资源大小 注意：在任何专用节点上做出决策-主节点、协调节点、机器学习节点、路由节点。</p><p>注：这是 Elastic 官方 2019 年 11 月份的视频 内容的详细梳理。<br>推荐过一遍视频：<a href="https://www.elastic.co/cn/webinars/elasticsearch-sizing-and-capacity-planning" target="_blank" rel="noopener">https://www.elastic.co/cn/webinars/elasticsearch-sizing-and-capacity-planning</a></p><p>附件：容量规划PDF文件：<a href="https://files.cnblogs.com/files/sanduzxcvbnm/elasticsearch-sizing-and-capacity-planning.pdf" target="_blank" rel="noopener">https://files.cnblogs.com/files/sanduzxcvbnm/elasticsearch-sizing-and-capacity-planning.pdf</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed Apr 15 2020 15:44:08 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自：&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;amp;mid=2247484628&amp;amp;idx=1&amp;amp;sn=666e416ae28b93e42c26f26b208dea84&amp;amp;chksm=eaa82cfcdddfa5eacfcddb0cf54edcecb3ad86ca2cafd6f4f2d90cf8a4033d83eb16cb2a56f0&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1214DDMLBFx4TWeYblyDIWrG&amp;amp;sharer_sharetime=1576338975283&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&amp;amp;mid=2247484628&amp;amp;idx=1&amp;amp;sn=666e416ae28b93e42c26f26b208dea84&amp;amp;chksm=eaa82cfcdddfa5eacfcddb0cf54edcecb3ad86ca2cafd6f4f2d90cf8a4033d83eb16cb2a56f0&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1214DDMLBFx4TWeYblyDIWrG&amp;amp;sharer_sharetime=1576338975283&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Elasticsearch 集群规模和容量规划：是进行 Elasticsearch 集群部署前对所需资源类型和数量的规划。&lt;/p&gt;&lt;p&gt;通过本文，您将了解：&lt;br&gt;Elasticsearch 计算资源详解&lt;br&gt;Elasticsearch 架构、增删改查操作和资源需求&lt;br&gt;Elasticsearch 集群规模和容量规划的方法论&lt;/p&gt;&lt;p&gt;1、Elasticsearch 基础架构&lt;/p&gt;&lt;h2 id=&quot;1-1-自顶向下的架构体系&quot;&gt;&lt;a href=&quot;#1-1-自顶向下的架构体系&quot; class=&quot;headerlink&quot; title=&quot;1.1 自顶向下的架构体系&quot;&gt;&lt;/a&gt;1.1 自顶向下的架构体系&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://img2020.cnblogs.com/blog/794174/202004/794174-20200415151901948-1231924385.png&quot; alt&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Cluster—协同工作的节点组，以保障 Elasticsearch 的运行。&lt;/li&gt;&lt;li&gt;Node—运行 Elasticsearch 软件的 Java 进程。&lt;/li&gt;&lt;li&gt;Index—一组形成逻辑数据存储的分片的集合。&lt;/li&gt;&lt;li&gt;Shard—Lucene 索引，用于存储和处理 Elasticsearch 索引的一部分。&lt;/li&gt;&lt;li&gt;Segment—Lucene 段，存储了 Lucene 索引的一部分且不可变。&lt;/li&gt;&lt;li&gt;Document—条记录，用以写入 Elasticsearch 索引并从中检索数据。&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/categories/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>EFK-5 ES集群开启用户认证</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-5%EF%BC%9AES%E9%9B%86%E7%BE%A4%E5%BC%80%E5%90%AF%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%20/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-5：ES集群开启用户认证 /</id>
    <published>2020-04-14T08:55:14.913Z</published>
    <updated>2020-04-14T09:17:25.005Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:58 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483826&amp;idx=1&amp;sn=583e9a526050682ae060f601eced917b&amp;chksm=fa769a9ccd01138a8740171769d1149a5df706ab3523eb0cbb5697293bda6e46954641d49f99&amp;mpshare=1&amp;scene=1&amp;srcid=01245nkmqHupjQF7csKql1i5&amp;sharer_sharetime=1579865464558&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483826&amp;idx=1&amp;sn=583e9a526050682ae060f601eced917b&amp;chksm=fa769a9ccd01138a8740171769d1149a5df706ab3523eb0cbb5697293bda6e46954641d49f99&amp;mpshare=1&amp;scene=1&amp;srcid=01245nkmqHupjQF7csKql1i5&amp;sharer_sharetime=1579865464558&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>基于ES内置及自定义用户实现kibana和filebeat的认证</p><a id="more"></a><p><img src="/elk/elk5.png" alt></p><h1 id="关闭服务"><a href="#关闭服务" class="headerlink" title="关闭服务"></a>关闭服务</h1><p>先关闭所有ElasticSearch、kibana、filebeat进程</p><h1 id="elasticsearch-修改elasticsearch-yml配置"><a href="#elasticsearch-修改elasticsearch-yml配置" class="headerlink" title="elasticsearch-修改elasticsearch.yml配置"></a>elasticsearch-修改elasticsearch.yml配置</h1><p>按以上表格对应的实例新增conf目录下elasticsearch.yml配置参数<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 在所有实例上加上以下配置</span><br><span class="line"></span><br><span class="line"># 开启本地用户</span><br><span class="line"></span><br><span class="line">xpack.security.enabled: true</span><br><span class="line"></span><br><span class="line"># xpack的版本</span><br><span class="line"></span><br><span class="line">xpack.license.self_generated.type: basic</span><br></pre></td></tr></table></figure><p></p><h1 id="elasticsearch-开启服务"><a href="#elasticsearch-开启服务" class="headerlink" title="elasticsearch-开启服务"></a>elasticsearch-开启服务</h1><p>开启所有ES服务<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch ./bin/elasticsearch</span><br></pre></td></tr></table></figure><p></p><h1 id="elasticsearch-建立本地内置用户"><a href="#elasticsearch-建立本地内置用户" class="headerlink" title="elasticsearch-建立本地内置用户"></a>elasticsearch-建立本地内置用户</h1><p>本地内置elastic、apmsystem、kibana、logstashsystem、beatssystem、remotemonitoring_user用户<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 在其中一台master节点操作</span><br><span class="line"></span><br><span class="line"># interactive 自定密码 auto自动生密码</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-setup-passwords interactive</span><br><span class="line"></span><br><span class="line"># 输入elastic密码</span><br><span class="line"></span><br><span class="line"># 输入apm_system密码</span><br><span class="line"></span><br><span class="line"># 输入kibana密码</span><br><span class="line"></span><br><span class="line"># 输入logstash_system密码</span><br><span class="line"></span><br><span class="line"># 输入beats_system密码</span><br><span class="line"></span><br><span class="line"># 输入remote_monitoring_user密码</span><br></pre></td></tr></table></figure><p></p><h2 id="测试内部用户"><a href="#测试内部用户" class="headerlink" title="测试内部用户"></a>测试内部用户</h2><p>通过base64将elastic用户进行加密，格式为“elastic:elastic的密码“<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 例如以下格式</span><br><span class="line"></span><br><span class="line">curl -H &quot;Authorization: Basic ZWxhc3RpYzplbGFzdGkxMjM0NTY3OA==&quot; &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><p></p><p>如果不通过Basic访问或base64加密错误会报以下错误:<br>“status”: 401</p><h1 id="kibana-创建私钥库"><a href="#kibana-创建私钥库" class="headerlink" title="kibana-创建私钥库"></a>kibana-创建私钥库</h1><h2 id="在192-168-1-21创建私钥库"><a href="#在192-168-1-21创建私钥库" class="headerlink" title="在192.168.1.21创建私钥库"></a>在192.168.1.21创建私钥库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/kibana/</span><br><span class="line"></span><br><span class="line"># 创建密钥库</span><br><span class="line"></span><br><span class="line">sudo -u kibana ./bin/kibana-keystore create</span><br><span class="line"></span><br><span class="line"># 连接ES用户名，这里输入kibana</span><br><span class="line"></span><br><span class="line">sudo -u kibana ./bin/kibana-keystore add elasticsearch.username</span><br><span class="line"></span><br><span class="line"># 连接ES密码，这里输入刚刚设置kibana的密码</span><br><span class="line"></span><br><span class="line">sudo -u kibana ./bin/kibana-keystore add elasticsearch.password</span><br></pre></td></tr></table></figure><h2 id="在192-168-1-21确认私钥库"><a href="#在192-168-1-21确认私钥库" class="headerlink" title="在192.168.1.21确认私钥库"></a>在192.168.1.21确认私钥库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u kibana ./bin/kibana-keystore list</span><br></pre></td></tr></table></figure><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u kibana /opt/kibana/bin/kibana -c /opt/kibana/config/kibana.yml</span><br></pre></td></tr></table></figure><h1 id="filebeat-服务器上创建密钥库"><a href="#filebeat-服务器上创建密钥库" class="headerlink" title="filebeat-服务器上创建密钥库"></a>filebeat-服务器上创建密钥库</h1><h2 id="在192-168-1-11创建filebeat密钥库"><a href="#在192-168-1-11创建filebeat密钥库" class="headerlink" title="在192.168.1.11创建filebeat密钥库"></a>在192.168.1.11创建filebeat密钥库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/filebeat/</span><br><span class="line"></span><br><span class="line">#创建密钥库</span><br><span class="line"></span><br><span class="line">./filebeat keystore create</span><br><span class="line"></span><br><span class="line">#创建test-filebeat用户私钥</span><br><span class="line"></span><br><span class="line">./filebeat keystore add test-filebeat</span><br></pre></td></tr></table></figure><h2 id="确认filebeat密钥库"><a href="#确认filebeat密钥库" class="headerlink" title="确认filebeat密钥库"></a>确认filebeat密钥库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./filebeat keystore list</span><br></pre></td></tr></table></figure><h1 id="filebeat-配置filebeat-yml"><a href="#filebeat-配置filebeat-yml" class="headerlink" title="filebeat-配置filebeat.yml"></a>filebeat-配置filebeat.yml</h1><h2 id="配置filebeat-yml"><a href="#配置filebeat-yml" class="headerlink" title="配置filebeat.yml"></a>配置filebeat.yml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"># 文件输入</span><br><span class="line"></span><br><span class="line">filebeat.inputs:</span><br><span class="line"></span><br><span class="line">  # 文件输入类型</span><br><span class="line"></span><br><span class="line">  - type: log</span><br><span class="line"></span><br><span class="line">    # 开启加载</span><br><span class="line"></span><br><span class="line">    enabled: true</span><br><span class="line"></span><br><span class="line">    # 文件位置</span><br><span class="line"></span><br><span class="line">    paths:</span><br><span class="line"></span><br><span class="line">      - /var/log/nginx/access.log</span><br><span class="line"></span><br><span class="line">    # 自定义参数</span><br><span class="line"></span><br><span class="line">    fields:</span><br><span class="line"></span><br><span class="line">      type: nginx_access # 类型是nginx_access,和上面fields.type是一致的</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 输出至elasticsearch</span><br><span class="line"></span><br><span class="line">output.elasticsearch:</span><br><span class="line"></span><br><span class="line">  # 连接ES集群的用户名</span><br><span class="line"></span><br><span class="line">  username: test-filebeat</span><br><span class="line"></span><br><span class="line">  # 连接ES集群的密码</span><br><span class="line"></span><br><span class="line">  password: &quot;$&#123;test-filebeat密码&#125;&quot;</span><br><span class="line"></span><br><span class="line">  # elasticsearch集群</span><br><span class="line"></span><br><span class="line">  hosts: [&quot;http://192.168.1.31:9200&quot;,</span><br><span class="line"></span><br><span class="line">          &quot;http://192.168.1.32:9200&quot;,</span><br><span class="line"></span><br><span class="line">          &quot;http://192.168.1.33:9200&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  # 索引配置</span><br><span class="line"></span><br><span class="line">  indices:</span><br><span class="line"></span><br><span class="line">    # 索引名</span><br><span class="line"></span><br><span class="line">    - index: &quot;nginx_access_%&#123;+yyy.MM&#125;&quot;</span><br><span class="line"></span><br><span class="line">      # 当类型是nginx_access时使用此索引</span><br><span class="line"></span><br><span class="line">      when.equals:</span><br><span class="line"></span><br><span class="line">        fields.type: &quot;nginx_access&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 关闭自带模板</span><br><span class="line"></span><br><span class="line">setup.template.enabled: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 开启日志记录</span><br><span class="line"></span><br><span class="line">logging.to_files: true</span><br><span class="line"></span><br><span class="line"># 日志等级</span><br><span class="line"></span><br><span class="line">logging.level: info</span><br><span class="line"></span><br><span class="line"># 日志文件</span><br><span class="line"></span><br><span class="line">logging.files:</span><br><span class="line"></span><br><span class="line">  # 日志位置</span><br><span class="line"></span><br><span class="line">  path: /opt/logs/filebeat/</span><br><span class="line"></span><br><span class="line">  # 日志名字</span><br><span class="line"></span><br><span class="line">  name: filebeat</span><br><span class="line"></span><br><span class="line">  # 日志轮转期限，必须要2~1024</span><br><span class="line"></span><br><span class="line">  keepfiles: 7</span><br><span class="line"></span><br><span class="line">  # 日志轮转权限</span><br><span class="line"></span><br><span class="line">  permissions: 0600</span><br></pre></td></tr></table></figure><h2 id="启动filebeat"><a href="#启动filebeat" class="headerlink" title="启动filebeat"></a>启动filebeat</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/filebeat/filebeat -e -c /opt/filebeat/filebeat.yml -d &quot;publish&quot;</span><br></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><h2 id="写入一条数据"><a href="#写入一条数据" class="headerlink" title="写入一条数据"></a>写入一条数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -I &quot;http://192.168.1.11&quot;</span><br></pre></td></tr></table></figure><h2 id="在kibana中查看"><a href="#在kibana中查看" class="headerlink" title="在kibana中查看"></a>在kibana中查看</h2><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="kibana角色权限相关文档链接"><a href="#kibana角色权限相关文档链接" class="headerlink" title="kibana角色权限相关文档链接"></a>kibana角色权限相关文档链接</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.elastic.co/guide/en/elasticsearch/reference/7.3/security-privileges.html#privileges-list-cluster</span><br></pre></td></tr></table></figure><h2 id="base64加密解密网站链接"><a href="#base64加密解密网站链接" class="headerlink" title="base64加密解密网站链接"></a>base64加密解密网站链接</h2><p><a href="https://tool.oschina.net/encrypt?type=3" target="_blank" rel="noopener">https://tool.oschina.net/encrypt?type=3</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:58 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483826&amp;amp;idx=1&amp;amp;sn=583e9a526050682ae060f601eced917b&amp;amp;chksm=fa769a9ccd01138a8740171769d1149a5df706ab3523eb0cbb5697293bda6e46954641d49f99&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=01245nkmqHupjQF7csKql1i5&amp;amp;sharer_sharetime=1579865464558&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483826&amp;amp;idx=1&amp;amp;sn=583e9a526050682ae060f601eced917b&amp;amp;chksm=fa769a9ccd01138a8740171769d1149a5df706ab3523eb0cbb5697293bda6e46954641d49f99&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=01245nkmqHupjQF7csKql1i5&amp;amp;sharer_sharetime=1579865464558&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;基于ES内置及自定义用户实现kibana和filebeat的认证&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>EFK-4 ElasticSearch集群TLS加密通讯</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-4%EF%BC%9AElasticSearch%E9%9B%86%E7%BE%A4TLS%E5%8A%A0%E5%AF%86%E9%80%9A%E8%AE%AF%20/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-4：ElasticSearch集群TLS加密通讯 /</id>
    <published>2020-04-14T08:54:19.306Z</published>
    <updated>2020-04-14T09:17:20.508Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483822&amp;idx=1&amp;sn=6813b22eb5bd3a727a56e0fb5ba3f7fb&amp;chksm=fa769a80cd011396cb6717124ebb9fb17bbff2f9d1fbcae50578cb2959225055cce0268d3633&amp;mpshare=1&amp;scene=1&amp;srcid=1205igKg8cJK4Owayo9UNt4Q&amp;sharer_sharetime=1575553256278&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483822&amp;idx=1&amp;sn=6813b22eb5bd3a727a56e0fb5ba3f7fb&amp;chksm=fa769a80cd011396cb6717124ebb9fb17bbff2f9d1fbcae50578cb2959225055cce0268d3633&amp;mpshare=1&amp;scene=1&amp;srcid=1205igKg8cJK4Owayo9UNt4Q&amp;sharer_sharetime=1575553256278&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>基于TLS实现ElasticSearch集群加密通讯，为ES集群创建CA、CERT证书，实现ElasticSearch集群之间数据通过TLS进行双向加密交互。</p><a id="more"></a><p><img src="/elk/elk4.png" alt></p><h1 id="Step1-关闭服务"><a href="#Step1-关闭服务" class="headerlink" title="Step1. 关闭服务"></a>Step1. 关闭服务</h1><p>首先，需要停止所有ElasticSearch、kibana、filebeat服务，待证书配置完成后再启动</p><h1 id="Step2-创建CA证书"><a href="#Step2-创建CA证书" class="headerlink" title="Step2. 创建CA证书"></a>Step2. 创建CA证书</h1><p>找任一一台ElasticSearch节点服务器操作即可<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/elasticsearch/</span><br><span class="line"># --days: 表示有效期多久</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-certutil ca --days 3660</span><br></pre></td></tr></table></figure><p></p><p>务必将生成的CA证书，传到安全地方永久存储，因为后期若需要新增ES节点，还会用到该证书<br>请将elastic-stack-ca.p12证书传到所有ES实例服务器上</p><h1 id="Step3-创建CERT证书"><a href="#Step3-创建CERT证书" class="headerlink" title="Step3. 创建CERT证书"></a>Step3. 创建CERT证书</h1><p>按上面表格进入相对应的目录创建CERT证书<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 在ES目录中建立证书目录及给予elasticsearch权限</span><br><span class="line">mkdir -p config/certs;chown elasticsearch.elasticsearch config/certs -R</span><br><span class="line"></span><br><span class="line"># 每一个实例一个证书</span><br><span class="line"># --ca CA证书的文件名，必选参数</span><br><span class="line"># --dns 服务器名，多服务器名用逗号隔开，可选参数</span><br><span class="line"># --ip 服务器IP，多IP用逗号隔开，可选参数</span><br><span class="line"># --out 输出到哪里，可选参数</span><br><span class="line"># --days 有效期多久，可选参数</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 --ip $&#123;本机IP&#125;,127.0.0.1 --out config/certs/cert.p12 --days 3660</span><br><span class="line"># 例如elasticsearch-master-1（192.168.1.31）执行命令：sudo -u elasticsearch ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 --ip 192.168.1.31,127.0.0.1 --out config/certs/cert.p12 --days 3660</span><br></pre></td></tr></table></figure><p></p><p>如果想批量生成CERT证书，请自行查阅附录链接，不过批量生成有时会碰到生成的证书不可用，因此建议一台一台生成</p><h1 id="Step4-创建密钥库"><a href="#Step4-创建密钥库" class="headerlink" title="Step4. 创建密钥库"></a>Step4. 创建密钥库</h1><p>按上面表格进入相对应的目录创建密钥库<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 每一个实例都要操作</span><br><span class="line"># 创建密钥库</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-keystore create</span><br><span class="line"># PKCS＃12文件的密码</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password</span><br><span class="line"># 信任库的密码</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password</span><br></pre></td></tr></table></figure><p></p><p>确认keystore、truststore已录入至密钥库<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch ./bin/elasticsearch-keystore list</span><br></pre></td></tr></table></figure><p></p><h1 id="Step5-删除CA证书"><a href="#Step5-删除CA证书" class="headerlink" title="Step5. 删除CA证书"></a>Step5. 删除CA证书</h1><p>由于上面创建的elastic-stack-ca.p12含有私钥，因此为了安全，建议将该文件删除（请务必提前备份好，因为后期增加节点还会用到）<br>按上面表格进入相对应的目录删除CA证书<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f elastic-stack-ca.p12</span><br></pre></td></tr></table></figure><p></p><h1 id="Step6-修改elasticsearch-yml配置"><a href="#Step6-修改elasticsearch-yml配置" class="headerlink" title="Step6. 修改elasticsearch.yml配置"></a>Step6. 修改elasticsearch.yml配置</h1><p>按上面表格对应的实例配置conf目录下elasticsearch.yml<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 在所有实例上加上以下配置</span><br><span class="line"># 开启transport.ssl认证</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line"># xpack认证方式 full为主机或IP认证及证书认证，certificates为证书认证，不对主机和IP认证，默认为full</span><br><span class="line">xpack.security.transport.ssl.verification_mode: full</span><br><span class="line"># xpack包含私钥和证书的PKCS＃12文件的路径</span><br><span class="line">xpack.security.transport.ssl.keystore.path: certs/cert.p12</span><br><span class="line"># xpack包含要信任的证书的PKCS＃12文件的路径</span><br><span class="line">xpack.security.transport.ssl.truststore.path: certs/cert.p12</span><br></pre></td></tr></table></figure><p></p><h1 id="Step7-启动服务"><a href="#Step7-启动服务" class="headerlink" title="Step7. 启动服务"></a>Step7. 启动服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 开启所有ES实例</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch</span><br><span class="line"></span><br><span class="line"># 开启filebeat</span><br><span class="line">/opt/filebeat/filebeat -e -c /opt/filebeat/filebeat.yml -d &quot;publish&quot;</span><br><span class="line"></span><br><span class="line"># 开启kibana</span><br><span class="line">sudo -u kibana /opt/kibana/bin/kibana -c /opt/kibana/config/kibana.yml</span><br></pre></td></tr></table></figure><h1 id="附-参考文档"><a href="#附-参考文档" class="headerlink" title="附. 参考文档"></a>附. 参考文档</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-tls.html</span><br><span class="line">https://www.elastic.co/guide/en/elasticsearch/reference/7.3/certutil.html</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483822&amp;amp;idx=1&amp;amp;sn=6813b22eb5bd3a727a56e0fb5ba3f7fb&amp;amp;chksm=fa769a80cd011396cb6717124ebb9fb17bbff2f9d1fbcae50578cb2959225055cce0268d3633&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1205igKg8cJK4Owayo9UNt4Q&amp;amp;sharer_sharetime=1575553256278&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483822&amp;amp;idx=1&amp;amp;sn=6813b22eb5bd3a727a56e0fb5ba3f7fb&amp;amp;chksm=fa769a80cd011396cb6717124ebb9fb17bbff2f9d1fbcae50578cb2959225055cce0268d3633&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1205igKg8cJK4Owayo9UNt4Q&amp;amp;sharer_sharetime=1575553256278&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;基于TLS实现ElasticSearch集群加密通讯，为ES集群创建CA、CERT证书，实现ElasticSearch集群之间数据通过TLS进行双向加密交互。&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>EFK-3 ES多实例部署</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-3%EF%BC%9A%20ES%E5%A4%9A%E5%AE%9E%E4%BE%8B%E9%83%A8%E7%BD%B2%20/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-3： ES多实例部署 /</id>
    <published>2020-04-14T08:53:36.243Z</published>
    <updated>2020-04-14T09:17:12.874Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483816&amp;idx=1&amp;sn=bfaf70613bcb775ccf5d40c2871a05a8&amp;chksm=fa769a86cd011390f22ff178071a580a8f17791e57166dfc8463984a5613c11875ef2ebb2ad7&amp;mpshare=1&amp;scene=1&amp;srcid=11253n8AXjLegAeaoHiCssEs&amp;sharer_sharetime=1574686178097&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483816&amp;idx=1&amp;sn=bfaf70613bcb775ccf5d40c2871a05a8&amp;chksm=fa769a86cd011390f22ff178071a580a8f17791e57166dfc8463984a5613c11875ef2ebb2ad7&amp;mpshare=1&amp;scene=1&amp;srcid=11253n8AXjLegAeaoHiCssEs&amp;sharer_sharetime=1574686178097&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>基于ElasticSearch多实例架构，实现资源合理分配、冷热数据分离。<br>ES多实例部署，将不同热度的数据存在不同的磁盘上，实现了数据冷热分离、资源合理分配。<br>在一个集群中部署多个ES实例，来实现资源合理分配。例如data服务器存在SSD与SAS硬盘，可以将热数据存放到SSD，而冷数据存放到SAS，实现数据冷热分离。</p><a id="more"></a><p><img src="/elk/elk3.png" alt></p><h1 id="192-168-1-51-elasticsearch-data部署双实例"><a href="#192-168-1-51-elasticsearch-data部署双实例" class="headerlink" title="192.168.1.51 elasticsearch-data部署双实例"></a>192.168.1.51 elasticsearch-data部署双实例</h1><h2 id="索引迁移"><a href="#索引迁移" class="headerlink" title="索引迁移"></a>索引迁移</h2><p>（此步不能忽略）：将192.168.1.51上的索引放到其它2台data节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.1.52,192.168.1.53&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="确认当前索引存储位置"><a href="#确认当前索引存储位置" class="headerlink" title="确认当前索引存储位置"></a>确认当前索引存储位置</h2><p>确认所有索引不在192.168.1.51节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="停掉192-168-1-51的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"><a href="#停掉192-168-1-51的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘" class="headerlink" title="停掉192.168.1.51的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"></a>停掉192.168.1.51的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 安装包下载和部署请参考第一篇《EFK-1: 快速指南》</span><br><span class="line"></span><br><span class="line">cd /opt/software/</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch /opt/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch-7.3.2 /opt/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch-* -R</span><br><span class="line"></span><br><span class="line">rm -rf /data/SAS/*</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /data/* -R</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/* -R</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"># SAS实例/opt/elasticsearch-SAS/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.51-SAS</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.51</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br><span class="line"></span><br><span class="line"># SSD实例/opt/elasticsearch-SSD/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.51-SSD</span><br><span class="line"></span><br><span class="line">    path.data: /data/SSD</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.51</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9201</span><br><span class="line"></span><br><span class="line">    transport.port: 9301</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br></pre></td></tr></table></figure><h2 id="SAS实例和SSD实例启动方式"><a href="#SAS实例和SSD实例启动方式" class="headerlink" title="SAS实例和SSD实例启动方式"></a>SAS实例和SSD实例启动方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch-SAS/bin/elasticsearch</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch /opt/elasticsearch-SSD/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="确认SAS和SSD已启2实例"><a href="#确认SAS和SSD已启2实例" class="headerlink" title="确认SAS和SSD已启2实例"></a>确认SAS和SSD已启2实例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h1 id="192-168-1-52-elasticsearch-data部署双实例"><a href="#192-168-1-52-elasticsearch-data部署双实例" class="headerlink" title="192.168.1.52 elasticsearch-data部署双实例"></a>192.168.1.52 elasticsearch-data部署双实例</h1><h2 id="索引迁移-1"><a href="#索引迁移-1" class="headerlink" title="索引迁移"></a>索引迁移</h2><p>（此步不能忽略）：将192.168.1.52上的索引放到其它2台data节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.1.51,192.168.1.53&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="确认当前索引存储位置-1"><a href="#确认当前索引存储位置-1" class="headerlink" title="确认当前索引存储位置"></a>确认当前索引存储位置</h2><p>确认所有索引不在192.168.1.52节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="停掉192-168-1-52的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"><a href="#停掉192-168-1-52的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘" class="headerlink" title="停掉192.168.1.52的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"></a>停掉192.168.1.52的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 安装包下载和部署请参考第一篇《EFK-1: 快速指南》</span><br><span class="line"></span><br><span class="line">cd /opt/software/</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch /opt/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch-7.3.2 /opt/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch-* -R</span><br><span class="line"></span><br><span class="line">rm -rf /data/SAS/*</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /data/* -R</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/* -R</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"># SAS实例/opt/elasticsearch-SAS/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.52-SAS</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.52</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br><span class="line"></span><br><span class="line"># SSD实例/opt/elasticsearch-SSD/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.52-SSD</span><br><span class="line"></span><br><span class="line">    path.data: /data/SSD</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.52</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9201</span><br><span class="line"></span><br><span class="line">    transport.port: 9301</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br></pre></td></tr></table></figure><h2 id="SAS实例和SSD实例启动方式-1"><a href="#SAS实例和SSD实例启动方式-1" class="headerlink" title="SAS实例和SSD实例启动方式"></a>SAS实例和SSD实例启动方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch-SAS/bin/elasticsearch</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch /opt/elasticsearch-SSD/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="确认SAS和SSD已启2实例-1"><a href="#确认SAS和SSD已启2实例-1" class="headerlink" title="确认SAS和SSD已启2实例"></a>确认SAS和SSD已启2实例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h1 id="192-168-1-53-elasticsearch-data部署双实例"><a href="#192-168-1-53-elasticsearch-data部署双实例" class="headerlink" title="192.168.1.53 elasticsearch-data部署双实例"></a>192.168.1.53 elasticsearch-data部署双实例</h1><h2 id="索引迁移-2"><a href="#索引迁移-2" class="headerlink" title="索引迁移"></a>索引迁移</h2><p>（此步不能忽略）：一定要做这步，将192.168.1.53上的索引放到其它2台data节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.1.51,192.168.1.52&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="确认当前索引存储位置-2"><a href="#确认当前索引存储位置-2" class="headerlink" title="确认当前索引存储位置"></a>确认当前索引存储位置</h2><p>确认所有索引不在192.168.1.52节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="停掉192-168-1-53的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"><a href="#停掉192-168-1-53的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘" class="headerlink" title="停掉192.168.1.53的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"></a>停掉192.168.1.53的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 安装包下载和部署请参考第一篇《EFK-1: 快速指南》</span><br><span class="line"></span><br><span class="line">cd /opt/software/</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch /opt/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch-7.3.2 /opt/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch-* -R</span><br><span class="line"></span><br><span class="line">rm -rf /data/SAS/*</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /data/* -R</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/* -R</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"># SAS实例/opt/elasticsearch-SAS/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.53-SAS</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.53</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br><span class="line"></span><br><span class="line"># SSD实例/opt/elasticsearch-SSD/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.53-SSD</span><br><span class="line"></span><br><span class="line">    path.data: /data/SSD</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.53</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9201</span><br><span class="line"></span><br><span class="line">    transport.port: 9301</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br></pre></td></tr></table></figure><h2 id="SAS实例和SSD实例启动方式-2"><a href="#SAS实例和SSD实例启动方式-2" class="headerlink" title="SAS实例和SSD实例启动方式"></a>SAS实例和SSD实例启动方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch-SAS/bin/elasticsearch</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch /opt/elasticsearch-SSD/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="确认SAS和SSD已启2实例-2"><a href="#确认SAS和SSD已启2实例-2" class="headerlink" title="确认SAS和SSD已启2实例"></a>确认SAS和SSD已启2实例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><h2 id="将所有索引移到SSD硬盘上"><a href="#将所有索引移到SSD硬盘上" class="headerlink" title="将所有索引移到SSD硬盘上"></a>将所有索引移到SSD硬盘上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 下面的参数会在后面的文章讲解，此处照抄即可</span><br><span class="line"></span><br><span class="line">curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.include._host_ip&quot;: &quot;&quot;,</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.include._host&quot;: &quot;&quot;,</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.include._name&quot;: &quot;&quot;,</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;&quot;,</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.require._name&quot;: &quot;*-SSD&quot;</span><br><span class="line"></span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h2 id="确认所有索引全在SSD硬盘上"><a href="#确认所有索引全在SSD硬盘上" class="headerlink" title="确认所有索引全在SSD硬盘上"></a>确认所有索引全在SSD硬盘上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</span><br></pre></td></tr></table></figure><h2 id="将nginx9月份的日志索引迁移到SAS硬盘上"><a href="#将nginx9月份的日志索引迁移到SAS硬盘上" class="headerlink" title="将nginx9月份的日志索引迁移到SAS硬盘上"></a>将nginx9月份的日志索引迁移到SAS硬盘上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &quot;192.168.1.31:9200/nginx_*_2019.09/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.require._name&quot;: &quot;*-SAS&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h2 id="确认nginx9月份的日志索引迁移到SAS硬盘上"><a href="#确认nginx9月份的日志索引迁移到SAS硬盘上" class="headerlink" title="确认nginx9月份的日志索引迁移到SAS硬盘上"></a>确认nginx9月份的日志索引迁移到SAS硬盘上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards&quot;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483816&amp;amp;idx=1&amp;amp;sn=bfaf70613bcb775ccf5d40c2871a05a8&amp;amp;chksm=fa769a86cd011390f22ff178071a580a8f17791e57166dfc8463984a5613c11875ef2ebb2ad7&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=11253n8AXjLegAeaoHiCssEs&amp;amp;sharer_sharetime=1574686178097&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483816&amp;amp;idx=1&amp;amp;sn=bfaf70613bcb775ccf5d40c2871a05a8&amp;amp;chksm=fa769a86cd011390f22ff178071a580a8f17791e57166dfc8463984a5613c11875ef2ebb2ad7&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=11253n8AXjLegAeaoHiCssEs&amp;amp;sharer_sharetime=1574686178097&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;基于ElasticSearch多实例架构，实现资源合理分配、冷热数据分离。&lt;br&gt;ES多实例部署，将不同热度的数据存在不同的磁盘上，实现了数据冷热分离、资源合理分配。&lt;br&gt;在一个集群中部署多个ES实例，来实现资源合理分配。例如data服务器存在SSD与SAS硬盘，可以将热数据存放到SSD，而冷数据存放到SAS，实现数据冷热分离。&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>EFK-2 ElasticSearch高性能高可用架构</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-2%EF%BC%9AElasticSearch%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-2：ElasticSearch高性能高可用架构/</id>
    <published>2020-04-14T08:53:02.596Z</published>
    <updated>2020-04-14T09:17:15.695Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483811&amp;idx=1&amp;sn=a413dea65f8f64abb24d82feea55db5b&amp;chksm=fa769a8dcd01139b1da8794914e10989c6a39a99971d8013e9d3b26766b80d5833e2fbaf0ab8&amp;mpshare=1&amp;scene=1&amp;srcid=1125tjbylqn3EdoMtaX2p73J&amp;sharer_sharetime=1574686271229&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483811&amp;idx=1&amp;sn=a413dea65f8f64abb24d82feea55db5b&amp;chksm=fa769a8dcd01139b1da8794914e10989c6a39a99971d8013e9d3b26766b80d5833e2fbaf0ab8&amp;mpshare=1&amp;scene=1&amp;srcid=1125tjbylqn3EdoMtaX2p73J&amp;sharer_sharetime=1574686271229&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>阐述了EFK的data/ingest/master角色的用途及分别部署三节点，在实现性能最大化的同时保障高可用</p><a id="more"></a><p><img src="/elk/elk2.png" alt></p><h1 id="elasticsearch-data"><a href="#elasticsearch-data" class="headerlink" title="elasticsearch-data"></a>elasticsearch-data</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>3台均执行相同的安装步骤<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/elasticsearch</span><br><span class="line"></span><br><span class="line">useradd elasticsearch -d /opt/elasticsearch -s /sbin/nologin</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch -R</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/elasticsearch -R</span><br><span class="line"></span><br><span class="line"># 数据盘需要elasticsearch写权限</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /data/SAS -R</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 限制一个进程可以拥有的VMA(虚拟内存区域)的数量要超过262144，不然elasticsearch会报max virtual memory areas vm.max_map_count [65535] is too low, increase to at least [262144]</span><br><span class="line"></span><br><span class="line">echo &quot;vm.max_map_count = 655350&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p></p><h2 id="elasticsearch-data配置"><a href="#elasticsearch-data配置" class="headerlink" title="elasticsearch-data配置"></a>elasticsearch-data配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.51 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.51</span><br><span class="line"></span><br><span class="line">    # 数据盘位置，如果有多个硬盘位置，用&quot;,&quot;隔开</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.51</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 关闭ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    # 开启data功能</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"># 192.168.1.52 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.52</span><br><span class="line"></span><br><span class="line">    # 数据盘位置，如果有多个硬盘位置，用&quot;,&quot;隔开</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.52</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 关闭ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    # 开启data功能</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"># 192.168.1.53 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.53</span><br><span class="line"></span><br><span class="line">    # 数据盘位置，如果有多个硬盘位置，用&quot;,&quot;隔开</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.53</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 关闭ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    # 开启data功能</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-data启动"><a href="#elasticsearch-data启动" class="headerlink" title="elasticsearch-data启动"></a>elasticsearch-data启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="elasticsearch集群状态"><a href="#elasticsearch集群状态" class="headerlink" title="elasticsearch集群状态"></a>elasticsearch集群状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/health?v&quot;</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-data状态"><a href="#elasticsearch-data状态" class="headerlink" title="elasticsearch-data状态"></a>elasticsearch-data状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-data参数说明"><a href="#elasticsearch-data参数说明" class="headerlink" title="elasticsearch-data参数说明"></a>elasticsearch-data参数说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">status: green  # 集群健康状态</span><br><span class="line"></span><br><span class="line">node.total: 6  # 有6台机子组成集群</span><br><span class="line"></span><br><span class="line">node.data: 6  # 有6个节点的存储</span><br><span class="line"></span><br><span class="line">node.role: d  # 只拥有data角色</span><br><span class="line"></span><br><span class="line">node.role: i  # 只拥有ingest角色</span><br><span class="line"></span><br><span class="line">node.role: m  # 只拥有master角色</span><br><span class="line"></span><br><span class="line">node.role: mid  # 拥master、ingest、data角色</span><br></pre></td></tr></table></figure><h1 id="elasticsearch-ingest"><a href="#elasticsearch-ingest" class="headerlink" title="elasticsearch-ingest"></a>elasticsearch-ingest</h1><p>新增三台ingest节点加入集群，同时关闭master和data功能</p><h2 id="elasticsearch-ingest安装"><a href="#elasticsearch-ingest安装" class="headerlink" title="elasticsearch-ingest安装"></a>elasticsearch-ingest安装</h2><p>3台es均执行相同的安装步骤<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/elasticsearch</span><br><span class="line"></span><br><span class="line">useradd elasticsearch -d /opt/elasticsearch -s /sbin/nologin</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch -R</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/elasticsearch -R</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 限制一个进程可以拥有的VMA(虚拟内存区域)的数量要超过262144，不然elasticsearch会报max virtual memory areas vm.max_map_count [65535] is too low, increase to at least [262144]</span><br><span class="line"></span><br><span class="line">echo &quot;vm.max_map_count = 655350&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p></p><h2 id="elasticsearch-ingest配置"><a href="#elasticsearch-ingest配置" class="headerlink" title="elasticsearch-ingest配置"></a>elasticsearch-ingest配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.41 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.41</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.41</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 开启ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: true</span><br><span class="line"></span><br><span class="line">    # 关闭data功能</span><br><span class="line"></span><br><span class="line">    node.data: false</span><br><span class="line"></span><br><span class="line"># 192.168.1.42 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.42</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.42</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 开启ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: true</span><br><span class="line"></span><br><span class="line">    # 关闭data功能</span><br><span class="line"></span><br><span class="line">    node.data: false</span><br><span class="line"></span><br><span class="line"># 192.168.1.43 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.43</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.43</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 开启ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: true</span><br><span class="line"></span><br><span class="line">    # 关闭data功能</span><br><span class="line"></span><br><span class="line">    node.data: false</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-ingest启动"><a href="#elasticsearch-ingest启动" class="headerlink" title="elasticsearch-ingest启动"></a>elasticsearch-ingest启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="elasticsearch集群状态-1"><a href="#elasticsearch集群状态-1" class="headerlink" title="elasticsearch集群状态"></a>elasticsearch集群状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/health?v&quot;</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-ingest状态"><a href="#elasticsearch-ingest状态" class="headerlink" title="elasticsearch-ingest状态"></a>elasticsearch-ingest状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-ingest参数说明"><a href="#elasticsearch-ingest参数说明" class="headerlink" title="elasticsearch-ingest参数说明"></a>elasticsearch-ingest参数说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    status: green  # 集群健康状态</span><br><span class="line"></span><br><span class="line">    node.total: 9  # 有9台机子组成集群</span><br><span class="line"></span><br><span class="line">    node.data: 6  # 有6个节点的存储</span><br><span class="line"></span><br><span class="line">    node.role: d  # 只拥有data角色</span><br><span class="line"></span><br><span class="line">    node.role: i  # 只拥有ingest角色</span><br><span class="line"></span><br><span class="line">    node.role: m  # 只拥有master角色</span><br><span class="line"></span><br><span class="line">    node.role: mid  # 拥master、ingest、data角色</span><br><span class="line">```            </span><br><span class="line"></span><br><span class="line"># elasticsearch-master</span><br><span class="line">首先，将上一篇《EFK-1》中部署的3台es（192.168.1.31、192.168.1.32、192.168.1.33）改成只有master的功能， 因此需要先将这3台上的索引数据迁移到本次所做的data节点中</span><br><span class="line">## 索引迁移</span><br><span class="line">一定要做这步，将之前的索引放到data节点上</span><br></pre></td></tr></table></figure><pre><code>curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;{  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.1.51,192.168.1.52,192.168.1.53&quot;}&apos;</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 确认当前索引存储位置</span><br><span class="line">确认所有索引不在192.168.1.31、192.168.1.32、192.168.1.33节点上</span><br></pre></td></tr></table></figure><pre><code>curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## elasticsearch-master配置</span><br><span class="line">注意事项：修改配置，重启进程，需要一台一台执行，要确保第一台成功后，再执行下一台。</span><br></pre></td></tr></table></figure><h1 id="192-168-1-31-opt-elasticsearch-config-elasticsearch-yml"><a href="#192-168-1-31-opt-elasticsearch-config-elasticsearch-yml" class="headerlink" title="192.168.1.31 /opt/elasticsearch/config/elasticsearch.yml"></a>192.168.1.31 /opt/elasticsearch/config/elasticsearch.yml</h1><pre><code>cluster.name: my-applicationnode.name: 192.168.1.31path.logs: /opt/logs/elasticsearchnetwork.host: 192.168.1.31discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;#开启master功能node.master: true#关闭ingest功能node.ingest: false#关闭data功能node.data: false</code></pre><h1 id="192-168-1-32-opt-elasticsearch-config-elasticsearch-yml"><a href="#192-168-1-32-opt-elasticsearch-config-elasticsearch-yml" class="headerlink" title="192.168.1.32 /opt/elasticsearch/config/elasticsearch.yml"></a>192.168.1.32 /opt/elasticsearch/config/elasticsearch.yml</h1><pre><code>cluster.name: my-applicationnode.name: 192.168.1.32path.logs: /opt/logs/elasticsearchnetwork.host: 192.168.1.32discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;#开启master功能node.master: true#关闭ingest功能node.ingest: false#关闭data功能node.data: false</code></pre><h1 id="192-168-1-33-opt-elasticsearch-config-elasticsearch-yml"><a href="#192-168-1-33-opt-elasticsearch-config-elasticsearch-yml" class="headerlink" title="192.168.1.33 /opt/elasticsearch/config/elasticsearch.yml"></a>192.168.1.33 /opt/elasticsearch/config/elasticsearch.yml</h1><pre><code>cluster.name: my-applicationnode.name: 192.168.1.33path.logs: /opt/logs/elasticsearchnetwork.host: 192.168.1.33discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;#开启master功能node.master: true#关闭ingest功能node.ingest: false#关闭data功能node.data: false</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">## elasticsearch集群状态</span><br></pre></td></tr></table></figure><pre><code>curl &quot;http://192.168.1.31:9200/_cat/health?v&quot;</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">## elasticsearch-master状态</span><br></pre></td></tr></table></figure><pre><code>curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</code></pre><p><code>`</code></p><p><strong>至此，当node.role里所有服务器都不再出现“mid”，则表示一切顺利完成。</strong></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483811&amp;amp;idx=1&amp;amp;sn=a413dea65f8f64abb24d82feea55db5b&amp;amp;chksm=fa769a8dcd01139b1da8794914e10989c6a39a99971d8013e9d3b26766b80d5833e2fbaf0ab8&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1125tjbylqn3EdoMtaX2p73J&amp;amp;sharer_sharetime=1574686271229&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483811&amp;amp;idx=1&amp;amp;sn=a413dea65f8f64abb24d82feea55db5b&amp;amp;chksm=fa769a8dcd01139b1da8794914e10989c6a39a99971d8013e9d3b26766b80d5833e2fbaf0ab8&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1125tjbylqn3EdoMtaX2p73J&amp;amp;sharer_sharetime=1574686271229&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;阐述了EFK的data/ingest/master角色的用途及分别部署三节点，在实现性能最大化的同时保障高可用&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>EFK-1 快速指南</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-1%EF%BC%9A%E5%BF%AB%E9%80%9F%E6%8C%87%E5%8D%97/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-1：快速指南/</id>
    <published>2020-04-14T08:52:17.408Z</published>
    <updated>2020-04-14T09:16:58.163Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483801&amp;idx=1&amp;sn=11fee5756c8770688238624802ac51ea&amp;chksm=fa769ab7cd0113a1ad19241290abe374b857227eebe989b3ba6b671b1eca855d380b76eeedde&amp;mpshare=1&amp;scene=1&amp;srcid=1125q5BPyFOD05H2trj4UdOf&amp;sharer_sharetime=1574686325386&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483801&amp;idx=1&amp;sn=11fee5756c8770688238624802ac51ea&amp;chksm=fa769ab7cd0113a1ad19241290abe374b857227eebe989b3ba6b671b1eca855d380b76eeedde&amp;mpshare=1&amp;scene=1&amp;srcid=1125q5BPyFOD05H2trj4UdOf&amp;sharer_sharetime=1574686325386&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#</a></p><p>阐述了EFK的安装部署，其中ES的架构为三节点，即master、ingest、data角色同时部署在三台服务器上。</p><a id="more"></a><p><img src="/elk/elk1.png" alt></p><h1 id="elasticsearch安装：3台es均执行相同的安装步骤"><a href="#elasticsearch安装：3台es均执行相同的安装步骤" class="headerlink" title="elasticsearch安装：3台es均执行相同的安装步骤"></a>elasticsearch安装：3台es均执行相同的安装步骤</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/software &amp;&amp; cd /opt/software</span><br><span class="line"></span><br><span class="line">wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/elasticsearch</span><br><span class="line"></span><br><span class="line">useradd elasticsearch -d /opt/elasticsearch -s /sbin/nologin</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch -R</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/elasticsearch -R</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 限制一个进程可以拥有的VMA(虚拟内存区域)的数量要超过262144，不然elasticsearch会报max virtual memory areas vm.max_map_count [65535] is too low, increase to at least [262144]</span><br><span class="line"></span><br><span class="line">echo &quot;vm.max_map_count = 655350&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><h1 id="filebeat安装"><a href="#filebeat安装" class="headerlink" title="filebeat安装"></a>filebeat安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/software &amp;&amp; cd /opt/software</span><br><span class="line"></span><br><span class="line">wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/filebeat/</span><br><span class="line"></span><br><span class="line">tar -zxvf filebeat-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv filebeat-7.3.2-linux-x86_64 /opt/filebeat</span><br></pre></td></tr></table></figure><h1 id="kibana安装"><a href="#kibana安装" class="headerlink" title="kibana安装"></a>kibana安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/software &amp;&amp; cd /opt/software</span><br><span class="line"></span><br><span class="line">wget https://artifacts.elastic.co/downloads/kibana/kibana-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf kibana-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv kibana-7.3.2-linux-x86_64 /opt/kibana</span><br><span class="line"></span><br><span class="line">useradd kibana -d /opt/kibana -s /sbin/nologin</span><br><span class="line"></span><br><span class="line">chown kibana.kibana /opt/kibana -R</span><br></pre></td></tr></table></figure><h1 id="nginx安装"><a href="#nginx安装" class="headerlink" title="nginx安装"></a>nginx安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 只在192.168.1.11安装</span><br><span class="line"></span><br><span class="line">yum install -y nginx</span><br><span class="line"></span><br><span class="line">/usr/sbin/nginx -c /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><h1 id="elasticsearch配置"><a href="#elasticsearch配置" class="headerlink" title="elasticsearch配置"></a>elasticsearch配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.31 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    # 集群名字</span><br><span class="line"></span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点名字</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.31</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 日志位置</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问IP</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.31</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问</span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点运输端口</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 集群中其他主机的列表</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 首次启动全新的Elasticsearch集群时，在第一次选举中便对其票数进行计数的master节点的集合</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 启用跨域资源共享</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 只要有2台数据或主节点已加入集群，就可以恢复</span><br><span class="line"></span><br><span class="line">    gateway.recover_after_nodes: 2</span><br><span class="line"></span><br><span class="line"># 192.168.1.32 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    # 集群名字</span><br><span class="line"></span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点名字</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.32</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 日志位置</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问IP</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.32</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问</span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点运输端口</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 集群中其他主机的列表</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 首次启动全新的Elasticsearch集群时，在第一次选举中便对其票数进行计数的master节点的集合</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 启用跨域资源共享</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 只要有2台数据或主节点已加入集群，就可以恢复</span><br><span class="line"></span><br><span class="line">    gateway.recover_after_nodes: 2</span><br><span class="line"></span><br><span class="line"># 192.168.1.33 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    # 集群名字</span><br><span class="line"></span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点名字</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.33</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 日志位置</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问IP</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.33</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问</span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点运输端口</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 集群中其他主机的列表</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 首次启动全新的Elasticsearch集群时，在第一次选举中便对其票数进行计数的master节点的集合</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 启用跨域资源共享</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 只要有2台数据或主节点已加入集群，就可以恢复</span><br><span class="line"></span><br><span class="line">    gateway.recover_after_nodes: 2</span><br></pre></td></tr></table></figure><h1 id="filebeat配置"><a href="#filebeat配置" class="headerlink" title="filebeat配置"></a>filebeat配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.11 /opt/filebeat/filebeat.yml</span><br><span class="line">    # 文件输入</span><br><span class="line"></span><br><span class="line">    filebeat.inputs:</span><br><span class="line"></span><br><span class="line">      # 文件输入类型</span><br><span class="line"></span><br><span class="line">      - type: log</span><br><span class="line"></span><br><span class="line">        # 开启加载</span><br><span class="line"></span><br><span class="line">        enabled: true</span><br><span class="line"></span><br><span class="line">        # 文件位置</span><br><span class="line"></span><br><span class="line">        paths:</span><br><span class="line"></span><br><span class="line">          - /var/log/nginx/access.log</span><br><span class="line"></span><br><span class="line">        # 自定义参数</span><br><span class="line"></span><br><span class="line">        fields:</span><br><span class="line"></span><br><span class="line">          type: nginx_access  # 类型是nginx_access,和上面fields.type是一致的</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 输出至elasticsearch</span><br><span class="line"></span><br><span class="line">    output.elasticsearch:</span><br><span class="line"></span><br><span class="line">      # elasticsearch集群</span><br><span class="line"></span><br><span class="line">      hosts: [&quot;http://192.168.1.31:9200&quot;,</span><br><span class="line"></span><br><span class="line">              &quot;http://192.168.1.32:9200&quot;,</span><br><span class="line"></span><br><span class="line">              &quot;http://192.168.1.33:9200&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      # 索引配置</span><br><span class="line"></span><br><span class="line">      indices:</span><br><span class="line"></span><br><span class="line">        # 索引名</span><br><span class="line"></span><br><span class="line">        - index: &quot;nginx_access_%&#123;+yyy.MM&#125;&quot;</span><br><span class="line"></span><br><span class="line">          # 当类型是nginx_access时使用此索引</span><br><span class="line"></span><br><span class="line">          when.equals:</span><br><span class="line"></span><br><span class="line">            fields.type: &quot;nginx_access&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭自带模板</span><br><span class="line"></span><br><span class="line">    setup.template.enabled: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 开启日志记录</span><br><span class="line"></span><br><span class="line">    logging.to_files: true</span><br><span class="line"></span><br><span class="line">    # 日志等级</span><br><span class="line"></span><br><span class="line">    logging.level: info</span><br><span class="line"></span><br><span class="line">    # 日志文件</span><br><span class="line"></span><br><span class="line">    logging.files:</span><br><span class="line"></span><br><span class="line">      # 日志位置</span><br><span class="line"></span><br><span class="line">      path: /opt/logs/filebeat/</span><br><span class="line"></span><br><span class="line">      # 日志名字</span><br><span class="line"></span><br><span class="line">      name: filebeat</span><br><span class="line"></span><br><span class="line">      # 日志轮转期限，必须要2~1024</span><br><span class="line"></span><br><span class="line">      keepfiles: 7</span><br><span class="line"></span><br><span class="line">      # 日志轮转权限</span><br><span class="line"></span><br><span class="line">      permissions: 0600</span><br></pre></td></tr></table></figure><h1 id="kibana配置"><a href="#kibana配置" class="headerlink" title="kibana配置"></a>kibana配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.21 /opt/kibana/config/kibana.yml</span><br><span class="line">    # 本节点访问端口</span><br><span class="line"></span><br><span class="line">    server.port: 5601</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点IP</span><br><span class="line"></span><br><span class="line">    server.host: &quot;192.168.1.21&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点名字</span><br><span class="line"></span><br><span class="line">    server.name: &quot;192.168.1.21&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # elasticsearch集群IP</span><br><span class="line"></span><br><span class="line">    elasticsearch.hosts: [&quot;http://192.168.1.31:9200&quot;,</span><br><span class="line"></span><br><span class="line">                          &quot;http://192.168.1.32:9200&quot;,</span><br><span class="line"></span><br><span class="line">                          &quot;http://192.168.1.33:9200&quot;]</span><br></pre></td></tr></table></figure><h1 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># elasticsearch启动（3台es均启动）</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch /opt/elasticsearch/bin/elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># filebeat启动</span><br><span class="line"></span><br><span class="line">/opt/filebeat/filebeat -e -c /opt/filebeat/filebeat.yml -d &quot;publish&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># kibana启动</span><br><span class="line"></span><br><span class="line">sudo -u kibana /opt/kibana/bin/kibana -c /opt/kibana/config/kibana.yml</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483801&amp;amp;idx=1&amp;amp;sn=11fee5756c8770688238624802ac51ea&amp;amp;chksm=fa769ab7cd0113a1ad19241290abe374b857227eebe989b3ba6b671b1eca855d380b76eeedde&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1125q5BPyFOD05H2trj4UdOf&amp;amp;sharer_sharetime=1574686325386&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483801&amp;amp;idx=1&amp;amp;sn=11fee5756c8770688238624802ac51ea&amp;amp;chksm=fa769ab7cd0113a1ad19241290abe374b857227eebe989b3ba6b671b1eca855d380b76eeedde&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1125q5BPyFOD05H2trj4UdOf&amp;amp;sharer_sharetime=1574686325386&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#&lt;/a&gt;&lt;/p&gt;&lt;p&gt;阐述了EFK的安装部署，其中ES的架构为三节点，即master、ingest、data角色同时部署在三台服务器上。&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>基于ELK Nginx日志分析</title>
    <link href="https://yongnights.github.io/2020/04/14/%E5%9F%BA%E4%BA%8EELK%20Nginx%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%20/"/>
    <id>https://yongnights.github.io/2020/04/14/基于ELK Nginx日志分析 /</id>
    <published>2020-04-14T03:13:53.149Z</published>
    <updated>2020-04-14T03:28:03.059Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 11:28:55 GMT+0800 (GMT+08:00) --><h1 id="配置Nginx-日志"><a href="#配置Nginx-日志" class="headerlink" title="配置Nginx 日志"></a>配置Nginx 日志</h1><p>Nginx 默认的access 日志为log格式，需要logstash 进行正则匹配和清洗处理，从而极大的增加了logstash的压力 所以我们Nginx 的日志修改为json 格式 。<br>Nginx access 日志和 Nginx error 日志<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    log_format  json  &apos;&#123;&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos;</span><br><span class="line">                      &apos;&quot;server_addr&quot;:&quot;$server_addr&quot;,&apos;</span><br><span class="line">                      &apos;&quot;hostname&quot;:&quot;$hostname&quot;,&apos;</span><br><span class="line">                      &apos;&quot;remote_add&quot;:&quot;$remote_addr&quot;,&apos;</span><br><span class="line">                      &apos;&quot;request_method&quot;:&quot;$request_method&quot;,&apos;</span><br><span class="line">                      &apos;&quot;scheme&quot;:&quot;$scheme&quot;,&apos;</span><br><span class="line">                      &apos;&quot;server_name&quot;:&quot;$server_name&quot;,&apos;</span><br><span class="line">                      &apos;&quot;http_referer&quot;:&quot;$http_referer&quot;,&apos;</span><br><span class="line">                      &apos;&quot;request_uri&quot;:&quot;$request_uri&quot;,&apos;</span><br><span class="line">                      &apos;&quot;args&quot;:&quot;$args&quot;,&apos;</span><br><span class="line">                      &apos;&quot;body_bytes_sent&quot;:$body_bytes_sent,&apos;</span><br><span class="line">                      &apos;&quot;status&quot;: $status,&apos;</span><br><span class="line">                      &apos;&quot;request_time&quot;:$request_time,&apos;</span><br><span class="line">                      &apos;&quot;upstream_response_time&quot;:&quot;$upstream_response_time&quot;,&apos;</span><br><span class="line">                      &apos;&quot;upstream_addr&quot;:&quot;$upstream_addr&quot;,&apos;</span><br><span class="line">                      &apos;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&apos;</span><br><span class="line">                      &apos;&quot;https&quot;:&quot;$https&quot;&apos;</span><br><span class="line">                      &apos;&#125;&apos;;</span><br><span class="line">    access_log  /var/log/nginx/access.log json;</span><br></pre></td></tr></table></figure><p></p><a id="more"></a><p>针对不同的虚拟主机配置Nginx日志<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">access_log  /var/log/nginx/80.access.log json;</span><br><span class="line">error_log  /var/log/nginx/80.error.log error;</span><br><span class="line">access_log  /var/log/nginx/8001.access.log json;</span><br><span class="line">error_log  /var/log/nginx/8001.error.log error;</span><br></pre></td></tr></table></figure><p></p><h1 id="Nginx-error-log-类型"><a href="#Nginx-error-log-类型" class="headerlink" title="Nginx error_log 类型"></a>Nginx error_log 类型</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ debug | info | notice | warn | error | crit ]</span><br></pre></td></tr></table></figure><p>例如：error_log /var/log/nginx/8001.error.log crit;<br>解释：日志文件存储在/var/log/nginx/8001.error.log 文件中，错误类型为 crit ，也就是记录最少错误信息（debug最详细 crit最少）；</p><h1 id="filebeat-配置"><a href="#filebeat-配置" class="headerlink" title="filebeat 配置"></a>filebeat 配置</h1><p>针对<em>.access.log 和 </em>.error.log 的日志进行不同的标签封装<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@elk-node1 nginx]# egrep -v &quot;*#|^$&quot; /etc/filebeat/filebeat.yml </span><br><span class="line">filebeat.inputs:</span><br><span class="line">- type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/nginx/*.access.log</span><br><span class="line">  tags: [&quot;nginx.access&quot;]</span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/nginx/*.error.log</span><br><span class="line">  tags: [&quot;nginx.error&quot;]</span><br><span class="line">filebeat.config.modules:</span><br><span class="line">  path: $&#123;path.config&#125;/modules.d/*.yml</span><br><span class="line">  reload.enabled: false</span><br><span class="line">setup.template.settings:</span><br><span class="line">  index.number_of_shards: 3</span><br><span class="line">setup.kibana:</span><br><span class="line">output.logstash:</span><br><span class="line">  hosts: [&quot;192.168.99.186:6044&quot;]</span><br><span class="line">processors:</span><br><span class="line">  - add_host_metadata: ~</span><br><span class="line">  - add_cloud_metadata: ~</span><br><span class="line">``` </span><br><span class="line"># logstash 配置</span><br><span class="line">## 查看logstash 安装已经安装插件</span><br></pre></td></tr></table></figure><p></p><p>/usr/share/logstash/bin/logstash-plugin list<br>[root@elk-node2 ~]#/usr/share/logstash/bin/logstash-plugin list |grep geoip<br>logstash-filter-geoip<br>/usr/share/logstash/bin/logstash-plugin install logstash-filter-geoip<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## Nginx 日志清洗规则</span><br></pre></td></tr></table></figure><p></p><p>[root@elk-node2 ~]# cat /etc/logstash/conf.d/nginx.conf<br>input {<br>beats {<br>port =&gt; 6044<br>}</p><p>}</p><p>filter {<br>if “nginx.access” in [tags] {<br>json {<br>source =&gt; “message”<br>remove_field =&gt; “message”<br>}<br>date {<br>match =&gt; [“timestamp” , “dd/MMM/YYYY:HH:mm:ss Z” ]<br>}<br>useragent {<br>target =&gt; “agent”<br>source =&gt; “http_user_agent”<br>}<br>geoip {</p><pre><code>         #target =&gt; &quot;geoip&quot;         source =&gt; &quot;remote_add&quot;         fields =&gt; [&quot;city_name&quot;, &quot;country_code2&quot;, &quot;country_name&quot;, &quot;region_name&quot;,&quot;longitude&quot;,&quot;latitude&quot;,&quot;ip&quot;]         add_field =&gt; [&quot;[geoip][coordinates]&quot;,&quot;%{[geoip][longitude]}&quot;]         add_field =&gt; [&quot;[geoip][coordinates]&quot;,&quot;%{[geoip][latitude]}&quot;]    }    mutate {        convert =&gt; [&quot;[geoip][coordinates]&quot;,&quot;float&quot;]     }}</code></pre><p>else if “nginx.error” in [tags] {<br>mutate {<br>remove_field =&gt; [“@timestamp”]<br>}<br>grok {<br>match =&gt; {“message” =&gt; “(?<datetime>%{YEAR}[./-]%{MONTHNUM}[./-]%{MONTHDAY}[- ]%{TIME}) [%{LOGLEVEL:severity}] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?&lt;real_ip&gt;%{IP}|%{HOSTNAME}))(?:, server: %{IPORHOST:domain}?)(?:, request: %{QS:request})?(?:, upstream: (?<upstream>\”%{URI}\”|%{QS}))?(?:, host: %{QS:request_host})?(?:, referrer: \”%{URI:referrer}\”)?”}<br>}<br>date {<br>match =&gt; [“datetime”, “yyyy/MM/dd HH:mm:ss”]<br>target =&gt; “@timestamp”<br>}<br>mutate {<br>remove_field =&gt; [“message”]<br>}<br>}<br>}</upstream></datetime></p><p>output{<br>stdout{codec =&gt; rubydebug}</p><pre><code>if &quot;nginx.access&quot; in [tags]{    elasticsearch{        index =&gt; &quot;logstash-nginx.access-%{+YYYY.MM.dd}&quot;        hosts =&gt; [&quot;192.168.99.186:9200&quot;]    }}else if &quot;nginx.error&quot; in [tags]{    elasticsearch {        index =&gt; &quot;nginx.error-%{+YYYY.MM.dd}&quot;        hosts =&gt; [&quot;192.168.99.186:9200&quot;]    }}</code></pre><p>}<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">注意：source 可以是任意处理后的字段，需要注意的是 IP 必须是公网 IP，否则logstash 的返回的geoip字段为空</span><br><span class="line"></span><br><span class="line">## Logstash解析</span><br><span class="line">Logstash 分为 Input、Output、Filter、Codec 等多种plugins。</span><br><span class="line">- Input：数据的输入源也支持多种插件，如elk官网的beats、file、graphite、http、kafka、redis、exec等等。</span><br><span class="line">- Output：数据的输出目的也支持多种插件，如本文的elasticsearch，当然这可能也是最常用的一种输出。以及exec、stdout终端、graphite、http、zabbix、nagios、redmine等等。</span><br><span class="line">- Filter：使用过滤器根据日志事件的特征，对数据事件进行处理过滤后，在输出。支持grok、date、geoip、mutate、ruby、json、kv、csv、checksum、dns、drop、xml等等。</span><br><span class="line">- Codec：编码插件，改变事件数据的表示方式，它可以作为对输入或输出运行该过滤。和其它产品结合，如rubydebug、graphite、fluent、nmap等等。</span><br><span class="line"></span><br><span class="line">## 配置文件的含义</span><br><span class="line">input</span><br><span class="line">filebeat  传入</span><br><span class="line"></span><br><span class="line">filter</span><br><span class="line">grok：数据结构化转换工具</span><br><span class="line">match：匹配条件格式</span><br><span class="line">geoip：该过滤器从geoip中匹配ip字段，显示该ip的地理位置</span><br><span class="line">source：ip来源字段　 </span><br><span class="line">target：指定插入的logstash字段目标存储为geoip　 </span><br><span class="line">add_field: 增加的字段，坐标经度　 </span><br><span class="line">add_field: 增加的字段，坐标纬度</span><br><span class="line">mutate：数据的修改、删除、类型转换　 </span><br><span class="line">convert：将坐标转为float类型　 </span><br><span class="line">replace：替换一个字段　 </span><br><span class="line">remove_field：移除message 的内容，因为数据已经过滤了一份，这里不必在用到该字段了，不然会相当于存两份　 </span><br><span class="line">date: 时间处理，该插件很实用，主要是用你日志文件中事件的事件来对timestamp进行转换　 </span><br><span class="line">match：匹配到timestamp字段后，修改格式为`dd/MMM/yyyy:HH:mm:ss Z` </span><br><span class="line">mutate：数据修改　 </span><br><span class="line">remove_field：移除timestamp字段。 </span><br><span class="line"></span><br><span class="line">output</span><br><span class="line">elasticsearch：输出到es中</span><br><span class="line">host：es的主机ip＋端口或者es 的FQDN＋端口</span><br><span class="line">index：为日志创建索引logstash-nginx-access-*，这里也就是kibana那里添加索引时的名称</span><br><span class="line"></span><br><span class="line"># Kibana 配置</span><br><span class="line">注意：默认配置中Kibana的访问日志会记录在/var/log/message 中，使用logging.quiet参数关闭日志</span><br></pre></td></tr></table></figure><p></p><p>[root@elk-node1 nginx]# egrep -v “*#|^$” /etc/kibana/kibana.yml<br>server.port: 5601<br>server.host: “192.168.99.185”<br>elasticsearch.hosts: [“<a href="http://192.168.99.185:9200&quot;]" target="_blank" rel="noopener">http://192.168.99.185:9200&quot;]</a><br>kibana.index: “.kibana”<br>logging.quiet: true<br>i18n.locale: “zh-CN”<br>tilemap.url: ‘<a href="http://webrd02.is.autonavi.com/appmaptile?lang=zh_cn&amp;size=1&amp;scale=1&amp;style=7&amp;x={x}&amp;y={y}&amp;z={z}&#39;" target="_blank" rel="noopener">http://webrd02.is.autonavi.com/appmaptile?lang=zh_cn&amp;size=1&amp;scale=1&amp;style=7&amp;x={x}&amp;y={y}&amp;z={z}&#39;</a><br><code>`</code><br>配置“tilemap.url:”参数使Kibana使用高德地图</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 11:28:55 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;配置Nginx-日志&quot;&gt;&lt;a href=&quot;#配置Nginx-日志&quot; class=&quot;headerlink&quot; title=&quot;配置Nginx 日志&quot;&gt;&lt;/a&gt;配置Nginx 日志&lt;/h1&gt;&lt;p&gt;Nginx 默认的access 日志为log格式，需要logstash 进行正则匹配和清洗处理，从而极大的增加了logstash的压力 所以我们Nginx 的日志修改为json 格式 。&lt;br&gt;Nginx access 日志和 Nginx error 日志&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;http &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    include       /etc/nginx/mime.types;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    default_type  application/octet-stream;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    log_format  json  &amp;apos;&amp;#123;&amp;quot;@timestamp&amp;quot;:&amp;quot;$time_iso8601&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;server_addr&amp;quot;:&amp;quot;$server_addr&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;hostname&amp;quot;:&amp;quot;$hostname&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;remote_add&amp;quot;:&amp;quot;$remote_addr&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;request_method&amp;quot;:&amp;quot;$request_method&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;scheme&amp;quot;:&amp;quot;$scheme&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;server_name&amp;quot;:&amp;quot;$server_name&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;http_referer&amp;quot;:&amp;quot;$http_referer&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;request_uri&amp;quot;:&amp;quot;$request_uri&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;args&amp;quot;:&amp;quot;$args&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;body_bytes_sent&amp;quot;:$body_bytes_sent,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;status&amp;quot;: $status,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;request_time&amp;quot;:$request_time,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;upstream_response_time&amp;quot;:&amp;quot;$upstream_response_time&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;upstream_addr&amp;quot;:&amp;quot;$upstream_addr&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;http_user_agent&amp;quot;:&amp;quot;$http_user_agent&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;https&amp;quot;:&amp;quot;$https&amp;quot;&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;#125;&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    access_log  /var/log/nginx/access.log json;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="nginx" scheme="https://yongnights.github.io/categories/elk/nginx/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="nginx" scheme="https://yongnights.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Linux日志切割方法[Logrotate、python、shell实现方式]</title>
    <link href="https://yongnights.github.io/2020/04/10/Linux%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E6%96%B9%E6%B3%95%5BLogrotate%E3%80%81python%E3%80%81shell%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%5D/"/>
    <id>https://yongnights.github.io/2020/04/10/Linux日志切割方法[Logrotate、python、shell实现方式]/</id>
    <published>2020-04-10T10:05:58.456Z</published>
    <updated>2020-04-10T10:06:45.966Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Apr 10 2020 18:07:52 GMT+0800 (GMT+08:00) --><p><strong>Linux日志切割方法[Logrotate、python、shell实现方式]</strong></p><p>​ 对于Linux系统安全来说，日志文件是极其重要的工具。不知为何，我发现很多运维同学的服务器上都运行着一些诸如每天切分Nginx日志之类的cron脚本，大家似乎遗忘了Logrotate，争相发明自己的轮子，这真是让人沮丧啊！就好比明明身边躺着现成的性感美女，大家却忙着自娱自乐，罪过！logrotate程序是一个日志文件管理工具。用于分割日志文件，删除旧的日志文件，并创建新的日志文件，起到“转储”作用。可以节省磁盘空间。下面就对logrotate日志轮转操作做一梳理记录。</p><p><strong>1、什么是轮转？</strong></p><p><strong>日志轮循（轮转）：日志轮转，切割，备份，归档</strong></p><h2 id="2、为什么需要轮转？"><a href="#2、为什么需要轮转？" class="headerlink" title="2、为什么需要轮转？"></a><strong>2、为什么需要轮转？</strong></h2><p>☆ 避免日志过大占满/var/log的文件系统</p><p>☆ 方便日志查看 ☆ 将丢弃系统中最旧的日志文件，以节省空间 ☆ 日志轮转的程序是logrotate</p><p>☆ logrotate本身不是系统守护进程，它是通过计划任务crond每天执行</p><a id="more"></a><h2 id="3、安装与配置logrotate"><a href="#3、安装与配置logrotate" class="headerlink" title="3、安装与配置logrotate"></a><strong>3、安装与配置logrotate</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install logrotate -y</span><br></pre></td></tr></table></figure><p>3.1、配置文件介绍</p><p>Linux系统默认安装logrotate工具，它默认的配置文件在：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>/etc/logrotate.conf</span><br><span class="line"><span class="meta">#</span>/etc/logrotate.d/</span><br></pre></td></tr></table></figure><p>logrotate.conf 是主要的配置文件，logrotate.d 是一个目录，该目录里的所有文件都会被主动的读入/etc/logrotate.conf中执行。另外，如果 /etc/logrotate.d/ 里面的文件中没有设定一些细节，则会以/etc/logrotate.conf这个文件的设定来作为默认值。</p><p>logrotate是基于cron来运行的，其脚本是/etc/cron.daily/logrotate，日志轮转是系统自动完成的。实际运行时，Logrotate会调用配置文件/etc/logrotate.conf。可以在/etc/logrotate.d目录里放置自定义好的配置文件，用来覆盖Logrotate的缺省值。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# cat /etc/cron.daily/logrotate</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then </span><br><span class="line">/usr/bin/logger -t logrotate "ALERT exited abnormally with [$EXITVALUE]"</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p><strong>注意：如果等不及cron自动执行日志轮转，想手动强制切割日志，需要加 -f 参数；不过正式执行前最好通过Debug选项来验证一下（-d参数），这对调试也很重要</strong>！</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> /usr/sbin/logrotate -f /etc/logrotate.d/nginx</span><br><span class="line"><span class="meta">#</span> /usr/sbin/logrotate -d -f /etc/logrotate.d/nginx</span><br></pre></td></tr></table></figure><p><strong>logrotate命令格式</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">logrotate [OPTION...] &lt;configfile&gt;</span><br><span class="line">-d, --debug ：debug模式，测试配置文件是否有错误。</span><br><span class="line">-f, --force ：强制转储文件。</span><br><span class="line">-m, --mail=command ：压缩日志后，发送日志到指定邮箱。</span><br><span class="line">-s, --state=statefile ：使用指定的状态文件。</span><br><span class="line">-v, --verbose ：显示转储过程。</span><br></pre></td></tr></table></figure><p><strong>根据日志切割设置进行操作，并显示详细信息</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# /usr/sbin/logrotate -v /etc/logrotate.conf</span><br><span class="line">[root@huanqiu_web1 ~]# /usr/sbin/logrotate -v /etc/logrotate.d/php</span><br></pre></td></tr></table></figure><p><strong>根据日志切割设置进行执行，并显示详细信息,但是不进行具体操作，debug模式</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# /usr/sbin/logrotate -d /etc/logrotate.conf</span><br><span class="line">[root@huanqiu_web1 ~]# /usr/sbin/logrotate -d /etc/logrotate.d/nginx</span><br></pre></td></tr></table></figure><p><strong>查看各log文件的具体执行情况</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@fangfull_web1 ~]# cat /var/lib/logrotate.status</span><br></pre></td></tr></table></figure><h3 id="3-2、logrotate配置文件"><a href="#3-2、logrotate配置文件" class="headerlink" title="3.2、logrotate配置文件"></a>3.2、logrotate配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> vim /etc/logrotate.conf</span><br><span class="line">1 # see "man logrotate" for details</span><br><span class="line">2 # rotate log files weekly</span><br><span class="line">3 weekly</span><br><span class="line">4 # 以7天为一个周期(每周轮转)syslog子配置文件：</span><br><span class="line">5 # keep 4 weeks worth of backlogs</span><br><span class="line">6 rotate 4</span><br><span class="line"><span class="meta">#</span> 一次将存储4个归档日志。对于第五个归档，时间最久的归档将被删除</span><br><span class="line">7 8</span><br><span class="line"><span class="meta">#</span> create new (empty) log files after rotating old ones</span><br><span class="line">9 create</span><br><span class="line"><span class="meta">#</span> 当老的转储文件被归档后,创建一个新的空的转储文件重新记录,权限和原来的转储文件权限一样</span><br><span class="line">10</span><br><span class="line">11 # use date as a suffix of the rotated file</span><br><span class="line">12 dateext</span><br><span class="line"><span class="meta">#</span> 用日期来做轮转之后的文件的后缀名</span><br><span class="line">13</span><br><span class="line">14 # uncomment this if you want your log files compressed</span><br><span class="line">15 #compress</span><br><span class="line"><span class="meta">#</span> 指定不压缩转储文件,如需压缩去掉注释就可以了，主要是通过gzip压缩</span><br><span class="line">16</span><br><span class="line">17 # RPM packages drop log rotation information into this directory</span><br><span class="line">18 include /etc/logrotate.d</span><br><span class="line"><span class="meta">#</span> 加载外部目录</span><br><span class="line">19</span><br><span class="line">20 # no packages own wtmp and btmp -- we'll rotate them here</span><br><span class="line">21 /var/log/wtmp &#123;</span><br><span class="line">22 monthly 表示此文件是每月轮转，而不会用到上面的每周轮转</span><br><span class="line">23 create 0664 root utmp 轮转之后创建新文件，权限是0664，属于root用户和utmp组</span><br><span class="line">24 minsize 1M 文件大于1M，而且周期到了，才会轮转</span><br><span class="line"><span class="meta">#</span> size 1M 文件大小大于1M立马轮转，不管有没有到周期</span><br><span class="line">25 rotate 1 保留1份日志文件，每1个月备份一次日志文件</span><br><span class="line">26 &#125;</span><br><span class="line">27</span><br><span class="line">28 /var/log/btmp &#123;</span><br><span class="line">29 missingok 如果日志文件不存在，不报错</span><br><span class="line">30 monthly</span><br><span class="line">31 create 0600 root utmp</span><br><span class="line">32 rotate 1</span><br><span class="line">33 &#125;</span><br><span class="line">34</span><br><span class="line">35 # system-specific logs may be also be configured here.</span><br></pre></td></tr></table></figure><h3 id="3-3、syslog-子配置文件"><a href="#3-3、syslog-子配置文件" class="headerlink" title="3.3、syslog 子配置文件"></a>3.3、syslog 子配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@yunwei ~]# cat /etc/logrotate.d/syslog</span><br><span class="line">//这个子配置文件，没有指定的参数都会以默认方式轮转</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">/var/log/messages</span><br><span class="line">/var/log/secure</span><br><span class="line">/var/log/spooler</span><br><span class="line">&#123;</span><br><span class="line">sharedscripts</span><br><span class="line">不管有多少个文件待轮转，prerotate 和 postrotate 代码只执行一次</span><br><span class="line">postrotate日志轮转常见参数：</span><br><span class="line">4、实践：SSH服务日志轮转</span><br><span class="line">要求：</span><br><span class="line">☆ 每天进行轮转，保留5天的日志文件</span><br><span class="line">☆ 日志文件大小大于5M进行轮转，不管是否到轮转周期</span><br><span class="line">思路：</span><br><span class="line">☆ 将ssh服务的日志单独记录 /var/log/ssh.log</span><br><span class="line">☆ 修改logrotate程序的主配置文件或者在/etc/logrotate.d/目录创建一个文件</span><br><span class="line">轮转完后执行postrotate 和 endscript 之间的shell代码</span><br><span class="line">/bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">上面这一句话表示轮转后对rsyslog的pid进行刷新（但pid其实不变)</span><br><span class="line">endscript</span><br><span class="line">&#125; </span><br><span class="line">思考：</span><br><span class="line">为什么轮转后需要对rsyslog的pid进行刷新呢？</span><br></pre></td></tr></table></figure><h3 id="3-4、日志轮转常见参数"><a href="#3-4、日志轮转常见参数" class="headerlink" title="3.4、日志轮转常见参数"></a>3.4、日志轮转常见参数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">常用的指令解释，这些指令都可以在man logrotate 中找得到。</span><br><span class="line">daily 指定转储周期为每天</span><br><span class="line">monthly 指定转储周期为每月</span><br><span class="line">weekly &lt;-- 每周轮转一次(monthly)</span><br><span class="line">rotate 4 &lt;-- 同一个文件最多轮转4次，4次之后就删除该文件</span><br><span class="line">create 0664 root utmp &lt;-- 轮转之后创建新文件，权限是0664，属于root用户和utmp组</span><br><span class="line">dateext &lt;-- 用日期来做轮转之后的文件的后缀名</span><br><span class="line">compress &lt;-- 用gzip对轮转后的日志进行压缩</span><br><span class="line">minsize 30K &lt;-- 文件大于30K，而且周期到了，才会轮转</span><br><span class="line">size 30k &lt;-- 文件必须大于30K才会轮转，而且文件只要大于30K就会轮转不管周期是否已到</span><br><span class="line">missingok &lt;-- 如果日志文件不存在，不报错</span><br><span class="line">notifempty &lt;-- 如果日志文件是空的，不轮转</span><br><span class="line">delaycompress &lt;-- 下一次轮转的时候才压缩</span><br><span class="line">sharedscripts &lt;-- 不管有多少文件待轮转，prerotate和postrotate 代码只执行一次</span><br><span class="line">prerotate &lt;-- 如果符合轮转的条件</span><br><span class="line">则在轮转之前执行prerotate和endscript 之间的shell代码</span><br><span class="line">postrotate &lt;-- 轮转完后执行postrotate 和 endscript 之间的shell代码</span><br></pre></td></tr></table></figure><h3 id="3-5、logrotate默认生效以及相关配置进行解释"><a href="#3-5、logrotate默认生效以及相关配置进行解释" class="headerlink" title="3.5、logrotate默认生效以及相关配置进行解释"></a>3.5、logrotate默认生效以及相关配置进行解释</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">Logrotate是基于CRON来运行的，其脚本是/etc/cron.daily/logrotate，</span><br><span class="line">实际运行时，Logrotate会调用配置文件/etc/logrotate.conf。</span><br><span class="line">[root@test ~]# cat /etc/cron.daily/logrotate</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then</span><br><span class="line">    /usr/bin/logger -t logrotate "ALERT exited abnormally with [$EXITVALUE]"</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br><span class="line">   </span><br><span class="line">  </span><br><span class="line">Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，</span><br><span class="line">具体可以查询CRON的配置文件/etc/anacrontab（老版本的文件是/etc/crontab）</span><br><span class="line">[root@test ~]# cat /etc/anacrontab</span><br><span class="line"><span class="meta">#</span> /etc/anacrontab: configuration file for anacron</span><br><span class="line">   </span><br><span class="line"><span class="meta">#</span> See anacron(8) and anacrontab(5) for details.</span><br><span class="line">   </span><br><span class="line">SHELL=/bin/sh</span><br><span class="line">PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">MAILTO=root</span><br><span class="line"><span class="meta">#</span> the maximal random delay added to the base delay of the jobs</span><br><span class="line">RANDOM_DELAY=45                                                                  </span><br><span class="line">//这个是随机的延迟时间，表示最大45分钟</span><br><span class="line"><span class="meta">#</span> the jobs will be started during the following hours only</span><br><span class="line">START_HOURS_RANGE=3-22                                                          </span><br><span class="line"> //这个是开始时间</span><br><span class="line">   </span><br><span class="line"><span class="meta">#</span>period in days   delay in minutes   job-identifier   command</span><br><span class="line">1 5 cron.daily    nice run-parts /etc/cron.daily</span><br><span class="line">7 25  cron.weekly   nice run-parts /etc/cron.weekly</span><br><span class="line">@monthly 45 cron.monthly    nice run-parts /etc/cron.monthly</span><br><span class="line">   </span><br><span class="line">第一个是Recurrence period</span><br><span class="line">第二个是延迟时间</span><br><span class="line">所以cron.daily会在3:22+(5,45)这个时间段执行，/etc/cron.daily是个文件夹</span><br><span class="line">   </span><br><span class="line">通过默认/etc/anacrontab文件配置，会发现logrotate自动切割日志文件的默认时间是凌晨3点多。</span><br><span class="line">   </span><br><span class="line">=====================================================================================</span><br><span class="line">现在需要将切割时间调整到每天的晚上12点，即每天切割的日志是前一天的0-24点之间的内容。</span><br><span class="line">操作如下：</span><br><span class="line">[root@kevin ~]# mv /etc/anacrontab /etc/anacrontab.bak          //取消日志自动轮转的设置</span><br><span class="line"> </span><br><span class="line">[root@G6-bs02 logrotate.d]# cat nstc_nohup.out</span><br><span class="line">/data/nstc/nohup.out &#123;</span><br><span class="line">rotate 30</span><br><span class="line">dateext</span><br><span class="line">daily</span><br><span class="line">copytruncate</span><br><span class="line">compress</span><br><span class="line">notifempty</span><br><span class="line">missingok</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">[root@G6-bs02 logrotate.d]# cat syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">/var/log/messages</span><br><span class="line">/var/log/secure</span><br><span class="line">/var/log/history</span><br><span class="line">&#123;</span><br><span class="line">    sharedscripts</span><br><span class="line">    compress</span><br><span class="line">    rotate 30</span><br><span class="line">    daily</span><br><span class="line">    dateext</span><br><span class="line">    postrotate</span><br><span class="line">    /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">结合crontab进行自定义的定时轮转操作</span><br><span class="line">[root@kevin ~]# crontab -l</span><br><span class="line"><span class="meta">#</span>log logrotate</span><br><span class="line">59 23 * * * /usr/sbin/logrotate -f /etc/logrotate.d/syslog &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">59 23 * * * /usr/sbin/logrotate -f /etc/logrotate.d/nstc_nohup.out &gt;/dev/null 2&gt;&amp;1</span><br><span class="line"> </span><br><span class="line">[root@G6-bs02 ~]# ll /data/nstc/nohup.out*</span><br><span class="line">-rw------- 1 app app 33218 1月  25 09:43 /data/nstc/nohup.out</span><br><span class="line">-rw------- 1 app app 67678 1月  25 23:59 /data/nstc/nohup.out-20180125.gz</span><br></pre></td></tr></table></figure><h2 id="4、相关案例"><a href="#4、相关案例" class="headerlink" title="4、相关案例"></a><strong>4、相关案例</strong></h2><h3 id="4-1、logrotate实现Nginx日志切割"><a href="#4-1、logrotate实现Nginx日志切割" class="headerlink" title="4.1、logrotate实现Nginx日志切割"></a>4.1、logrotate实现Nginx日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@master-server ~]# vim /etc/logrotate.d/nginx</span><br><span class="line">/usr/local/nginx/logs/*.log &#123;</span><br><span class="line">daily</span><br><span class="line">rotate 7</span><br><span class="line">missingok</span><br><span class="line">notifempty</span><br><span class="line">dateext</span><br><span class="line">sharedscripts</span><br><span class="line">postrotate</span><br><span class="line">    if [ -f /usr/local/nginx/logs/nginx.pid ]; then</span><br><span class="line">        kill -USR1 `cat /usr/local/nginx/logs/nginx.pid`</span><br><span class="line">    fi</span><br><span class="line">endscript</span><br><span class="line">&#125;</span><br><span class="line">kill -USR1 指的是Nginx平滑重启</span><br></pre></td></tr></table></figure><h3 id="4-2、shell脚本实现Nginx日志切割"><a href="#4-2、shell脚本实现Nginx日志切割" class="headerlink" title="4.2、shell脚本实现Nginx日志切割"></a>4.2、shell脚本实现Nginx日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@bastion-IDC ~]# vim /usr/local/sbin/logrotate-nginx.sh</span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>创建转储日志压缩存放目录</span><br><span class="line">mkdir -p /data/nginx_logs/days</span><br><span class="line"><span class="meta">#</span>手工对nginx日志进行切割转换</span><br><span class="line">/usr/sbin/logrotate -vf /etc/logrotate.d/nginx</span><br><span class="line"><span class="meta">#</span>当前时间</span><br><span class="line">time=$(date -d "yesterday" +"%Y-%m-%d")</span><br><span class="line"><span class="meta">#</span>进入转储日志存放目录</span><br><span class="line">cd /data/nginx_logs/days</span><br><span class="line"><span class="meta">#</span>对目录中的转储日志文件的文件名进行统一转换</span><br><span class="line">for i in $(ls ./ | grep "^\(.*\)\.[[:digit:]]$")</span><br><span class="line">do</span><br><span class="line">mv $&#123;i&#125; ./$(echo $&#123;i&#125;|sed -n 's/^\(.*\)\.\([[:digit:]]\)$/\1/p')-$(echo $time)</span><br><span class="line">done</span><br><span class="line"><span class="meta">#</span>对转储的日志文件进行压缩存放，并删除原有转储的日志文件，只保存压缩后的日志文件。以节约存储空间</span><br><span class="line">for i in $(ls ./ | grep "^\(.*\)\-\([[:digit:]-]\+\)$")</span><br><span class="line">do</span><br><span class="line">tar jcvf $&#123;i&#125;.bz2 ./$&#123;i&#125;</span><br><span class="line">rm -rf ./$&#123;i&#125;</span><br><span class="line">done</span><br><span class="line"><span class="meta">#</span>只保留最近7天的压缩转储日志文件</span><br><span class="line">find /data/nginx_logs/days/* -name "*.bz2" -mtime 7 -type f -exec rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure><p><strong>crontab定时执行</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@bastion-IDC ~# crontab -e</span><br><span class="line"><span class="meta">#</span>logrotate</span><br><span class="line">0 0 * * * /bin/bash -x /usr/local/sbin/logrotate-nginx.sh &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><p><strong>手动执行脚本</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@bastion-IDC ~]# /bin/bash -x /usr/local/sbin/logrotate-nginx.sh</span><br><span class="line">[root@bastion-IDC ~]# cd /data/nginx_logs/days</span><br><span class="line">[root@bastion-IDC days]# lshuantest.access_log-2017-01-18.bz2</span><br></pre></td></tr></table></figure><h3 id="4-3、PHP日志切割"><a href="#4-3、PHP日志切割" class="headerlink" title="4.3、PHP日志切割"></a>4.3、PHP日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# cat /etc/logrotate.d/php</span><br><span class="line">/Data/logs/php/*log &#123;</span><br><span class="line">    daily</span><br><span class="line">    rotate 365</span><br><span class="line">    missingok</span><br><span class="line">    notifempty</span><br><span class="line">    compress</span><br><span class="line">    dateext</span><br><span class="line">    sharedscripts</span><br><span class="line">    postrotate</span><br><span class="line">        if [ -f /Data/app/php5.6.26/var/run/php-fpm.pid ]; then</span><br><span class="line">            kill -USR1 `cat /Data/app/php5.6.26/var/run/php-fpm.pid`</span><br><span class="line">        fi</span><br><span class="line">    endscript</span><br><span class="line">    postrotate</span><br><span class="line">        /bin/chmod 644 /Data/logs/php/*gz</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">[root@huanqiu_web1 ~]# ll /Data/app/php5.6.26/var/run/php-fpm.pid</span><br><span class="line">-rw-r--r-- 1 root root 4 Dec 28 17:03 /Data/app/php5.6.26/var/run/php-fpm.pid</span><br><span class="line"> </span><br><span class="line">[root@huanqiu_web1 ~]# cd /Data/logs/php</span><br><span class="line">[root@huanqiu_web1 php]# ll</span><br><span class="line">total 25676</span><br><span class="line">-rw-r--r-- 1 root   root         0 Jun  1  2016 error.log</span><br><span class="line">-rw-r--r-- 1 nobody nobody     182 Aug 30  2015 error.log-20150830.gz</span><br><span class="line">-rw-r--r-- 1 nobody nobody     371 Sep  1  2015 error.log-20150901.gz</span><br><span class="line">-rw-r--r-- 1 nobody nobody     315 Sep  7  2015 error.log-20150907.gz</span><br><span class="line">.........</span><br></pre></td></tr></table></figure><h3 id="4-4、linux系统日志切割"><a href="#4-4、linux系统日志切割" class="headerlink" title="4.4、linux系统日志切割"></a>4.4、linux系统日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# cat /etc/logrotate.d/syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">/var/log/messages</span><br><span class="line">/var/log/secure</span><br><span class="line">/var/log/spooler</span><br><span class="line">&#123;</span><br><span class="line">    sharedscripts</span><br><span class="line">    postrotate</span><br><span class="line">    /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/messages*</span><br><span class="line">-rw------- 1 root root 34248975 Jan 19 18:42 /var/log/messages</span><br><span class="line">-rw------- 1 root root 51772994 Dec 25 03:11 /var/log/messages-20161225</span><br><span class="line">-rw------- 1 root root 51800210 Jan  1 03:05 /var/log/messages-20170101</span><br><span class="line">-rw------- 1 root root 51981366 Jan  8 03:36 /var/log/messages-20170108</span><br><span class="line">-rw------- 1 root root 51843025 Jan 15 03:40 /var/log/messages-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/cron*</span><br><span class="line">-rw------- 1 root root 2155681 Jan 19 18:43 /var/log/cron</span><br><span class="line">-rw------- 1 root root 2932618 Dec 25 03:11 /var/log/cron-20161225</span><br><span class="line">-rw------- 1 root root 2939305 Jan  1 03:06 /var/log/cron-20170101</span><br><span class="line">-rw------- 1 root root 2951820 Jan  8 03:37 /var/log/cron-20170108</span><br><span class="line">-rw------- 1 root root 3203992 Jan 15 03:41 /var/log/cron-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/secure*</span><br><span class="line">-rw------- 1 root root  275343 Jan 19 18:36 /var/log/secure</span><br><span class="line">-rw------- 1 root root 2111936 Dec 25 03:06 /var/log/secure-20161225</span><br><span class="line">-rw------- 1 root root 2772744 Jan  1 02:57 /var/log/secure-20170101</span><br><span class="line">-rw------- 1 root root 1115543 Jan  8 03:26 /var/log/secure-20170108</span><br><span class="line">-rw------- 1 root root  731599 Jan 15 03:40 /var/log/secure-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/spooler*</span><br><span class="line">-rw------- 1 root root 0 Jan 15 03:41 /var/log/spooler</span><br><span class="line">-rw------- 1 root root 0 Dec 18 03:21 /var/log/spooler-20161225</span><br><span class="line">-rw------- 1 root root 0 Dec 25 03:11 /var/log/spooler-20170101</span><br><span class="line">-rw------- 1 root root 0 Jan  1 03:06 /var/log/spooler-20170108</span><br><span class="line">-rw------- 1 root root 0 Jan  8 03:37 /var/log/spooler-20170115</span><br></pre></td></tr></table></figure><h3 id="4-5、Tomcat日志切割"><a href="#4-5、Tomcat日志切割" class="headerlink" title="4.5、Tomcat日志切割"></a>4.5、Tomcat日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# cat /etc/logrotate.d/syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">/var/log/messages</span><br><span class="line">/var/log/secure</span><br><span class="line">/var/log/spooler</span><br><span class="line">&#123;</span><br><span class="line">    sharedscripts</span><br><span class="line">    postrotate</span><br><span class="line">    /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/messages*</span><br><span class="line">-rw------- 1 root root 34248975 Jan 19 18:42 /var/log/messages</span><br><span class="line">-rw------- 1 root root 51772994 Dec 25 03:11 /var/log/messages-20161225</span><br><span class="line">-rw------- 1 root root 51800210 Jan  1 03:05 /var/log/messages-20170101</span><br><span class="line">-rw------- 1 root root 51981366 Jan  8 03:36 /var/log/messages-20170108</span><br><span class="line">-rw------- 1 root root 51843025 Jan 15 03:40 /var/log/messages-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/cron*</span><br><span class="line">-rw------- 1 root root 2155681 Jan 19 18:43 /var/log/cron</span><br><span class="line">-rw------- 1 root root 2932618 Dec 25 03:11 /var/log/cron-20161225</span><br><span class="line">-rw------- 1 root root 2939305 Jan  1 03:06 /var/log/cron-20170101</span><br><span class="line">-rw------- 1 root root 2951820 Jan  8 03:37 /var/log/cron-20170108</span><br><span class="line">-rw------- 1 root root 3203992 Jan 15 03:41 /var/log/cron-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/secure*</span><br><span class="line">-rw------- 1 root root  275343 Jan 19 18:36 /var/log/secure</span><br><span class="line">-rw------- 1 root root 2111936 Dec 25 03:06 /var/log/secure-20161225</span><br><span class="line">-rw------- 1 root root 2772744 Jan  1 02:57 /var/log/secure-20170101</span><br><span class="line">-rw------- 1 root root 1115543 Jan  8 03:26 /var/log/secure-20170108</span><br><span class="line">-rw------- 1 root root  731599 Jan 15 03:40 /var/log/secure-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/spooler*</span><br><span class="line">-rw------- 1 root root 0 Jan 15 03:41 /var/log/spooler</span><br><span class="line">-rw------- 1 root root 0 Dec 18 03:21 /var/log/spooler-20161225</span><br><span class="line">-rw------- 1 root root 0 Dec 25 03:11 /var/log/spooler-20170101</span><br><span class="line">-rw------- 1 root root 0 Jan  1 03:06 /var/log/spooler-20170108</span><br><span class="line">-rw------- 1 root root 0 Jan  8 03:37 /var/log/spooler-20170115</span><br></pre></td></tr></table></figure><h3 id="4-6、使用python脚本进行jumpserver日志切割"><a href="#4-6、使用python脚本进行jumpserver日志切割" class="headerlink" title="4.6、使用python脚本进行jumpserver日志切割"></a>4.6、使用python脚本进行jumpserver日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@test-vm01 mnt]# cat log_rotate.py</span><br><span class="line"><span class="meta">#</span>!/usr/bin/env python</span><br><span class="line">   </span><br><span class="line">import datetime,os,sys,shutil</span><br><span class="line">   </span><br><span class="line">log_path = '/opt/jumpserver/logs/'</span><br><span class="line">log_file = 'jumpserver.log'</span><br><span class="line">   </span><br><span class="line">yesterday = (datetime.datetime.now() - datetime.timedelta(days = 1))</span><br><span class="line">   </span><br><span class="line">try:</span><br><span class="line">    os.makedirs(log_path + yesterday.strftime('%Y') + os.sep + yesterday.strftime('%m'))</span><br><span class="line">except OSError,e:</span><br><span class="line">    print</span><br><span class="line">    print e</span><br><span class="line">    sys.exit()</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">shutil.move(log_path + log_file,log_path \</span><br><span class="line">            + yesterday.strftime('%Y') + os.sep \</span><br><span class="line">            + yesterday.strftime('%m') + os.sep \</span><br><span class="line">            + log_file + '_' + yesterday.strftime('%Y%m%d') + '.log')</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">os.popen("sudo /opt/jumpserver/service.sh restart")</span><br><span class="line"> </span><br><span class="line">手动执行这个脚本：</span><br><span class="line">[root@test-vm01 mnt]# chmod 755 log_rotate.py</span><br><span class="line">[root@test-vm01 mnt]# python log_rotate.py</span><br><span class="line"> </span><br><span class="line">查看日志切割后的效果：</span><br><span class="line">[root@test-vm01 mnt]# ls /opt/jumpserver/logs/</span><br><span class="line">2017  jumpserver.log </span><br><span class="line">[root@test-vm01 mnt]# ls /opt/jumpserver/logs/2017/</span><br><span class="line">09</span><br><span class="line">[root@test-vm01 mnt]# ls /opt/jumpserver/logs/2017/09/</span><br><span class="line">jumpserver.log_20170916.log</span><br><span class="line"> </span><br><span class="line">然后做每日的定时切割任务：</span><br><span class="line">[root@test-vm01 mnt]# crontab -e</span><br><span class="line">30 1 * * * /usr/bin/python /mnt/log_rotate.py &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h3 id="4-7、使用python脚本进行Nginx日志切割"><a href="#4-7、使用python脚本进行Nginx日志切割" class="headerlink" title="4.7、使用python脚本进行Nginx日志切割"></a>4.7、使用python脚本进行Nginx日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@test-vm01 mnt]# vim log_rotate.py</span><br><span class="line"><span class="meta">#</span>!/usr/bin/env python</span><br><span class="line">   </span><br><span class="line">import datetime,os,sys,shutil</span><br><span class="line">   </span><br><span class="line">log_path = '/app/nginx/logs/'</span><br><span class="line">log_file = 'www_access.log'</span><br><span class="line">   </span><br><span class="line">yesterday = (datetime.datetime.now() - datetime.timedelta(days = 1))</span><br><span class="line">   </span><br><span class="line">try:</span><br><span class="line">    os.makedirs(log_path + yesterday.strftime('%Y') + os.sep + yesterday.strftime('%m'))</span><br><span class="line">except OSError,e:</span><br><span class="line">    print</span><br><span class="line">    print e</span><br><span class="line">    sys.exit()</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">shutil.move(log_path + log_file,log_path \</span><br><span class="line">            + yesterday.strftime('%Y') + os.sep \</span><br><span class="line">            + yesterday.strftime('%m') + os.sep \</span><br><span class="line">            + log_file + '_' + yesterday.strftime('%Y%m%d') + '.log')</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">os.popen("sudo kill -USR1 `cat /app/nginx/logs/nginx.pid`")</span><br></pre></td></tr></table></figure><h2 id="5、logrotate无法自动轮询日志的解决办法"><a href="#5、logrotate无法自动轮询日志的解决办法" class="headerlink" title="5、logrotate无法自动轮询日志的解决办法"></a><strong>5、logrotate无法自动轮询日志的解决办法</strong></h2><p>起始原因：使用logrotate轮询nginx日志，配置好之后，发现nginx日志连续两天没被切割，这是为什么呢？？然后开始检查日志切割的配置文件是否有问题，检查后确定配置文件一切正常。于是怀疑是logrotate预定的cron没执行，查看了cron的日志，发现有一条”Dec 7 04:02:01 www crond[18959]: (root) CMD (run-parts /etc/cron.daily)”的日志，证明cron在04:02分时已经执行/etc/cron.daily目录下的程序。接着查看/etc /cron.daily/logrotate（这是logrotate自动轮转的脚本）的内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_test ~]# cat /etc/cron.daily/logrotate</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then</span><br><span class="line">    /usr/bin/logger -t logrotate "ALERT exited abnormally with [$EXITVALUE]"</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>有发现异常，配置好的日志轮转操作都是由这个脚本完成的，一切运行正常，脚本应该就没问题。 直接执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_test ~]# /usr/sbin/logrotate /etc/logrotate.conf</span><br></pre></td></tr></table></figure><p>这些系统日志是正常轮询了，但nginx日志却还是没轮询,接着强行启动记录文件维护操作，纵使logrotate指令认为没有需要，应该有可能是logroate认为nginx日志太小，不进行轮询。 故需要强制轮询，即在/etc/cron.daily/logrotate脚本中将 -t 参数替换成 -f 参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_test ~]# cat /etc/cron.daily/logrotate</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then</span><br><span class="line">    /usr/bin/logger -f logrotate "ALERT exited abnormally with [$EXITVALUE]"</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p><strong>重启下cron服务</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_test ~]# /etc/init.d/crond restart</span><br><span class="line">Stopping crond: [ OK ]Starting crond: [ OK ]</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Fri Apr 10 2020 18:07:52 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;strong&gt;Linux日志切割方法[Logrotate、python、shell实现方式]&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;​ 对于Linux系统安全来说，日志文件是极其重要的工具。不知为何，我发现很多运维同学的服务器上都运行着一些诸如每天切分Nginx日志之类的cron脚本，大家似乎遗忘了Logrotate，争相发明自己的轮子，这真是让人沮丧啊！就好比明明身边躺着现成的性感美女，大家却忙着自娱自乐，罪过！logrotate程序是一个日志文件管理工具。用于分割日志文件，删除旧的日志文件，并创建新的日志文件，起到“转储”作用。可以节省磁盘空间。下面就对logrotate日志轮转操作做一梳理记录。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、什么是轮转？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;日志轮循（轮转）：日志轮转，切割，备份，归档&lt;/strong&gt;&lt;/p&gt;&lt;h2 id=&quot;2、为什么需要轮转？&quot;&gt;&lt;a href=&quot;#2、为什么需要轮转？&quot; class=&quot;headerlink&quot; title=&quot;2、为什么需要轮转？&quot;&gt;&lt;/a&gt;&lt;strong&gt;2、为什么需要轮转？&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;☆ 避免日志过大占满/var/log的文件系统&lt;/p&gt;&lt;p&gt;☆ 方便日志查看 ☆ 将丢弃系统中最旧的日志文件，以节省空间 ☆ 日志轮转的程序是logrotate&lt;/p&gt;&lt;p&gt;☆ logrotate本身不是系统守护进程，它是通过计划任务crond每天执行&lt;/p&gt;
    
    </summary>
    
      <category term="shell" scheme="https://yongnights.github.io/categories/shell/"/>
    
      <category term="Linux" scheme="https://yongnights.github.io/categories/shell/Linux/"/>
    
    
      <category term="Linux" scheme="https://yongnights.github.io/tags/Linux/"/>
    
      <category term="shell" scheme="https://yongnights.github.io/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>使用 Auditbeat 模块监控 shell 命令</title>
    <link href="https://yongnights.github.io/2020/04/03/%E4%BD%BF%E7%94%A8%20Auditbeat%20%E6%A8%A1%E5%9D%97%E7%9B%91%E6%8E%A7%20shell%20%E5%91%BD%E4%BB%A4/"/>
    <id>https://yongnights.github.io/2020/04/03/使用 Auditbeat 模块监控 shell 命令/</id>
    <published>2020-04-03T02:26:23.282Z</published>
    <updated>2020-04-03T02:38:18.649Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><blockquote><p>使用 Auditbeat 模块监控 shell 命令<br>Auditbeat Audited 模块可以用来监控所有用户在系统上执行的 shell 命令。在终端用户偶尔才会登录的服务器上，通常需要进行监控。<br>该示例是在 CentOS Linux 7.6 上使用 Auditbeat 7.4.2 RPM 软件包和 Elasticsearch Service（ESS）[<a href="https://www.elastic.co/products/elasticsearch/service]上的" target="_blank" rel="noopener">https://www.elastic.co/products/elasticsearch/service]上的</a> Elastic Stack ] 7.4.2 部署的。</p></blockquote><p><em>可以参考其中的思路，配置流程等，使用本机自建的ES，不使用Elasticsearch Service（ESS）集群</em></p><h1 id="禁用-Auditd"><a href="#禁用-Auditd" class="headerlink" title="禁用 Auditd"></a>禁用 Auditd</h1><p>系统守护进程 auditd 会影响 Auditbeat Audited 模块的正常使用，所以必须将其禁用。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 停止 auditd：</span><br><span class="line">service auditd stop</span><br><span class="line"></span><br><span class="line"># 禁用服务：</span><br><span class="line">systemctl disable auditd.service</span><br></pre></td></tr></table></figure><p></p><p>如果您在使用 Auditbeat Auditd 模块的同时也必须要运行 Audited 进程，那么在内核版本为 3.16 或者更高的情况下可以考虑设置 socket_type: multicast 参数。默认值为 unicast。有关此参数的更多信息，请参见文档[<a href="https://www.elastic.co/guide/en/beats/auditbeat/master/auditbeat-module-auditd.html#_configuration_options_14]的配置选项部分。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/master/auditbeat-module-auditd.html#_configuration_options_14]的配置选项部分。</a></p><a id="more"></a><h1 id="配置-Auditbeat"><a href="#配置-Auditbeat" class="headerlink" title="配置 Auditbeat"></a>配置 Auditbeat</h1><p>Auditbeat 守护进程将事件数据发送到一个 Elasticsearch Service（ESS）集群中。有关更多详细信息，请参见文档Auditbeat[<a href="https://www.elastic.co/guide/en/beats/auditbeat/master/configuring-howto-auditbeat.html]" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/master/configuring-howto-auditbeat.html]</a><br>中的配置部分。<br>要想获取工作示例，必须配置 Auditbeat 的 cloud.id 和 cloud.auth 参数，详情参见此文档[<a href="https://www.elastic.co/guide/en/beats/auditbeat/master/configure-cloud-id.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/master/configure-cloud-id.html]。</a><br>编辑 /etc/auditbeat/auditbeat.yml：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cloud.id: &lt;your_cloud_id&gt;</span><br><span class="line">cloud.auth: ingest_user:password</span><br></pre></td></tr></table></figure><p></p><p>如果您要将数据发送到 Elasticsearch 集群（例如本地实例），请参见此文档：[<a href="https://www.elastic.co/guide/en/beats/auditbeat/master/configure-cloud-id.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/master/configure-cloud-id.html]。</a></p><h1 id="Auditbeat-模块规则"><a href="#Auditbeat-模块规则" class="headerlink" title="Auditbeat 模块规则"></a>Auditbeat 模块规则</h1><p>Audited 模块订阅内核以接收系统事件。定义规则以捕获这些事件，并且使用Linux Auditctl 进程所使用的格式，详情参见此文档：[<a href="https://linux.die.net/man/8/auditctl]。" target="_blank" rel="noopener">https://linux.die.net/man/8/auditctl]。</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/auditbeat/audit.rules.d/rules.conf</span><br><span class="line">-a exit,always -F arch=b64 -F euid=0 -S execve -k root_acct</span><br><span class="line">-a exit,always -F arch=b32 -F euid=0 -S execve -k root_acct</span><br><span class="line">-a exit,always -F arch=b64 -F euid&gt;=1000 -S execve -k user_acct</span><br><span class="line">-a exit,always -F arch=b32 -F euid&gt;=1000 -S execve -k user_acct</span><br></pre></td></tr></table></figure><p></p><ul><li>euid 是用户的有效ID。0 代表会获取 root 用户和 uid &gt;=1000 或者权限更高的其他用户的所有活动。</li><li>-k<key>用于为事件分配任意“键”，它将显示在 tags 字段中。它还可以在 Kibana 中用来对事件进行过滤和分类。</key></li></ul><h1 id="Auditbeat-设置命令"><a href="#Auditbeat-设置命令" class="headerlink" title="Auditbeat 设置命令"></a>Auditbeat 设置命令</h1><p>运行Auditbeat 加载索引模板，读取 node pipelines，索引文件周期策略和Kibana 仪表板。<br><code>auditbeat -e setup</code><br>如果您不使用ESS，欢迎参考此文档[<a href="https://www.elastic.co/guide/en/beats/auditbeat/current/setup-kibana-endpoint.html]" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/current/setup-kibana-endpoint.html]</a> 来设置您的 Kibana 端点。</p><h1 id="开始使用"><a href="#开始使用" class="headerlink" title="开始使用"></a>开始使用</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">systemctl start auditbeat</span><br><span class="line"></span><br><span class="line"># 列出启用的规则：</span><br><span class="line">auditbeat show auditd-rules</span><br><span class="line">-a never,exit -S all -F pid=23617</span><br><span class="line">-a always,exit -F arch=b64 -S execve -F euid=root -F key=root_acct</span><br><span class="line">-a always,exit -F arch=b32 -S execve -F euid=root -F key=root_acct</span><br><span class="line">-a always,exit -F arch=b64 -S execve -F euid&gt;=vagrant -F key=user_acct</span><br><span class="line">-a always,exit -F arch=b32 -S execve -F euid&gt;=vagrant -F key=user_acct</span><br></pre></td></tr></table></figure><h1 id="监控数据"><a href="#监控数据" class="headerlink" title="监控数据"></a>监控数据</h1><p>当用户执行一些类似于 whoami，ls 以及 lsblk 的 shell 命令时，kibana 中就会发现这些事件。</p><ul><li>Kibana 会显示出 user.name，process.executable，process.args 和 tags 这些选定的字段。</li><li>过滤的字段是 user.name: root 和 auditd.data.syscall: execve。</li><li>每秒刷新一次数据。</li></ul><h1 id="TTY-审计"><a href="#TTY-审计" class="headerlink" title="TTY 审计"></a>TTY 审计</h1><p>当系统中发生 TTY 事件时，Auditbeat Audited 模块也可以接收它们。配置system-auth PAM 配置文件以启用 TTY。只有 root 用户的 TTY 事件将被实时记录。其他用户的事件通常会被缓冲直到 exit。TTY 审计会捕获系统内置命令像pwd，test 等。<br>追加以下内容到 /etc/pam.d/system-auth 便可以对所有用户启用审核，关于 pam_tty_audit 的详细信息，参见此文档：[<a href="https://linux.die.net/man/8/pam_tty_audit]。" target="_blank" rel="noopener">https://linux.die.net/man/8/pam_tty_audit]。</a><br><code>session required pam_tty_audit.so enable=*</code></p><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo su -</span><br><span class="line">Last login: Fri Nov 22 23:43:00 UTC 2019 on pts/0</span><br><span class="line">$ helllloooo there!</span><br><span class="line">-bash: helllloooo: command not found</span><br><span class="line">$ exit</span><br></pre></td></tr></table></figure><h1 id="Kibana-发现"><a href="#Kibana-发现" class="headerlink" title="Kibana 发现"></a>Kibana 发现</h1><h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>Auditbeat 还可以做什么：</p><ul><li>当一个文件在磁盘上更改（创建，更新或删除）时可以发送事件，得益于 file_integrity 模块，详情参考此文档：[<a href="https://www.elastic.co/guide/en/beats/auditbeat/current/auditbeat-module-file_integrity.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/current/auditbeat-module-file_integrity.html]。</a></li><li>通过 system 模块发送有关系统的指标，详情参考此文档：[<a href="https://www.elastic.co/guide/en/beats/auditbeat/current/auditbeat-module-system.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/current/auditbeat-module-system.html]。</a><br>该链接还提供了 Auditbeat 的相关文档，详情参考此文档：[<a href="https://www.elastic.co/guide/en/beats/auditbeat/current/index.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/current/index.html]。</a></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;blockquote&gt;&lt;p&gt;使用 Auditbeat 模块监控 shell 命令&lt;br&gt;Auditbeat Audited 模块可以用来监控所有用户在系统上执行的 shell 命令。在终端用户偶尔才会登录的服务器上，通常需要进行监控。&lt;br&gt;该示例是在 CentOS Linux 7.6 上使用 Auditbeat 7.4.2 RPM 软件包和 Elasticsearch Service（ESS）[&lt;a href=&quot;https://www.elastic.co/products/elasticsearch/service]上的&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.elastic.co/products/elasticsearch/service]上的&lt;/a&gt; Elastic Stack ] 7.4.2 部署的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;em&gt;可以参考其中的思路，配置流程等，使用本机自建的ES，不使用Elasticsearch Service（ESS）集群&lt;/em&gt;&lt;/p&gt;&lt;h1 id=&quot;禁用-Auditd&quot;&gt;&lt;a href=&quot;#禁用-Auditd&quot; class=&quot;headerlink&quot; title=&quot;禁用 Auditd&quot;&gt;&lt;/a&gt;禁用 Auditd&lt;/h1&gt;&lt;p&gt;系统守护进程 auditd 会影响 Auditbeat Audited 模块的正常使用，所以必须将其禁用。&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 停止 auditd：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;service auditd stop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 禁用服务：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;systemctl disable auditd.service&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果您在使用 Auditbeat Auditd 模块的同时也必须要运行 Audited 进程，那么在内核版本为 3.16 或者更高的情况下可以考虑设置 socket_type: multicast 参数。默认值为 unicast。有关此参数的更多信息，请参见文档[&lt;a href=&quot;https://www.elastic.co/guide/en/beats/auditbeat/master/auditbeat-module-auditd.html#_configuration_options_14]的配置选项部分。&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.elastic.co/guide/en/beats/auditbeat/master/auditbeat-module-auditd.html#_configuration_options_14]的配置选项部分。&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Auditbeat" scheme="https://yongnights.github.io/categories/elk/Auditbeat/"/>
    
      <category term="shell" scheme="https://yongnights.github.io/categories/elk/Auditbeat/shell/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Auditbeat" scheme="https://yongnights.github.io/tags/Auditbeat/"/>
    
      <category term="shell" scheme="https://yongnights.github.io/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch：如何对PDF文件进行搜索</title>
    <link href="https://yongnights.github.io/2020/04/03/Elasticsearch%EF%BC%9A%E5%A6%82%E4%BD%95%E5%AF%B9PDF%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E6%90%9C%E7%B4%A2/"/>
    <id>https://yongnights.github.io/2020/04/03/Elasticsearch：如何对PDF文件进行搜索/</id>
    <published>2020-04-03T01:57:15.620Z</published>
    <updated>2020-04-03T02:25:31.514Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><blockquote><p>Elasticsearch 通常用于字符串，数字，日期等数据类型的检索，但是在 HCM、ERP 和电子商务等应用程序中经常存在对办公文档进行搜索的需求。今天的这篇文章中我们来讲一下如何实现 PDF、DOC、XLS 等办公文件的搜索，本解决方案适用于 Elasticsearch 5.0 以后的版本。</p></blockquote><h1 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h1><p>首先把我们的 .pdf 文件进行 Base64 处理，然后上传到 Elasticsearch 中的 ingest node 中进行处理。我们可以通过 Ingest attachment plugin 来使得 Elasticsearch 提取通用格式的文件附件比如 PPT、XLS及PDF。最终，数据进入到 Elasticsearch 的 data node 中以便让我们进行搜索。</p><h1 id="导入PDF文件到Elasticsearch中"><a href="#导入PDF文件到Elasticsearch中" class="headerlink" title="导入PDF文件到Elasticsearch中"></a>导入PDF文件到Elasticsearch中</h1><h2 id="准备PDF文件"><a href="#准备PDF文件" class="headerlink" title="准备PDF文件"></a>准备PDF文件</h2><p>我们可以使用 Word 或其它编辑软件来生产一个 PDF 文件，暂且我们叫这个文件的名字为 sample.pdf，而它的内容非常简单，在 sample.pdf 文件中，我们只有一句话：“I like this useful tool”。</p><h2 id="安装-Ingest-attachment-plugin"><a href="#安装-Ingest-attachment-plugin" class="headerlink" title="安装 Ingest attachment plugin"></a>安装 Ingest attachment plugin</h2><p>Ingest attachment plugin 允许 Elasticsearch 通过使用 Apache 文本提取库 Tika 提取通用格式（例如：PPT，XLS 和 PDF）的文件附件。Apache Tika 工具包可从一千多种不同的文件类型中检测并提取元数据和文本。所有这些文件类型都可以通过一个界面进行解析，从而使 Tika 对搜索引擎索引，内容分析，翻译等有用。<br>需要注意的是，源字段必须是 Base64 编码的二进制，如果不想增加在 Base64 之间来回转换的开销，则可以使用 CBOR 格式而不是 JSON，并将字段指定为字节数组而不是字符串表示形式，这样处理器将跳过 Base64 解码。<br>可以使用插件管理器安装此插件，该插件必须安装在集群中的每个节点上，并且每个节点必须在安装后重新启动。<br><code>sudo bin/elasticsearch-plugin install ingest-attachment</code><br>等我们安装好这个插件后，我们可以通过如下的命令来查看该插件是否已经被成功安装好了:<br><code>./bin/elasticsearch-plugin list</code></p><a id="more"></a><h2 id="创建-attachment-pipeline"><a href="#创建-attachment-pipeline" class="headerlink" title="创建 attachment pipeline"></a>创建 attachment pipeline</h2><p>在我们的 ingest node 上创建一个叫做 pdfattachment 的 pipleline：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PUT _ingest/pipeline/pdfattachment</span><br><span class="line">&#123;</span><br><span class="line">  &quot;description&quot;: &quot;Extract attachment information encoded in Base64 with UTF-8 charset&quot;,</span><br><span class="line">  &quot;processors&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;attachment&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;file&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h2 id="转换并上传PDF文件的内容到Elasticsearch中"><a href="#转换并上传PDF文件的内容到Elasticsearch中" class="headerlink" title="转换并上传PDF文件的内容到Elasticsearch中"></a>转换并上传PDF文件的内容到Elasticsearch中</h2><p>对于 Ingest attachment plugin 来说，它的数据必须是 Base64 的。我们可以在网站Base64 encoder 来进行转换，我们可以直接通过下面的脚本来进行操作：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!/bin/bash</span><br><span class="line"></span><br><span class="line">encodedPdf=`cat sample.pdf | base64`</span><br><span class="line"></span><br><span class="line">json=&quot;&#123;\&quot;file\&quot;:\&quot;$&#123;encodedPdf&#125;\&quot;&#125;&quot;</span><br><span class="line"></span><br><span class="line">echo &quot;$json&quot; &gt; json.file</span><br><span class="line"></span><br><span class="line">curl -XPOST &apos;http://localhost:9200/pdf-test1/_doc?pipeline=pdfattachment&amp;pretty&apos; -H &apos;Content-Type: application/json&apos; -d @json.file</span><br></pre></td></tr></table></figure><p></p><p>在上面的脚本中，我们针对 sample.pdf 进行 Base64 的转换，并生成一个叫做 json.file 的文件。在最后，我们把这个 json.file 文件的内容通过 curl 指令上传到 Elasticsearch 中，我们可以在 Elasticsearch 中查看一个叫做 pdf-test1 的索引。</p><h1 id="查看索引并搜索"><a href="#查看索引并搜索" class="headerlink" title="查看索引并搜索"></a>查看索引并搜索</h1><p>可以通过如下的命令来查询 pdf-test1 索引：<br><code>GET pdf-test1/_search</code><br>可以看出来，我们的索引中有一个叫做 content 的字段，它包含了我们的 pdf 文件的内容，这个字段可以同我们进行搜索。在上面我们也看到了一个很大的一个字段 file，它含有我们转换过的 Base64 格式的内容。如果我们不想要这个字段，我们可以通过添加另外一个 remove processor 来除去这个字段：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">PUT _ingest/pipeline/pdfattachment</span><br><span class="line">&#123;</span><br><span class="line">  &quot;description&quot;: &quot;Extract attachment information encoded in Base64 with UTF-8 charset&quot;,</span><br><span class="line">  &quot;processors&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;attachment&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;file&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;remove&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;file&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;blockquote&gt;&lt;p&gt;Elasticsearch 通常用于字符串，数字，日期等数据类型的检索，但是在 HCM、ERP 和电子商务等应用程序中经常存在对办公文档进行搜索的需求。今天的这篇文章中我们来讲一下如何实现 PDF、DOC、XLS 等办公文件的搜索，本解决方案适用于 Elasticsearch 5.0 以后的版本。&lt;/p&gt;&lt;/blockquote&gt;&lt;h1 id=&quot;实现原理&quot;&gt;&lt;a href=&quot;#实现原理&quot; class=&quot;headerlink&quot; title=&quot;实现原理&quot;&gt;&lt;/a&gt;实现原理&lt;/h1&gt;&lt;p&gt;首先把我们的 .pdf 文件进行 Base64 处理，然后上传到 Elasticsearch 中的 ingest node 中进行处理。我们可以通过 Ingest attachment plugin 来使得 Elasticsearch 提取通用格式的文件附件比如 PPT、XLS及PDF。最终，数据进入到 Elasticsearch 的 data node 中以便让我们进行搜索。&lt;/p&gt;&lt;h1 id=&quot;导入PDF文件到Elasticsearch中&quot;&gt;&lt;a href=&quot;#导入PDF文件到Elasticsearch中&quot; class=&quot;headerlink&quot; title=&quot;导入PDF文件到Elasticsearch中&quot;&gt;&lt;/a&gt;导入PDF文件到Elasticsearch中&lt;/h1&gt;&lt;h2 id=&quot;准备PDF文件&quot;&gt;&lt;a href=&quot;#准备PDF文件&quot; class=&quot;headerlink&quot; title=&quot;准备PDF文件&quot;&gt;&lt;/a&gt;准备PDF文件&lt;/h2&gt;&lt;p&gt;我们可以使用 Word 或其它编辑软件来生产一个 PDF 文件，暂且我们叫这个文件的名字为 sample.pdf，而它的内容非常简单，在 sample.pdf 文件中，我们只有一句话：“I like this useful tool”。&lt;/p&gt;&lt;h2 id=&quot;安装-Ingest-attachment-plugin&quot;&gt;&lt;a href=&quot;#安装-Ingest-attachment-plugin&quot; class=&quot;headerlink&quot; title=&quot;安装 Ingest attachment plugin&quot;&gt;&lt;/a&gt;安装 Ingest attachment plugin&lt;/h2&gt;&lt;p&gt;Ingest attachment plugin 允许 Elasticsearch 通过使用 Apache 文本提取库 Tika 提取通用格式（例如：PPT，XLS 和 PDF）的文件附件。Apache Tika 工具包可从一千多种不同的文件类型中检测并提取元数据和文本。所有这些文件类型都可以通过一个界面进行解析，从而使 Tika 对搜索引擎索引，内容分析，翻译等有用。&lt;br&gt;需要注意的是，源字段必须是 Base64 编码的二进制，如果不想增加在 Base64 之间来回转换的开销，则可以使用 CBOR 格式而不是 JSON，并将字段指定为字节数组而不是字符串表示形式，这样处理器将跳过 Base64 解码。&lt;br&gt;可以使用插件管理器安装此插件，该插件必须安装在集群中的每个节点上，并且每个节点必须在安装后重新启动。&lt;br&gt;&lt;code&gt;sudo bin/elasticsearch-plugin install ingest-attachment&lt;/code&gt;&lt;br&gt;等我们安装好这个插件后，我们可以通过如下的命令来查看该插件是否已经被成功安装好了:&lt;br&gt;&lt;code&gt;./bin/elasticsearch-plugin list&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/categories/elk/Elasticsearch/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch索引和查询性能调优的21条建议</title>
    <link href="https://yongnights.github.io/2020/04/03/Elasticsearch%E7%B4%A2%E5%BC%95%E5%92%8C%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%8421%E6%9D%A1%E5%BB%BA%E8%AE%AE/"/>
    <id>https://yongnights.github.io/2020/04/03/Elasticsearch索引和查询性能调优的21条建议/</id>
    <published>2020-04-03T01:30:32.227Z</published>
    <updated>2020-04-03T01:49:18.635Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><h1 id="Elasticsearch部署建议"><a href="#Elasticsearch部署建议" class="headerlink" title="Elasticsearch部署建议"></a>Elasticsearch部署建议</h1><h2 id="1-选择合理的硬件配置：尽可能使用-SSD"><a href="#1-选择合理的硬件配置：尽可能使用-SSD" class="headerlink" title="1. 选择合理的硬件配置：尽可能使用 SSD"></a>1. 选择合理的硬件配置：尽可能使用 SSD</h2><p>Elasticsearch 最大的瓶颈往往是磁盘读写性能，尤其是随机读取性能。使用SSD（PCI-E接口SSD卡/SATA接口SSD盘）通常比机械硬盘（SATA盘/SAS盘）查询速度快5~10倍，写入性能提升不明显。<br>对于文档检索类查询性能要求较高的场景，建议考虑 SSD 作为存储，同时按照 1:10 的比例配置内存和硬盘。对于日志分析类查询并发要求较低的场景，可以考虑采用机械硬盘作为存储，同时按照 1:50 的比例配置内存和硬盘。单节点存储数据建议在2TB以内，不要超过5TB，避免查询速度慢、系统不稳定。</p><h2 id="2-给JVM配置机器一半的内存，但是不建议超过32G"><a href="#2-给JVM配置机器一半的内存，但是不建议超过32G" class="headerlink" title="2. 给JVM配置机器一半的内存，但是不建议超过32G"></a>2. 给JVM配置机器一半的内存，但是不建议超过32G</h2><p>修改 conf/jvm.options 配置，-Xms 和 -Xmx 设置为相同的值，推荐设置为机器内存的一半左右，剩余一半留给操作系统缓存使用。JVM 内存建议不要低于 2G，否则有可能因为内存不足导致 ES 无法正常启动或内存溢出，JVM 建议不要超过 32G，否则 JVM 会禁用内存对象指针压缩技术，造成内存浪费。机器内存大于 64G 内存时，推荐配置 -Xms30g -Xmx30g。JVM 堆内存较大时，内存垃圾回收暂停时间比较长，建议配置 ZGC 或 G1 垃圾回收算法。</p><h2 id="3-规模较大的集群配置专有主节点，避免脑裂问题"><a href="#3-规模较大的集群配置专有主节点，避免脑裂问题" class="headerlink" title="3. 规模较大的集群配置专有主节点，避免脑裂问题"></a>3. 规模较大的集群配置专有主节点，避免脑裂问题</h2><p>Elasticsearch 主节点负责集群元信息管理、index 的增删操作、节点的加入剔除，定期将最新的集群状态广播至各个节点。在集群规模较大时，建议配置专有主节点只负责集群管理，不存储数据，不承担数据读写压力。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 专有主节点配置(conf/elasticsearch.yml)：</span><br><span class="line">node.master:true</span><br><span class="line">node.data: false</span><br><span class="line">node.ingest:false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 数据节点配置(conf/elasticsearch.yml)：</span><br><span class="line">node.master:false</span><br><span class="line">node.data:true</span><br><span class="line">node.ingest:true</span><br></pre></td></tr></table></figure><p></p><p>Elasticsearch 默认每个节点既是候选主节点，又是数据节点。最小主节点数量参数 minimum_master_nodes 推荐配置为候选主节点数量一半以上，该配置告诉 Elasticsearch 当没有足够的 master 候选节点的时候，不进行 master 节点选举，等 master 节点足够了才进行选举。<br>例如对于 3 节点集群，最小主节点数量从默认值 1 改为 2。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 最小主节点数量配置(conf/elasticsearch.yml)：</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br></pre></td></tr></table></figure><p></p><a id="more"></a><h2 id="4-Linux操作系统调优"><a href="#4-Linux操作系统调优" class="headerlink" title="4. Linux操作系统调优"></a>4. Linux操作系统调优</h2><p>关闭交换分区，防止内存置换降低性能。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 将/etc/fstab 文件中包含swap的行注释掉</span><br><span class="line">sed -i &apos;/swap/s/^/#/&apos; /etc/fstab</span><br><span class="line">swapoff -a</span><br><span class="line"></span><br><span class="line"># 单用户可以打开的最大文件数量，可以设置为官方推荐的65536或更大些</span><br><span class="line">echo &quot;* - nofile 655360&quot; &gt;&gt; /etc/security/limits.conf</span><br><span class="line"></span><br><span class="line"># 单用户线程数调大</span><br><span class="line">echo &quot;* - nproc 131072&quot; &gt;&gt; /etc/security/limits.conf</span><br><span class="line"></span><br><span class="line"># 单进程可以使用的最大map内存区域数量</span><br><span class="line">echo &quot;vm.max_map_count = 655360&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line"># 参数修改立即生效</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p></p><h1 id="索引性能调优建议"><a href="#索引性能调优建议" class="headerlink" title="索引性能调优建议"></a>索引性能调优建议</h1><h2 id="1-设置合理的索引分片数和副本数"><a href="#1-设置合理的索引分片数和副本数" class="headerlink" title="1. 设置合理的索引分片数和副本数"></a>1. 设置合理的索引分片数和副本数</h2><p>索引分片数建议设置为集群节点的整数倍，初始数据导入时副本数设置为 0，生产环境副本数建议设置为 1（设置 1 个副本，集群任意 1 个节点宕机数据不会丢失；设置更多副本会占用更多存储空间，操作系统缓存命中率会下降，检索性能不一定提升）。单节点索引分片数建议不要超过 3 个，每个索引分片推荐 10-40GB 大小，索引分片数设置后不可以修改，副本数设置后可以修改。<br>Elasticsearch6.X 及之前的版本默认索引分片数为 5、副本数为 1，从 Elasticsearch7.0 开始调整为默认索引分片数为 1、副本数为 1。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"># 索引设置</span><br><span class="line">curl -XPUT http://localhost:9200/fulltext001?pretty -H &apos;Content-Type: application/json&apos;   </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;refresh_interval&quot;: &quot;30s&quot;,</span><br><span class="line">        &quot;merge.policy.max_merged_segment&quot;: &quot;1000mb&quot;,</span><br><span class="line">        &quot;translog.durability&quot;: &quot;async&quot;,</span><br><span class="line">        &quot;translog.flush_threshold_size&quot;: &quot;2gb&quot;,</span><br><span class="line">        &quot;translog.sync_interval&quot;: &quot;100s&quot;,</span><br><span class="line">        &quot;index&quot;: &#123;</span><br><span class="line">            &quot;number_of_shards&quot;: &quot;21&quot;,</span><br><span class="line">            &quot;number_of_replicas&quot;: &quot;0&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># mapping 设置</span><br><span class="line">curl -XPOST http://localhost:9200/fulltext001/doc/_mapping?pretty  -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;doc&quot;: &#123;</span><br><span class="line">        &quot;_all&quot;: &#123;</span><br><span class="line">            &quot;enabled&quot;: false</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;content&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                &quot;analyzer&quot;: &quot;ik_max_word&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;id&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 写入数据示例</span><br><span class="line">curl -XPUT &apos;http://localhost:9200/fulltext001/doc/1?pretty&apos; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;id&quot;: &quot;https://www.huxiu.com/article/215169.html&quot;,</span><br><span class="line">    &quot;content&quot;: &quot;“娃娃机，迷你KTV，VR体验馆，堪称商场三大标配‘神器’。”一家地处商业中心的大型综合体负责人告诉懂懂笔记，在过去的这几个月里，几乎所有的综合体都“标配”了这三种“设备”…&quot;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 修改副本数示例</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/fulltext001/_settings&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;number_of_replicas&quot;: 1</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="2-使用批量请求"><a href="#2-使用批量请求" class="headerlink" title="2. 使用批量请求"></a>2. 使用批量请求</h2><p>使用批量请求将产生比单文档索引请求好得多的性能。写入数据时调用批量提交接口，推荐每批量提交 5~15MB 数据。例如单条记录 1KB 大小，每批次提交 10000 条左右记录写入性能较优；单条记录 5KB 大小，每批次提交 2000 条左右记录写入性能较优。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 批量请求接口API</span><br><span class="line">curl -XPOST &quot;http://localhost:9200/_bulk&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;</span><br><span class="line">&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot; &#125; &#125;&#123; &quot;field1&quot; : &quot;value1&quot; &#125;</span><br><span class="line">&#123; &quot;delete&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;create&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;3&quot; &#125; &#125;&#123; &quot;field1&quot; : &quot;value3&quot; &#125;</span><br><span class="line">&#123; &quot;update&quot; : &#123;&quot;_id&quot; : &quot;1&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_index&quot; : &quot;test&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;field2&quot; : &quot;value2&quot;&#125; &#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="3-通过多进程-线程发送数据"><a href="#3-通过多进程-线程发送数据" class="headerlink" title="3. 通过多进程/线程发送数据"></a>3. 通过多进程/线程发送数据</h2><p>单线程批量写入数据往往不能充分利用服务器 CPU 资源，可以尝试调整写入线程数或者在多个客户端上同时向 Elasticsearch 服务器提交写入请求。与批量调整大小请求类似，只有测试才能确定最佳的 worker 数量。可以通过逐渐增加工作任务数量来测试，直到集群上的 I/O 或 CPU 饱和。</p><h2 id="4-调大refresh-interval"><a href="#4-调大refresh-interval" class="headerlink" title="4. 调大refresh interval"></a>4. 调大refresh interval</h2><p>在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。<br>并不是所有的情况都需要每秒刷新。可能你正在使用 Elasticsearch 索引大量的日志文件，你可能想优化索引速度而不是近实时搜索，可以通过设置 refresh_interval，降低每个索引的刷新频率。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 设置 refresh interval API</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/index&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;refresh_interval&quot;: &quot;30s&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><p>refresh_interval 可以在已经存在的索引上进行动态更新，在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &quot;http://localhost:9200/index/_settings&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123; &quot;refresh_interval&quot;: -1 &#125;&apos;</span><br><span class="line"></span><br><span class="line">curl -XPUT &quot;http://localhost:9200/index/_settings&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123; &quot;refresh_interval&quot;: &quot;1s&quot; &#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="5-配置事务日志参数"><a href="#5-配置事务日志参数" class="headerlink" title="5. 配置事务日志参数"></a>5. 配置事务日志参数</h2><p>事务日志 translog 用于防止节点失败时的数据丢失。它的设计目的是帮助 shard 恢复操作，否则数据可能会从内存 flush 到磁盘时发生意外而丢失。事务日志 translog 的落盘(fsync)是 ES 在后台自动执行的，默认每 5 秒钟提交到磁盘上，或者当 translog 文件大小大于 512MB 提交，或者在每个成功的索引、删除、更新或批量请求时提交。<br>索引创建时，可以调整默认日志刷新间隔 5 秒，例如改为 60 秒，index.translog.sync_interval: “60s”。创建索引后，可以动态调整 translog 参数，”index.translog.durability”:”async” 相当于关闭了 index、bulk 等操作的同步 flush translog 操作，仅使用默认的定时刷新、文件大小阈值刷新的机制。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 动态设置 translog API</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/index&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;index.translog.durability&quot;: &quot;async&quot;,</span><br><span class="line">        &quot;translog.flush_threshold_size&quot;: &quot;2gb&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="6-设计mapping配置合适的字段类型"><a href="#6-设计mapping配置合适的字段类型" class="headerlink" title="6. 设计mapping配置合适的字段类型"></a>6. 设计mapping配置合适的字段类型</h2><p>Elasticsearch 在写入文档时，如果请求中指定的索引名不存在，会自动创建新索引，并根据文档内容猜测可能的字段类型。但这往往不是最高效的，我们可以根据应用场景来设计合理的字段类型。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 例如写入一条记录</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/twitter/doc/1?pretty&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;user&quot;: &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot;: &quot;2009-11-15T13:12:00&quot;,</span><br><span class="line">    &quot;message&quot;: &quot;Trying out Elasticsearch, so far so good?&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><p>查询 Elasticsearch 自动创建的索引 mapping，会发现将 post_date 字段自动识别为 date 类型，但是 message 和 user 字段被设置为 text、keyword 冗余字段，造成写入速度降低、占用更多磁盘空间。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;twitter&quot;: &#123;</span><br><span class="line">        &quot;mappings&quot;: &#123;</span><br><span class="line">            &quot;doc&quot;: &#123;</span><br><span class="line">                &quot;properties&quot;: &#123;</span><br><span class="line">                    &quot;message&quot;: &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                        &quot;fields&quot;: &#123;</span><br><span class="line">                            &quot;keyword&quot;: &#123;</span><br><span class="line">                                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                                &quot;ignore_above&quot;: 256</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;post_date&quot;: &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;date&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;user&quot;: &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                        &quot;fields&quot;: &#123;</span><br><span class="line">                            &quot;keyword&quot;: &#123;</span><br><span class="line">                                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                                &quot;ignore_above&quot;: 256</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;settings&quot;: &#123;</span><br><span class="line">            &quot;index&quot;: &#123;</span><br><span class="line">                &quot;number_of_shards&quot;: &quot;5&quot;,</span><br><span class="line">                &quot;number_of_replicas&quot;: &quot;1&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>根据业务场景设计索引配置合理的分片数、副本数，设置字段类型、分词器。如果不需要合并全部字段，禁用 _all 字段，通过 copy_to 来合并字段。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &quot;http://localhost:9200/twitter?pretty&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;index&quot;: &#123;</span><br><span class="line">            &quot;number_of_shards&quot;: &quot;20&quot;,</span><br><span class="line">            &quot;number_of_replicas&quot;: &quot;0&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line">curl -XPOST &quot;http://localhost:9200/twitter/doc/_mapping?pretty&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;doc&quot;: &#123;</span><br><span class="line">        &quot;_all&quot;: &#123;</span><br><span class="line">            &quot;enabled&quot;: false</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;user&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;post_date&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;date&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;message&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                &quot;analyzer&quot;: &quot;cjk&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h1 id="查询性能调优建议"><a href="#查询性能调优建议" class="headerlink" title="查询性能调优建议"></a>查询性能调优建议</h1><h2 id="1-使用过滤器缓存和分片查询缓存"><a href="#1-使用过滤器缓存和分片查询缓存" class="headerlink" title="1. 使用过滤器缓存和分片查询缓存"></a>1. 使用过滤器缓存和分片查询缓存</h2><p>默认情况下，Elasticsearch 的查询会计算返回的每条数据与查询语句的相关度，但对于非全文索引的使用场景，用户并不关心查询结果与查询条件的相关度，只是想精确地查找目标数据。此时，可以通过 filter 来让 Elasticsearch 不计算评分，并且尽可能地缓存 filter 的结果集，供后续包含相同 filter 的查询使用，提高查询效率。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 普通查询</span><br><span class="line">curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">            &quot;user&quot;: &quot;kimchy&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 过滤器(filter)查询</span><br><span class="line">curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;filter&quot;: &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                    &quot;user&quot;: &quot;kimchy&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><p>分片查询缓存的目的是缓存聚合、提示词结果和命中数（它不会缓存返回的文档，因此，它只在 search_type=count 时起作用）。<br>通过下面的参数我们可以设置分片缓存的大小，默认情况下是 JVM 堆的 1% 大小，当然我们也可以手动设置在 config/elasticsearch.yml 文件里。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">indices.requests.cache.size: 1%</span><br></pre></td></tr></table></figure><p></p><p>查看缓存占用内存情况(name 表示节点名, query_cache 表示过滤器缓存，request_cache 表示分片缓存，fielddata 表示字段数据缓存，segments 表示索引段)。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET &quot;http://localhost:9200/_cat/nodes?h=name,query_cache.memory_size,request_cache.memory_size,fielddata.memory_size,segments.memory&amp;v&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="2-使用路由-routing"><a href="#2-使用路由-routing" class="headerlink" title="2. 使用路由 routing"></a>2. 使用路由 routing</h2><p>Elasticsearch写入文档时，文档会通过一个公式路由到一个索引中的一个分片上。默认的公式如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shard_num = hash(_routing) % num_primary_shards</span><br></pre></td></tr></table></figure><p></p><p><code>_routing</code> 字段的取值，默认是 <code>_id</code> 字段，可以根据业务场景设置经常查询的字段作为路由字段。例如可以考虑将用户 id、地区作为路由字段，查询时可以过滤不必要的分片，加快查询速度。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># 写入时指定路由</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/my_index/my_type/1?routing=user1&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;title&quot;: &quot;This is a document&quot;,</span><br><span class="line">    &quot;author&quot;: &quot;user1&quot;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 查询时不指定路由，需要查询所有分片</span><br><span class="line">curl -XGET &quot;http://localhost:9200/my_index/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">            &quot;title&quot;: &quot;document&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 返回结果</span><br><span class="line">&#123;</span><br><span class="line">    &quot;took&quot;: 2,</span><br><span class="line">    &quot;timed_out&quot;: false,</span><br><span class="line">    &quot;_shards&quot;: &#123;</span><br><span class="line">        &quot;total&quot;: 5,</span><br><span class="line">        &quot;successful&quot;: 5,</span><br><span class="line">        &quot;skipped&quot;: 0,</span><br><span class="line">        &quot;failed&quot;: 0</span><br><span class="line">    &#125;</span><br><span class="line">    ... ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询时指定路由，只需要查询1个分片</span><br><span class="line">curl -XGET &quot;http://localhost:9200/my_index/_search?routing=user1&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">            &quot;title&quot;: &quot;document&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 返回结果</span><br><span class="line">&#123;</span><br><span class="line">    &quot;took&quot;: 1,</span><br><span class="line">    &quot;timed_out&quot;: false,</span><br><span class="line">    &quot;_shards&quot;: &#123;</span><br><span class="line">        &quot;total&quot;: 1,</span><br><span class="line">        &quot;successful&quot;: 1,</span><br><span class="line">        &quot;skipped&quot;: 0,</span><br><span class="line">        &quot;failed&quot;: 0</span><br><span class="line">    &#125;</span><br><span class="line">    ... ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h2 id="3-强制合并只读索引，关闭历史数据索引"><a href="#3-强制合并只读索引，关闭历史数据索引" class="headerlink" title="3. 强制合并只读索引，关闭历史数据索引"></a>3. 强制合并只读索引，关闭历史数据索引</h2><p>只读索引可以从合并成一个单独的大 segment 中收益，减少索引碎片，减少 JVM 堆常驻内存。强制合并索引操作会耗费大量磁盘 IO，尽量配置在业务低峰期(例如凌晨)执行。历史数据索引如果业务上不再支持查询请求，可以考虑关闭索引，减少 JVM 内存占用。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 索引forcemerge API</span><br><span class="line">curl -XPOST &quot;http://localhost:9200/abc20180923/_forcemerge?max_num_segments=1&quot;</span><br><span class="line"></span><br><span class="line"># 索引关闭API</span><br><span class="line">curl -XPOST &quot;http://localhost:9200/abc2017*/_close&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="4-配置合适的分词器"><a href="#4-配置合适的分词器" class="headerlink" title="4. 配置合适的分词器"></a>4. 配置合适的分词器</h2><p>Elasticsearch 内置了很多分词器，包括 standard、cjk、nGram 等，也可以安装自研/开源分词器。根据业务场景选择合适的分词器，避免全部采用默认 standard 分词器。</p><p>常用分词器：</p><ul><li>standard：默认分词，英文按空格切分，中文按照单个汉字切分。</li><li>cjk：根据二元索引对中日韩文分词，可以保证查全率。</li><li>nGram：可以将英文按照字母切分，结合ES的短语搜索(match_phrase)使用。</li><li>IK：比较热门的中文分词，能按照中文语义切分，可以自定义词典。</li><li>pinyin：可以让用户输入拼音，就能查找到相关的关键词。</li><li>aliws：阿里巴巴自研分词，支持多种模型和分词算法，词库丰富，分词结果准确，适用于电商等对查准要求高的场景。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 分词效果测试API</span><br><span class="line">curl -XPOST &quot;http://localhost:9200/_analyze&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;analyzer&quot;: &quot;ik_max_word&quot;,</span><br><span class="line">    &quot;text&quot;: &quot;南京市长江大桥&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h2 id="5-配置查询聚合节点"><a href="#5-配置查询聚合节点" class="headerlink" title="5. 配置查询聚合节点"></a>5. 配置查询聚合节点</h2><p>查询聚合节点可以发送粒子查询请求到其他节点，收集和合并结果，以及响应发出查询的客户端。通过给查询聚合节点配置更高规格的 CPU 和内存，可以加快查询运算速度、提升缓存命中率。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询聚合节点配置(conf/elasticsearch.yml)：</span><br><span class="line">node.master:false</span><br><span class="line">node.data:false</span><br><span class="line">node.ingest:false</span><br></pre></td></tr></table></figure><p></p><h2 id="6-设置查询读取记录条数和字段"><a href="#6-设置查询读取记录条数和字段" class="headerlink" title="6. 设置查询读取记录条数和字段"></a>6. 设置查询读取记录条数和字段</h2><p>默认的查询请求通常返回排序后的前 10 条记录，最多一次读取 10000 条记录，通过 from 和 size 参数控制读取记录范围，避免一次读取过多的记录。通过 _source 参数可以控制返回字段信息，尽量避免读取大字段。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 查询请求示例</span><br><span class="line">curl -XGET http://localhost:9200/fulltext001/_search?pretty  -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;from&quot;: 0,</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;_source&quot;: &quot;id&quot;,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;must&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;match&quot;: &#123;</span><br><span class="line">                        &quot;content&quot;: &quot;虎嗅&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;sort&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;id&quot;: &#123;</span><br><span class="line">                &quot;order&quot;: &quot;asc&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="7-设置-teminate-after-查询快速返回"><a href="#7-设置-teminate-after-查询快速返回" class="headerlink" title="7. 设置 teminate_after 查询快速返回"></a>7. 设置 teminate_after 查询快速返回</h2><p>如果不需要精确统计查询命中记录条数，可以配 teminate_after 指定每个 shard 最多匹配 N 条记录后返回，设置查询超时时间 timeout。在查询结果中可以通过 “terminated_early” 字段标识是否提前结束查询请求。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># teminate_after 查询语法示例</span><br><span class="line">curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;from&quot;: 0,</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;timeout&quot;: &quot;10s&quot;,</span><br><span class="line">    &quot;terminate_after&quot;: 1000,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;filter&quot;: &#123;</span><br><span class="line">                &quot;term&quot;: &#123;</span><br><span class="line">                    &quot;user&quot;: &quot;elastic&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="8-避免查询深度翻页"><a href="#8-避免查询深度翻页" class="headerlink" title="8. 避免查询深度翻页"></a>8. 避免查询深度翻页</h2><p>Elasticsearch 默认只允许查看排序前 10000 条的结果，当翻页查看排序靠后的记录时，响应耗时一般较长。使用 search_after 方式查询会更轻量级，如果每次只需要返回 10 条结果，则每个 shard 只需要返回 search_after 之后的 10 个结果即可，返回的总数据量只是和 shard 个数以及本次需要的个数有关，和历史已读取的个数无关。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># search_after查询语法示例</span><br><span class="line">curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">            &quot;message&quot;: &quot;Elasticsearch&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;sort&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;_score&quot;: &#123;</span><br><span class="line">                &quot;order&quot;: &quot;desc&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;_id&quot;: &#123;</span><br><span class="line">                &quot;order&quot;: &quot;asc&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;search_after&quot;: [</span><br><span class="line">        0.84290016,     //上一次response中某个doc的score</span><br><span class="line">        &quot;1024&quot;          //上一次response中某个doc的id</span><br><span class="line">    ]</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="9-避免前缀模糊匹配"><a href="#9-避免前缀模糊匹配" class="headerlink" title="9. 避免前缀模糊匹配"></a>9. 避免前缀模糊匹配</h2><p>Elasticsearch 默认支持通过 <em>? 正则表达式来做模糊匹配，如果在一个数据量较大规模的索引上执行模糊匹配，尤其是前缀模糊匹配，通常耗时会比较长，甚至可能导致内存溢出。尽量避免在高并发查询请求的生产环境执行这类操作。<br>某客户需要对车牌号进行模糊查询，通过查询请求 “车牌号:</em>A8848*” 查询时，往往导致整个集群负载较高。通过对数据预处理，增加冗余字段 “车牌号.keyword”，并事先将所有车牌号按照1元、2元、3元…7元分词后存储至该字段，字段存储内容示例：沪,A,8,4,沪A,A8,88,84,48,沪A8…沪A88488。通过查询”车牌号.keyword:A8848”即可解决原来的性能问题。</p><h2 id="10-避免索引稀疏"><a href="#10-避免索引稀疏" class="headerlink" title="10. 避免索引稀疏"></a>10. 避免索引稀疏</h2><p>Elasticsearch6.X 之前的版本默认允许在一个 index 下面创建多个 type，Elasticsearch6.X 版本只允许创建一个 type，Elasticsearch7.X 版本只允许 type 值为 “_doc”。在一个索引下面创建多个字段不一样的 type，或者将几百个字段不一样的索引合并到一个索引中，会导致索引稀疏问题。<br>建议每个索引下只创建一个 type，字段不一样的数据分别独立创建 index，不要合并成一个大索引。每个查询请求根据需要去读取相应的索引，避免查询大索引扫描全部记录，加快查询速度。</p><h2 id="11-扩容集群节点个数，升级节点规格"><a href="#11-扩容集群节点个数，升级节点规格" class="headerlink" title="11. 扩容集群节点个数，升级节点规格"></a>11. 扩容集群节点个数，升级节点规格</h2><p>通常服务器节点数越多，服务器硬件配置规格越高，Elasticsearch 集群的处理能力越强。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;Elasticsearch部署建议&quot;&gt;&lt;a href=&quot;#Elasticsearch部署建议&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch部署建议&quot;&gt;&lt;/a&gt;Elasticsearch部署建议&lt;/h1&gt;&lt;h2 id=&quot;1-选择合理的硬件配置：尽可能使用-SSD&quot;&gt;&lt;a href=&quot;#1-选择合理的硬件配置：尽可能使用-SSD&quot; class=&quot;headerlink&quot; title=&quot;1. 选择合理的硬件配置：尽可能使用 SSD&quot;&gt;&lt;/a&gt;1. 选择合理的硬件配置：尽可能使用 SSD&lt;/h2&gt;&lt;p&gt;Elasticsearch 最大的瓶颈往往是磁盘读写性能，尤其是随机读取性能。使用SSD（PCI-E接口SSD卡/SATA接口SSD盘）通常比机械硬盘（SATA盘/SAS盘）查询速度快5~10倍，写入性能提升不明显。&lt;br&gt;对于文档检索类查询性能要求较高的场景，建议考虑 SSD 作为存储，同时按照 1:10 的比例配置内存和硬盘。对于日志分析类查询并发要求较低的场景，可以考虑采用机械硬盘作为存储，同时按照 1:50 的比例配置内存和硬盘。单节点存储数据建议在2TB以内，不要超过5TB，避免查询速度慢、系统不稳定。&lt;/p&gt;&lt;h2 id=&quot;2-给JVM配置机器一半的内存，但是不建议超过32G&quot;&gt;&lt;a href=&quot;#2-给JVM配置机器一半的内存，但是不建议超过32G&quot; class=&quot;headerlink&quot; title=&quot;2. 给JVM配置机器一半的内存，但是不建议超过32G&quot;&gt;&lt;/a&gt;2. 给JVM配置机器一半的内存，但是不建议超过32G&lt;/h2&gt;&lt;p&gt;修改 conf/jvm.options 配置，-Xms 和 -Xmx 设置为相同的值，推荐设置为机器内存的一半左右，剩余一半留给操作系统缓存使用。JVM 内存建议不要低于 2G，否则有可能因为内存不足导致 ES 无法正常启动或内存溢出，JVM 建议不要超过 32G，否则 JVM 会禁用内存对象指针压缩技术，造成内存浪费。机器内存大于 64G 内存时，推荐配置 -Xms30g -Xmx30g。JVM 堆内存较大时，内存垃圾回收暂停时间比较长，建议配置 ZGC 或 G1 垃圾回收算法。&lt;/p&gt;&lt;h2 id=&quot;3-规模较大的集群配置专有主节点，避免脑裂问题&quot;&gt;&lt;a href=&quot;#3-规模较大的集群配置专有主节点，避免脑裂问题&quot; class=&quot;headerlink&quot; title=&quot;3. 规模较大的集群配置专有主节点，避免脑裂问题&quot;&gt;&lt;/a&gt;3. 规模较大的集群配置专有主节点，避免脑裂问题&lt;/h2&gt;&lt;p&gt;Elasticsearch 主节点负责集群元信息管理、index 的增删操作、节点的加入剔除，定期将最新的集群状态广播至各个节点。在集群规模较大时，建议配置专有主节点只负责集群管理，不存储数据，不承担数据读写压力。&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 专有主节点配置(conf/elasticsearch.yml)：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.master:true&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.data: false&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.ingest:false&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 数据节点配置(conf/elasticsearch.yml)：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.master:false&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.data:true&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.ingest:true&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Elasticsearch 默认每个节点既是候选主节点，又是数据节点。最小主节点数量参数 minimum_master_nodes 推荐配置为候选主节点数量一半以上，该配置告诉 Elasticsearch 当没有足够的 master 候选节点的时候，不进行 master 节点选举，等 master 节点足够了才进行选举。&lt;br&gt;例如对于 3 节点集群，最小主节点数量从默认值 1 改为 2。&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 最小主节点数量配置(conf/elasticsearch.yml)：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;discovery.zen.minimum_master_nodes: 2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/categories/elk/Elasticsearch/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Logstash集成GaussDB(高斯DB)数据到Elasticsearch</title>
    <link href="https://yongnights.github.io/2020/04/03/Logstash%E9%9B%86%E6%88%90GaussDB(%E9%AB%98%E6%96%AFDB)%E6%95%B0%E6%8D%AE%E5%88%B0Elasticsearch/"/>
    <id>https://yongnights.github.io/2020/04/03/Logstash集成GaussDB(高斯DB)数据到Elasticsearch/</id>
    <published>2020-04-03T01:17:06.856Z</published>
    <updated>2020-04-03T01:30:57.339Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><h1 id="GaussDB-简介"><a href="#GaussDB-简介" class="headerlink" title="GaussDB 简介"></a>GaussDB 简介</h1><p>GaussDB 数据库分为 GaussDB T 和 GaussDB A，分别面向 OLTP 和 OLAP 的业务用户。<br>GaussDB T 数据库是华为公司全自研的分布式数据库，支持x86和华为鲲鹏硬件架构。基于创新性数据库内核，提供高并发事务实时处理能力、两地三中心金融级高可用能力和分布式高扩展能力。<br>GaussDB A 是一款具备分析及混合负载能力的分布式数据库，支持x86和华为鲲鹏硬件架构，支持行存储与列存储，提供PB级数据分析能力、多模分析能力和实时处理能力，用于数据仓库、数据集市、实时分析、实时决策和混合负载等场景，广泛应用于金融、政府、电信等行业核心系统。</p><h1 id="Logstash-的-jdbc-input-plugin"><a href="#Logstash-的-jdbc-input-plugin" class="headerlink" title="Logstash 的 jdbc input plugin"></a>Logstash 的 jdbc input plugin</h1><p>参考 Logstash的 Jdbc input plugin 的官方文档，该插件可以通过JDBC接口将任何数据库中的数据导入 Logstash。周期性加载或一次加载，每一行是一个 event，列转成 filed。我们先解读下文档里提到的重要配置项。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">jdbc_driver_library：JDBC驱动包路径。</span><br><span class="line">jdbc_driver_class：JDBC驱动程序类。</span><br><span class="line">jdbc_connection_string：JDBC连接串。</span><br><span class="line">jdbc_user：数据库用户名。</span><br><span class="line">jdbc_password：数据库用户口令。</span><br><span class="line">statement_filepath：SQL语句所在文件路径。</span><br><span class="line">scheduler：调度计划。</span><br></pre></td></tr></table></figure><p></p><a id="more"></a><p>以上参数已经支持了周期性加载或一次性加载。如果想按字段的自增列或时间戳来集成数据，还需要以下参数：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sql_last_value：这个参数内置在sql语句里。作为条件的变量值。</span><br><span class="line">last_run_metadata_path：sql_last_value 上次运行值所在的文件路径。</span><br><span class="line">use_column_value：设置为时true时，将定义的 tracking_column 值用作 :sql_last_value。默认false。</span><br><span class="line">tracking_column：值设置为将被跟踪的列。</span><br><span class="line">tracking_column_type：跟踪列的类型。目前仅支持数字和时间戳。</span><br><span class="line">record_last_run：上次运行 sql_last_value 值是否保存到 last_run_metadata_path。默认true。</span><br><span class="line">clean_run：是否应保留先前的运行状态。默认false。</span><br></pre></td></tr></table></figure><p></p><p>另外如果想使用预编译语句，语句里用？作为占位符，再增加以下参数：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">use_prepared_statements：设置为 true 时，启用预编译语句。</span><br><span class="line">prepared_statement_name：预编译语句名称。</span><br><span class="line">prepared_statement_bind_values：数组类型，存放绑定值。:sql_last_value 可以作为预定义参数。</span><br></pre></td></tr></table></figure><p></p><p>参考：<a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-inputs-jdbc.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/7.5/plugins-inputs-jdbc.html</a></p><h1 id="对接-GaussDB-T"><a href="#对接-GaussDB-T" class="headerlink" title="对接 GaussDB T"></a>对接 GaussDB T</h1><p>按每分钟一次频率的周期性来加载 GaussDB T 的会话信息到 Elasticsearch 中，input 区域的配置如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    jdbc &#123;</span><br><span class="line">      jdbc_connection_string =&gt; &quot;jdbc:zenith:@vip:40000&quot;</span><br><span class="line">      jdbc_user =&gt; &quot;omm&quot;</span><br><span class="line">      jdbc_password =&gt; &quot;omm_password&quot;</span><br><span class="line">      jdbc_driver_library =&gt; &quot;/opt/gs/com.huawei.gauss.jdbc.ZenithDriver-GaussDB_100_1.0.1.SPC2.B003.jar&quot;</span><br><span class="line">      jdbc_driver_class =&gt; &quot;com.huawei.gauss.jdbc.ZenithDriver&quot;</span><br><span class="line">      statement_filepath =&gt; &quot;/opt/statement_filepath/gs_100_session.sql&quot;</span><br><span class="line">      schedule =&gt; &quot;*/1 * * * *&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>statement_filepath 路径文件里配置的sql如下：<br></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dv_sessions</span><br></pre></td></tr></table></figure><p></p><p>启动 logstash，可以看到logstash 日志中显示有<code>select * from dv_sessions</code>的信息</p><h1 id="对接-GaussDB-A"><a href="#对接-GaussDB-A" class="headerlink" title="对接 GaussDB A"></a>对接 GaussDB A</h1><p>按字段的时间戳来增量加载数据，注意 GaussDB A 的驱动和 GaussDB T 是不同的。input 区域的配置如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    jdbc &#123;</span><br><span class="line">      jdbc_connection_string =&gt; &quot;jdbc:postgresql://vip:25308/postgres&quot;</span><br><span class="line">      jdbc_user =&gt; &quot;monitor&quot;</span><br><span class="line">      jdbc_password =&gt; &quot;monitor_password&quot;</span><br><span class="line">      jdbc_driver_library =&gt; &quot;/opt/gsdriver/gsjdbc4.jar&quot;</span><br><span class="line">      jdbc_driver_class =&gt; &quot;org.postgresql.Driver&quot;</span><br><span class="line">      statement_filepath =&gt; &quot;/opt/statement_filepath/gauss_active_session.sql&quot;</span><br><span class="line">      schedule =&gt; &quot;*/1 * * * *&quot;</span><br><span class="line">      record_last_run =&gt; &quot;true&quot;</span><br><span class="line">      use_column_value =&gt; &quot;true&quot;</span><br><span class="line">      tracking_column =&gt; &quot;sample_time&quot;</span><br><span class="line">      tracking_column_type =&gt; &quot;timestamp&quot;</span><br><span class="line">      clean_run =&gt; &quot;false&quot;</span><br><span class="line">      last_run_metadata_path =&gt; &quot;/opt/last_run_metadata_path/gauss_last_sample_time&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>statement_filepath 路径文件里配置的sql如下，注意里面的预定义变量 :sql_last_value。<br></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> clustername,coorname,sample_time,datid,datname,pid,usesysid,usename,application_name,abbrev(client_addr) <span class="keyword">AS</span> client_addr,client_hostname,client_port,backend_start,xact_start,query_start,state_change,waiting,<span class="keyword">enqueue</span>,state,resource_pool,query_id,<span class="keyword">query</span> <span class="keyword">from</span> monitor.ash_pg_stat_activity_r <span class="keyword">where</span> sample_time &gt; :sql_last_value</span><br></pre></td></tr></table></figure><p></p><p>last_run_metadata_path 路径下的文件内容：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--- 2020-02-05 12:10:00.000000000 +08:00</span><br></pre></td></tr></table></figure><p></p><p>启动 logstash，可以看到 logstash 日志，注意 :sql_last_value的地方</p><h1 id="数据-output-到-Elasticsearch"><a href="#数据-output-到-Elasticsearch" class="headerlink" title="数据 output 到 Elasticsearch"></a>数据 output 到 Elasticsearch</h1><p>logstash 的 output 区域的配置如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">output &#123;       </span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;https://vip:9200&quot;] </span><br><span class="line">        index =&gt; &quot;gauss_active_session-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        document_type =&gt; &quot;gauss_active_session&quot;</span><br><span class="line">        user =&gt; &quot;elastic&quot;</span><br><span class="line">        password =&gt; &quot;elastic_password&quot;</span><br><span class="line">        ssl =&gt; true</span><br><span class="line">        cacert =&gt; &quot;../es_client-ca.cer&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>登入 kibana 查看，按每分钟增量加载的会话表数据已经集成到了 elasticsearch，后续就可以开始做数据分析和可视化了。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;GaussDB-简介&quot;&gt;&lt;a href=&quot;#GaussDB-简介&quot; class=&quot;headerlink&quot; title=&quot;GaussDB 简介&quot;&gt;&lt;/a&gt;GaussDB 简介&lt;/h1&gt;&lt;p&gt;GaussDB 数据库分为 GaussDB T 和 GaussDB A，分别面向 OLTP 和 OLAP 的业务用户。&lt;br&gt;GaussDB T 数据库是华为公司全自研的分布式数据库，支持x86和华为鲲鹏硬件架构。基于创新性数据库内核，提供高并发事务实时处理能力、两地三中心金融级高可用能力和分布式高扩展能力。&lt;br&gt;GaussDB A 是一款具备分析及混合负载能力的分布式数据库，支持x86和华为鲲鹏硬件架构，支持行存储与列存储，提供PB级数据分析能力、多模分析能力和实时处理能力，用于数据仓库、数据集市、实时分析、实时决策和混合负载等场景，广泛应用于金融、政府、电信等行业核心系统。&lt;/p&gt;&lt;h1 id=&quot;Logstash-的-jdbc-input-plugin&quot;&gt;&lt;a href=&quot;#Logstash-的-jdbc-input-plugin&quot; class=&quot;headerlink&quot; title=&quot;Logstash 的 jdbc input plugin&quot;&gt;&lt;/a&gt;Logstash 的 jdbc input plugin&lt;/h1&gt;&lt;p&gt;参考 Logstash的 Jdbc input plugin 的官方文档，该插件可以通过JDBC接口将任何数据库中的数据导入 Logstash。周期性加载或一次加载，每一行是一个 event，列转成 filed。我们先解读下文档里提到的重要配置项。&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;jdbc_driver_library：JDBC驱动包路径。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdbc_driver_class：JDBC驱动程序类。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdbc_connection_string：JDBC连接串。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdbc_user：数据库用户名。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdbc_password：数据库用户口令。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;statement_filepath：SQL语句所在文件路径。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;scheduler：调度计划。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Logstash" scheme="https://yongnights.github.io/categories/elk/Logstash/"/>
    
      <category term="GaussDB" scheme="https://yongnights.github.io/categories/elk/Logstash/GaussDB/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/categories/elk/Logstash/GaussDB/Elasticsearch/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/tags/Elasticsearch/"/>
    
      <category term="Logstash" scheme="https://yongnights.github.io/tags/Logstash/"/>
    
      <category term="GaussDB" scheme="https://yongnights.github.io/tags/GaussDB/"/>
    
  </entry>
  
  <entry>
    <title>详细说明-CentOS7部署FastDFS+nginx模块</title>
    <link href="https://yongnights.github.io/2020/04/02/%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E-CentOS7%E9%83%A8%E7%BD%B2FastDFS+nginx%E6%A8%A1%E5%9D%97/"/>
    <id>https://yongnights.github.io/2020/04/02/详细说明-CentOS7部署FastDFS+nginx模块/</id>
    <published>2020-04-02T03:57:08.447Z</published>
    <updated>2020-04-02T06:47:32.648Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><h1 id="软件下载"><a href="#软件下载" class="headerlink" title="软件下载"></a>软件下载</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 已经事先把所需软件下载好并上传到/usr/local/src目录了</span><br><span class="line">https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs-client-java/archive/V1.28.tar.gz</span><br><span class="line">https://openresty.org/download/openresty-1.15.8.3.tar.gz</span><br></pre></td></tr></table></figure><h1 id="基础环境设置"><a href="#基础环境设置" class="headerlink" title="基础环境设置"></a>基础环境设置</h1><h2 id="安装依赖组件"><a href="#安装依赖组件" class="headerlink" title="安装依赖组件"></a>安装依赖组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install  gcc gcc-c++ libevent</span><br><span class="line">yum -y groupinstall &apos;Development Tools&apos;</span><br></pre></td></tr></table></figure><p><code><a id="more"></a></code></p><h2 id="安装libfastcommon"><a href="#安装libfastcommon" class="headerlink" title="安装libfastcommon"></a>安装libfastcommon</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf libfastcommon-1.0.43.tar.gz</span><br><span class="line">cd libfastcommon-1.0.43</span><br><span class="line">./make.sh</span><br><span class="line">./make.sh install</span><br><span class="line"></span><br><span class="line"># 检查文件是否存在，确保在/usr/lib路径下有libfastcommon.so和libfdfsclient.so</span><br><span class="line">ll /usr/lib | grep &quot;libf&quot;</span><br><span class="line">lrwxrwxrwx   1 root root     27 Apr  2 10:07 libfastcommon.so -&gt; /usr/lib64/libfastcommon.so</span><br><span class="line">-rwxr-xr-x   1 root root 356664 Apr  2 10:15 libfdfsclient.so</span><br></pre></td></tr></table></figure><h2 id="安装fastdfs"><a href="#安装fastdfs" class="headerlink" title="安装fastdfs"></a>安装fastdfs</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf fastdfs-6.06.tar.gz</span><br><span class="line">cd fastdfs-6.06</span><br><span class="line">./make.sh</span><br><span class="line">./make.sh install</span><br><span class="line"></span><br><span class="line"># FastDFS的配置文件默认安装到/etc/fdfs目录下</span><br><span class="line"></span><br><span class="line"># 安装成功后将fastdfs-6.06/conf下的俩文件拷贝到/etc/fdfs/下</span><br><span class="line">cd conf</span><br><span class="line">cp http.conf mime.types /etc/fdfs/</span><br><span class="line">cd /etc/fdfs/</span><br><span class="line">[root@bogon fdfs]# ll</span><br><span class="line">total 68</span><br><span class="line">-rw-r--r-- 1 root root  1909 Apr  2 10:15 client.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root   965 Apr  2 10:16 http.conf</span><br><span class="line">-rw-r--r-- 1 root root 31172 Apr  2 10:16 mime.types</span><br><span class="line">-rw-r--r-- 1 root root 10246 Apr  2 10:15 storage.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root   620 Apr  2 10:15 storage_ids.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root  9138 Apr  2 10:15 tracker.conf.sample</span><br></pre></td></tr></table></figure><h3 id="fdfs-trackerd配置并启动"><a href="#fdfs-trackerd配置并启动" class="headerlink" title="fdfs_trackerd配置并启动"></a>fdfs_trackerd配置并启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 创建tracker工作目录,storage存储目录(选择大磁盘空间)等</span><br><span class="line">mkdir -p /opt/&#123;fdfs_tracker,fdfs_storage,fdfs_storage_data&#125;</span><br><span class="line"></span><br><span class="line">cd /etc/fdfs/</span><br><span class="line">cp tracker.conf.sample tracker.conf</span><br><span class="line">vim tracker.conf</span><br><span class="line">    disabled = false # 配置tracker.conf这个配置文件是否生效，因为在启动fastdfs服务端进程时需要指定配置文件，所以需要使次配置文件生效。false是生效，true是屏蔽。</span><br><span class="line">    bind_addr = # 程序的监听地址，如果不设定则监听所有地址，可以设置本地ip地址</span><br><span class="line">    port = 22122 #tracker监听的端口</span><br><span class="line">    base_path = /opt/fdfs_tracker # tracker保存data和logs的路径</span><br><span class="line">    http.server_port=8080 # http服务端口，保持默认</span><br><span class="line"></span><br><span class="line"># 启动fdfs_trackerd</span><br><span class="line">/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</span><br><span class="line"></span><br><span class="line"># 查看/opt/fdfs_tracker目录，发现目录下多了data和logs两个目录</span><br><span class="line"></span><br><span class="line"># 查看端口号，验证启动情况</span><br><span class="line">[root@bogon fdfs]# ps -ef | grep fdfs</span><br><span class="line">root       2119      1  0 10:22 ?        00:00:00 /usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</span><br><span class="line">[root@bogon fdfs]# ss -tulnp | grep 22122</span><br><span class="line">tcp    LISTEN     0      128       *:22122      *:*    users:((&quot;fdfs_trackerd&quot;,pid=2119,fd=5))</span><br><span class="line"></span><br><span class="line"># 命令行选项</span><br><span class="line">Usage: /usr/bin/fdfs_trackerd &lt;config_file&gt; [start|stop|restart]</span><br><span class="line"></span><br><span class="line"># 设置开机自启动</span><br><span class="line">echo &quot;/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart&quot; | tee -a /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h3 id="fdfs-storage配置并启动"><a href="#fdfs-storage配置并启动" class="headerlink" title="fdfs_storage配置并启动"></a>fdfs_storage配置并启动</h3><p>与tracker不同的是，storage还需要一个目录用来存储数据，所以在上面步骤中另外多建了两个目录fdfs_storage_data,fdfs_storage<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp storage.conf.sample storage.conf</span><br><span class="line">vim storage.conf</span><br><span class="line">    disabled=false # 启用这个配置文件</span><br><span class="line">    group_name=group1 #组名，根据实际情况修改，文件链接中会用到</span><br><span class="line">    port=23000 #设置storage的端口号，默认是23000，同一个组的storage端口号必须一致</span><br><span class="line">    base_path = /opt/fdfs_storage # #设置storage数据文件和日志目录，注意,这个目录最好有大于50G的磁盘空间</span><br><span class="line">    store_path_count=1 #存储路径个数，需要和store_path个数匹配 </span><br><span class="line">    store_path0 = /opt/fdfs_storage_data # 实际保存文件的路径，注意,这个目录最好有大于50G的磁盘空间</span><br><span class="line">    tracker_server = 192.168.75.5:22122 # tracker监听地址和端口号，要与tracker.conf文件中设置的保持一致</span><br><span class="line">    http.server_port=8888 #设置 http 端口号</span><br><span class="line">    </span><br><span class="line"># 启动fdfs_storaged</span><br><span class="line">/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</span><br><span class="line"></span><br><span class="line"># 查看端口号，验证启动情况</span><br><span class="line">[root@bogon fdfs]# ps -ef | grep &quot;fdfs_storaged&quot;</span><br><span class="line">root       2194      1  7 10:36 ?        00:00:01 /usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</span><br><span class="line">[root@bogon fdfs]# ss -tulnp | grep &quot;fdfs&quot;</span><br><span class="line">tcp    LISTEN     0      128       *:23000      *:*     users:((&quot;fdfs_storaged&quot;,pid=2194,fd=5))</span><br><span class="line">tcp    LISTEN     0      128       *:22122      *:*     users:((&quot;fdfs_trackerd&quot;,pid=2119,fd=5))</span><br><span class="line"></span><br><span class="line"># 命令行选项</span><br><span class="line">Usage: /usr/bin/fdfs_trackerd &lt;config_file&gt; [start|stop|restart]</span><br><span class="line"></span><br><span class="line"># 设置开机自启动</span><br><span class="line">echo &quot;/usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart&quot; | tee -a /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><p></p><h3 id="校验整合"><a href="#校验整合" class="headerlink" title="校验整合"></a>校验整合</h3><p>要确定一下，storage是否注册到了tracker中去<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/fdfs_monitor /etc/fdfs/storage.conf</span><br></pre></td></tr></table></figure><p></p><p>成功后可以看到：ip_addr = 192.168.75.5 ACTIVE</p><h3 id="使用FastDFS自带工具测试"><a href="#使用FastDFS自带工具测试" class="headerlink" title="使用FastDFS自带工具测试"></a>使用FastDFS自带工具测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp client.conf.sample client.conf</span><br><span class="line">vim client.conf</span><br><span class="line">    base_path = /opt/fdfs_tracker # tracker服务器文件路径</span><br><span class="line">    tracker_server = 192.168.75.5:22122 #tracker服务器IP地址和端口号</span><br><span class="line">    http.tracker_server_port = 8080 # tracker服务器的http端口号,必须和tracker的设置对应起来</span><br></pre></td></tr></table></figure><p>上传一张图片1.jpg到Centos服务器上的 /tmp 目录下，进行测试，命令如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/fdfs_test /etc/fdfs/client.conf upload /tmp/1.jpg</span><br><span class="line">This is FastDFS client test program v6.06</span><br><span class="line"></span><br><span class="line">Copyright (C) 2008, Happy Fish / YuQing</span><br><span class="line"></span><br><span class="line">FastDFS may be copied only under the terms of the GNU General</span><br><span class="line">Public License V3, which may be found in the FastDFS source kit.</span><br><span class="line">Please visit the FastDFS Home Page http://www.fastken.com/ </span><br><span class="line">for more detail.</span><br><span class="line"></span><br><span class="line">[2020-04-02 10:47:57] DEBUG - base_path=/opt/fdfs_tracker, connect_timeout=5, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0</span><br><span class="line"></span><br><span class="line">tracker_query_storage_store_list_without_group: </span><br><span class="line">        server 1. group_name=, ip_addr=192.168.75.5, port=23000</span><br><span class="line"></span><br><span class="line">group_name=group1, ip_addr=192.168.75.5, port=23000</span><br><span class="line">storage_upload_by_filename</span><br><span class="line">group_name=group1, remote_filename=M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">source ip address: 192.168.75.5</span><br><span class="line">file timestamp=2020-04-02 10:47:58</span><br><span class="line">file size=2402082</span><br><span class="line">file crc32=779422649</span><br><span class="line">example file url: http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">storage_upload_slave_by_filename</span><br><span class="line">group_name=group1, remote_filename=M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br><span class="line">source ip address: 192.168.75.5</span><br><span class="line">file timestamp=2020-04-02 10:47:58</span><br><span class="line">file size=2402082</span><br><span class="line">file crc32=779422649</span><br><span class="line">example file url: http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br></pre></td></tr></table></figure><p></p><p>以上图中的文件地址：<a href="http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg对应storage服务器上的/opt/fdfs_storage_data/data/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg文件" target="_blank" rel="noopener">http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg对应storage服务器上的/opt/fdfs_storage_data/data/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg文件</a>;</p><blockquote><p>组名：group1<br>磁盘：M00<br>目录：00/00<br>文件名称：wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg<br>注意图片路径中的8080端口,这个是tracker的端口</p></blockquote><p>上传的图片会被上传到我们创建的fdfs_storage_data目录下，会有四个图片文件:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon 00]# pwd</span><br><span class="line">/opt/fdfs_storage_data/data/00/00</span><br><span class="line">[root@bogon 00]# ll</span><br><span class="line">total 4704</span><br><span class="line">-rw-r--r-- 1 root root 2402082 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br><span class="line">-rw-r--r-- 1 root root      49 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg-m</span><br><span class="line">-rw-r--r-- 1 root root 2402082 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">-rw-r--r-- 1 root root      49 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg-m</span><br></pre></td></tr></table></figure><p></p><p>data下有256个1级目录，每级目录下又有256个2级子目录，总共65536个文件，新写的文件会以hash的方式被路由到其中某个子目录下，然后将文件数据直接作为一个本地文件存储到该目录中。</p><h2 id="FastDFS和nginx结合使用"><a href="#FastDFS和nginx结合使用" class="headerlink" title="FastDFS和nginx结合使用"></a>FastDFS和nginx结合使用</h2><p>FastDFS通过Tracker服务器,将文件放在Storage服务器存储,但是同组之间的服务器需要复制文件,有延迟的问题.<br>假设Tracker服务器将文件上传到了172.20.132.57,文件ID已经返回客户端,这时,后台会将这个文件复制到172.20.132.57,如果复制没有完成,客户端就用这个ID在172.20.132.57取文件,肯定会出现错误。<br>这个fastdfs-nginx-module可以重定向连接到源服务器取文件,避免客户端由于复制延迟的问题,出现错误。<br>正是这样，FastDFS需要结合nginx，所以取消原来对HTTP的直接支持。</p><h3 id="在tracker上安装-nginx"><a href="#在tracker上安装-nginx" class="headerlink" title="在tracker上安装 nginx"></a>在tracker上安装 nginx</h3><p>在每个tracker上安装nginx的主要目的是做负载均衡及实现高可用。如果只有一台tracker服务器可以不配置nginx.<br>一个tracker对应多个storage，通过nginx对storage负载均衡;</p><h3 id="在storage上安装nginx-openresty"><a href="#在storage上安装nginx-openresty" class="headerlink" title="在storage上安装nginx(openresty)"></a>在storage上安装nginx(openresty)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src/</span><br><span class="line">tar -zxvf fastdfs-nginx-module-1.22.tar.gz</span><br><span class="line">cd fastdfs-nginx-module-1.22/src</span><br><span class="line">cp mod_fastdfs.conf /etc/fdfs/</span><br><span class="line">vim /etc/fdfs/mod_fastdfs.conf</span><br><span class="line">    base_path=/opt/fdfs_storage # 与storage.conf配置中的保持一致</span><br><span class="line">    tracker_server=192.168.75.5:22122 #tracker服务器的IP地址以及端口号</span><br><span class="line">    url_have_group_name = true # url中包含group名称</span><br><span class="line">    store_path0=/opt/fdfs_storage_data #与storage.conf中的路径保持一致</span><br><span class="line">    group_count = 1 #设置组的个数</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">yum -y install pcre pcre-devel openssl openssl-devel zlib zlib-devel </span><br><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf openresty-1.15.8.3.tar.gz</span><br><span class="line">cd openresty-1.15.8.3</span><br><span class="line">./configure \</span><br><span class="line">    --with-luajit \</span><br><span class="line">    --with-http_stub_status_module \</span><br><span class="line">    --with-http_ssl_module \</span><br><span class="line">    --with-http_realip_module \</span><br><span class="line">    --with-http_gzip_static_module \</span><br><span class="line">    --add-module=/usr/local/src/fastdfs-nginx-module-1.22/src</span><br><span class="line">gmake</span><br><span class="line">gmake install</span><br><span class="line"></span><br><span class="line"># 修改配置文件</span><br><span class="line">vim /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">    error_log  logs/error.log;</span><br><span class="line">    pid      logs/nginx.pid;</span><br><span class="line">    server&#123;</span><br><span class="line">        server_name  192.168.75.5; </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line"></span><br><span class="line"># 浏览器访问，出现openresty欢迎页面</span><br><span class="line"></span><br><span class="line"># 设置nginx开机启动</span><br><span class="line">echo &quot;/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf&quot; | tee -a /etc/rc.d/rc.local</span><br><span class="line"></span><br><span class="line"># 再次修改配置文件，加载fastdfs模块</span><br><span class="line">vim /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">    server&#123;</span><br><span class="line">        location /group1/M00/ &#123;</span><br><span class="line">            root /opt/fdfs_storage/data;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 重载nginx</span><br><span class="line">/usr/local/openresty/nginx/sbin/nginx -s reload</span><br><span class="line"></span><br><span class="line"># 参考上面测试的那一步图片url地址：http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">使用nginxf访问的话，实际地址是：http://192.168.75.5/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">需要把tracker使用的8080端口去掉，否则无法访问</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 进一步完善nginx配置文件</span><br><span class="line">    # 这个server设置的是storage nginx</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       9991;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location ~/group1/M00 &#123;</span><br><span class="line">            root /opt/fastdfs_storage/data;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # 若访问不到图片需要配置这个软连接</span><br><span class="line">    # ln -s /opt/fastdfs_storage_data/data/ /opt/fastdfs_storage_data/data/M00</span><br><span class="line">    </span><br><span class="line">    # 这个server设置的是tracker nginx</span><br><span class="line">    upstream fdfs_group1 &#123;</span><br><span class="line">        server 127.0.0.1:9991;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        </span><br><span class="line">        location /group1/M00 &#123;</span><br><span class="line">            proxy_pass http://fdfs_group1;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h1 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h1><h2 id="集群规划-单tracker-双storage"><a href="#集群规划-单tracker-双storage" class="headerlink" title="集群规划(单tracker,双storage)"></a>集群规划(单tracker,双storage)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">虚拟机     IP                 说明</span><br><span class="line">tracker 192.168.75.5 tracker 服务器</span><br><span class="line">storage01 192.168.75.6 storage01服务器【group1】</span><br><span class="line">storage02 192.168.75.7 storage02服务器【group2】</span><br></pre></td></tr></table></figure><h2 id="软件清单"><a href="#软件清单" class="headerlink" title="软件清单"></a>软件清单</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fastdfs-6.06.tar.gz</span><br><span class="line">fastdfs-client-java-1.28.tar.gz</span><br><span class="line">fastdfs-nginx-module-1.22.tar.gz</span><br><span class="line">libfastcommon-1.0.43.tar.gz</span><br><span class="line">openresty-1.15.8.3.tar.gz</span><br></pre></td></tr></table></figure><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><h3 id="1-tracker服务器"><a href="#1-tracker服务器" class="headerlink" title="1.tracker服务器"></a>1.tracker服务器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 1. 安装libfastcommon 模块</span><br><span class="line"># 2. 编译安装 FastDFS</span><br><span class="line"># 3. 修改配置文件tarcker.conf和client.conf(测试上传)</span><br><span class="line"></span><br><span class="line"># vim /etc/fdfs/tracker.conf</span><br><span class="line">    store_lookup=0  #采用轮询策略进行存储，0：轮询 1：始终定向到某个group 2：选择存储空间最大的进行存储</span><br><span class="line"></span><br><span class="line"># 4. 开机启动</span><br></pre></td></tr></table></figure><h3 id="2-storage服务器"><a href="#2-storage服务器" class="headerlink" title="2.storage服务器"></a>2.storage服务器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># 1. 安装libfastcommon 模块</span><br><span class="line"># 2. 编译安装 FastDFS</span><br><span class="line"># 3. 修改配置文件storage.conf</span><br><span class="line"></span><br><span class="line"># storage01 配置</span><br><span class="line"># vim /etc/fdfs/storage.conf</span><br><span class="line">group_name=group1</span><br><span class="line">base_path=/home/fastdfs_storage</span><br><span class="line">store_path0=/home/fastdfs_storage</span><br><span class="line">tracker_server=192.168.75.6:22122</span><br><span class="line">http.server_port=8888</span><br><span class="line"></span><br><span class="line"># storage02 配置</span><br><span class="line"># vim /etc/fdfs/storage.conf</span><br><span class="line">group_name=group2</span><br><span class="line">base_path=/home/fastdfs_storage</span><br><span class="line">store_path0=/home/fastdfs_storage</span><br><span class="line">tracker_server=192.168.75.7:22122</span><br><span class="line">http.server_port=8888</span><br><span class="line"></span><br><span class="line"># 4. 开机启动</span><br><span class="line"># 5. 安装nginx和fastdfs-nginx-module模块</span><br><span class="line"></span><br><span class="line"># storage01 配置：</span><br><span class="line"># vim /etc/fdfs/mod_fastdfs.conf</span><br><span class="line">connect_timeout=10</span><br><span class="line">base_path=/home/fastdfs_storage</span><br><span class="line">url_have_group_name=true</span><br><span class="line">store_path0=/home/fastdfs_storage</span><br><span class="line">tracker_server=192.168.75.6:22122</span><br><span class="line">group_name=group1</span><br><span class="line"></span><br><span class="line"># storage02 配置：</span><br><span class="line"># vim /etc/fdfs/mod_fastdfs.conf</span><br><span class="line">connect_timeout=10</span><br><span class="line">base_path=/home/fastdfs_storage</span><br><span class="line">url_have_group_name=true</span><br><span class="line">store_path0=/home/fastdfs_storage</span><br><span class="line">tracker_server=192.168.75.7:22122</span><br><span class="line">group_name=group2</span><br><span class="line"></span><br><span class="line"># 6. 复制 FastDFS 安装目录的部分配置文件到 /etc/fdfs 目录</span><br><span class="line">cp http.conf mime.types /etc/fdfs/</span><br><span class="line"></span><br><span class="line"># 7. 配置nginx</span><br><span class="line">server &#123;</span><br><span class="line">    listen 8888;  </span><br><span class="line">    server_name localhost; </span><br><span class="line">     </span><br><span class="line">    location ~/group([0-9])/M00 &#123;</span><br><span class="line">        ngx_fastdfs_module;  </span><br><span class="line">    &#125;</span><br><span class="line">    error_page 500 502 503 504 /50x.html;  </span><br><span class="line">    location = /50x.html &#123;  </span><br><span class="line">        root html;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-测试"><a href="#3-测试" class="headerlink" title="3.测试"></a>3.测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/fdfs/client.conf</span><br><span class="line">    base_path=/home/fastdfs_tracker</span><br><span class="line">    tracker_server=192.168.75.5:22122</span><br><span class="line"></span><br><span class="line">/usr/bin/fdfs_upload_file /etc/fdfs/client.conf test.jpg</span><br></pre></td></tr></table></figure><h3 id="4-tracker安装nginx"><a href="#4-tracker安装nginx" class="headerlink" title="4. tracker安装nginx"></a>4. tracker安装nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">http &#123;  </span><br><span class="line">    include mime.types;  </span><br><span class="line">    default_type application/octet-stream;  </span><br><span class="line">    sendfile on;  </span><br><span class="line">    keepalive_timeout 65;</span><br><span class="line">    </span><br><span class="line">    #group1</span><br><span class="line">    upstream fdfs_group1 &#123;</span><br><span class="line">       server 192.168.75.6:8888;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    #group2</span><br><span class="line">    upstream fdfs_group2 &#123;</span><br><span class="line">       server 192.168.75.7:8888;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;  </span><br><span class="line">        listen 8000;  </span><br><span class="line">        server_name localhost;</span><br><span class="line">        </span><br><span class="line">        location /group1/M00 &#123;</span><br><span class="line">           proxy_pass http://fdfs_group1;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location /group2/M00 &#123;</span><br><span class="line">           proxy_pass http://fdfs_group2;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 500 502 503 504 /50x.html;  </span><br><span class="line">        location = /50x.html &#123;  </span><br><span class="line">            root html;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;软件下载&quot;&gt;&lt;a href=&quot;#软件下载&quot; class=&quot;headerlink&quot; title=&quot;软件下载&quot;&gt;&lt;/a&gt;软件下载&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 已经事先把所需软件下载好并上传到/usr/local/src目录了&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs-client-java/archive/V1.28.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://openresty.org/download/openresty-1.15.8.3.tar.gz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h1 id=&quot;基础环境设置&quot;&gt;&lt;a href=&quot;#基础环境设置&quot; class=&quot;headerlink&quot; title=&quot;基础环境设置&quot;&gt;&lt;/a&gt;基础环境设置&lt;/h1&gt;&lt;h2 id=&quot;安装依赖组件&quot;&gt;&lt;a href=&quot;#安装依赖组件&quot; class=&quot;headerlink&quot; title=&quot;安装依赖组件&quot;&gt;&lt;/a&gt;安装依赖组件&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum -y install  gcc gcc-c++ libevent&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;yum -y groupinstall &amp;apos;Development Tools&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;
    
    </summary>
    
      <category term="nginx" scheme="https://yongnights.github.io/categories/nginx/"/>
    
      <category term="FastDFS" scheme="https://yongnights.github.io/categories/nginx/FastDFS/"/>
    
    
      <category term="nginx" scheme="https://yongnights.github.io/tags/nginx/"/>
    
      <category term="FastDFS" scheme="https://yongnights.github.io/tags/FastDFS/"/>
    
  </entry>
  
  <entry>
    <title>CentOS7部署FastDFS+nginx模块</title>
    <link href="https://yongnights.github.io/2020/04/02/CentOS7%E9%83%A8%E7%BD%B2FastDFS+nginx%E6%A8%A1%E5%9D%97/"/>
    <id>https://yongnights.github.io/2020/04/02/CentOS7部署FastDFS+nginx模块/</id>
    <published>2020-04-02T01:31:47.162Z</published>
    <updated>2020-04-08T10:04:48.822Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 08 2020 18:05:48 GMT+0800 (GMT+08:00) --><h1 id="软件下载"><a href="#软件下载" class="headerlink" title="软件下载"></a>软件下载</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 已经事先把所需软件下载好并上传到/usr/local/src目录了</span><br><span class="line">https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs-client-java/archive/V1.28.tar.gz</span><br><span class="line">https://openresty.org/download/openresty-1.15.8.3.tar.gz</span><br></pre></td></tr></table></figure><h1 id="基础环境设置"><a href="#基础环境设置" class="headerlink" title="基础环境设置"></a>基础环境设置</h1><h2 id="安装依赖组件"><a href="#安装依赖组件" class="headerlink" title="安装依赖组件"></a>安装依赖组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install  gcc gcc-c++ libevent</span><br><span class="line">yum -y groupinstall &apos;Development Tools&apos;</span><br></pre></td></tr></table></figure><p><code><a id="more"></a></code></p><h2 id="安装libfastcommon"><a href="#安装libfastcommon" class="headerlink" title="安装libfastcommon"></a>安装libfastcommon</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf libfastcommon-1.0.43.tar.gz</span><br><span class="line">cd libfastcommon-1.0.43</span><br><span class="line">./make.sh</span><br><span class="line">./make.sh install</span><br><span class="line"></span><br><span class="line"># 检查文件是否存在</span><br><span class="line">[root@bogon libfastcommon-1.0.43]# ll /usr/lib64 | grep &quot;libfastcommon.so&quot; </span><br><span class="line">-rwxr-xr-x   1 root root  1035264 Apr  2 10:07 libfastcommon.so</span><br><span class="line">[root@bogon libfastcommon-1.0.43]# ll /usr/lib | grep &quot;libfastcommon.so&quot;  </span><br><span class="line">lrwxrwxrwx   1 root root    27 Apr  2 10:07 libfastcommon.so -&gt; /usr/lib64/libfastcommon.so</span><br></pre></td></tr></table></figure><h2 id="安装fastdfs"><a href="#安装fastdfs" class="headerlink" title="安装fastdfs"></a>安装fastdfs</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf fastdfs-6.06.tar.gz</span><br><span class="line">cd fastdfs-6.06</span><br><span class="line">./make.sh</span><br><span class="line">./make.sh install</span><br><span class="line"></span><br><span class="line"># 安装成功后将解压目录下的conf下的俩文件拷贝到/etc/fdfs/下</span><br><span class="line">cd conf</span><br><span class="line">cp http.conf mime.types /etc/fdfs/</span><br><span class="line">cd /etc/fdfs/</span><br><span class="line">[root@bogon fdfs]# ll</span><br><span class="line">total 68</span><br><span class="line">-rw-r--r-- 1 root root  1909 Apr  2 10:15 client.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root   965 Apr  2 10:16 http.conf</span><br><span class="line">-rw-r--r-- 1 root root 31172 Apr  2 10:16 mime.types</span><br><span class="line">-rw-r--r-- 1 root root 10246 Apr  2 10:15 storage.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root   620 Apr  2 10:15 storage_ids.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root  9138 Apr  2 10:15 tracker.conf.sample</span><br></pre></td></tr></table></figure><h3 id="fdfs-trackerd配置并启动"><a href="#fdfs-trackerd配置并启动" class="headerlink" title="fdfs_trackerd配置并启动"></a>fdfs_trackerd配置并启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp tracker.conf.sample tracker.conf</span><br><span class="line">mkdir -p /opt/&#123;fdfs_tracker,fdfs_storage,fdfs_storage_data&#125;</span><br><span class="line">vim tracker.conf</span><br><span class="line">    base_path = /opt/fdfs_tracker</span><br><span class="line"></span><br><span class="line"># 启动fdfs_trackerd</span><br><span class="line">/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</span><br><span class="line"># 查看端口号，验证启动情况</span><br><span class="line">[root@bogon fdfs]# ps -ef | grep fdfs</span><br><span class="line">root       2119      1  0 10:22 ?        00:00:00 /usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</span><br><span class="line">[root@bogon fdfs]# ss -tulnp | grep 22122</span><br><span class="line">tcp    LISTEN     0      128       *:22122                 *:*                   users:((&quot;fdfs_trackerd&quot;,pid=2119,fd=5))</span><br><span class="line"></span><br><span class="line"># 命令行选项</span><br><span class="line">Usage: /usr/bin/fdfs_trackerd &lt;config_file&gt; [start|stop|restart]</span><br><span class="line"></span><br><span class="line"># 注意：在/opt/fdfs_data目录下生成两个目录,一个是数据,一个是日志.</span><br><span class="line"># 设置开机自启动</span><br><span class="line">echo &quot;/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart&quot; | tee -a /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h3 id="fdfs-storaged配置并启动"><a href="#fdfs-storaged配置并启动" class="headerlink" title="fdfs_storaged配置并启动"></a>fdfs_storaged配置并启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp storage.conf.sample storage.conf</span><br><span class="line">vim storage.conf</span><br><span class="line">    base_path = /opt/fdfs_storage # 注意,这个目录最好有大于50G的磁盘空间</span><br><span class="line">    store_path0 = /opt/fdfs_storage_data # 若配置这个参数，则该目录为实际保存文件的路径</span><br><span class="line">    tracker_server = 192.168.75.5:22122 # 注意：这个参数不能设置127.0.0.1，否则storage注册时会报错：ERROR - file: storage_func.c, line: 1361, conf file &quot;/etc/fdfs/storage.conf&quot;, tracker: &quot;127.0.0.1:22122&quot; is invalid, tracker server ip can&apos;t be 127.0.0.1</span><br><span class="line"># 启动fdfs_storaged</span><br><span class="line">/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</span><br><span class="line">[root@bogon fdfs]# ps -ef | grep &quot;fdfs_storaged&quot;</span><br><span class="line">root       2194      1  7 10:36 ?        00:00:01 /usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</span><br><span class="line">[root@bogon fdfs]# ss -tulnp | grep &quot;fdfs&quot;</span><br><span class="line">tcp    LISTEN     0      128       *:23000                 *:*                   users:((&quot;fdfs_storaged&quot;,pid=2194,fd=5))</span><br><span class="line">tcp    LISTEN     0      128       *:22122                 *:*                   users:((&quot;fdfs_trackerd&quot;,pid=2119,fd=5))</span><br><span class="line"></span><br><span class="line"># 命令行选项</span><br><span class="line">Usage: /usr/bin/fdfs_trackerd &lt;config_file&gt; [start|stop|restart]</span><br><span class="line"># 设置开机自启动</span><br><span class="line">echo &quot;/usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart&quot; | tee -a /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h3 id="校验整合"><a href="#校验整合" class="headerlink" title="校验整合"></a>校验整合</h3><p>要确定一下，storage是否注册到了tracker中去<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/fdfs_monitor /etc/fdfs/storage.conf</span><br></pre></td></tr></table></figure><p></p><p>成功后可以看到：ip_addr = 192.168.75.5 ACTIVE</p><h3 id="使用FastDFS自带工具测试"><a href="#使用FastDFS自带工具测试" class="headerlink" title="使用FastDFS自带工具测试"></a>使用FastDFS自带工具测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp client.conf.sample client.conf</span><br><span class="line">vim client.conf</span><br><span class="line">    base_path = /opt/fdfs_tracker #tracker服务器文件路径</span><br><span class="line">    tracker_server = 192.168.75.5:22122 #tracker服务器IP地址和端口号</span><br><span class="line">    http.tracker_server_port = 8080 # tracker服务器的http端口号,必须和tracker的设置对应起来</span><br></pre></td></tr></table></figure><p>上传一张图片1.jpg到Centos服务器上的 /tmp 目录下，进行测试，命令如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/fdfs_test /etc/fdfs/client.conf upload /tmp/1.jpg</span><br><span class="line">This is FastDFS client test program v6.06</span><br><span class="line"></span><br><span class="line">Copyright (C) 2008, Happy Fish / YuQing</span><br><span class="line"></span><br><span class="line">FastDFS may be copied only under the terms of the GNU General</span><br><span class="line">Public License V3, which may be found in the FastDFS source kit.</span><br><span class="line">Please visit the FastDFS Home Page http://www.fastken.com/ </span><br><span class="line">for more detail.</span><br><span class="line"></span><br><span class="line">[2020-04-02 10:47:57] DEBUG - base_path=/opt/fdfs_tracker, connect_timeout=5, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0</span><br><span class="line"></span><br><span class="line">tracker_query_storage_store_list_without_group: </span><br><span class="line">        server 1. group_name=, ip_addr=192.168.75.5, port=23000</span><br><span class="line"></span><br><span class="line">group_name=group1, ip_addr=192.168.75.5, port=23000</span><br><span class="line">storage_upload_by_filename</span><br><span class="line">group_name=group1, remote_filename=M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">source ip address: 192.168.75.5</span><br><span class="line">file timestamp=2020-04-02 10:47:58</span><br><span class="line">file size=2402082</span><br><span class="line">file crc32=779422649</span><br><span class="line">example file url: http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">storage_upload_slave_by_filename</span><br><span class="line">group_name=group1, remote_filename=M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br><span class="line">source ip address: 192.168.75.5</span><br><span class="line">file timestamp=2020-04-02 10:47:58</span><br><span class="line">file size=2402082</span><br><span class="line">file crc32=779422649</span><br><span class="line">example file url: http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br></pre></td></tr></table></figure><p></p><p>以上图中的文件地址：<a href="http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg对应storage服务器上的/opt/fdfs_storage_data/data/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg文件" target="_blank" rel="noopener">http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg对应storage服务器上的/opt/fdfs_storage_data/data/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg文件</a>;</p><blockquote><p>注意图片路径中的8080端口,这个是tracker的端口，</p></blockquote><p>但是查看该目录，会有四个图片文件:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon 00]# pwd</span><br><span class="line">/opt/fdfs_storage_data/data/00/00</span><br><span class="line">[root@bogon 00]# ll</span><br><span class="line">total 4704</span><br><span class="line">-rw-r--r-- 1 root root 2402082 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br><span class="line">-rw-r--r-- 1 root root      49 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg-m</span><br><span class="line">-rw-r--r-- 1 root root 2402082 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">-rw-r--r-- 1 root root      49 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg-m</span><br></pre></td></tr></table></figure><p></p><h2 id="FastDFS和nginx结合使用"><a href="#FastDFS和nginx结合使用" class="headerlink" title="FastDFS和nginx结合使用"></a>FastDFS和nginx结合使用</h2><h3 id="在tracker上安装-nginx"><a href="#在tracker上安装-nginx" class="headerlink" title="在tracker上安装 nginx"></a>在tracker上安装 nginx</h3><p>在每个tracker上安装nginx的主要目的是做负载均衡及实现高可用。如果只有一台tracker服务器可以不配置nginx.<br>一个tracker对应多个storage，通过nginx对storage负载均衡;</p><h3 id="在storage上安装nginx-openresty"><a href="#在storage上安装nginx-openresty" class="headerlink" title="在storage上安装nginx(openresty)"></a>在storage上安装nginx(openresty)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src/</span><br><span class="line">tar -zxvf fastdfs-nginx-module-1.22.tar.gz</span><br><span class="line">cd fastdfs-nginx-module-1.22/src</span><br><span class="line">cp mod_fastdfs.conf /etc/fdfs/</span><br><span class="line">vim /etc/fdfs/mod_fastdfs.conf</span><br><span class="line">    base_path=/opt/fdfs_storage</span><br><span class="line">    tracker_server=192.168.75.5:22122</span><br><span class="line">    url_have_group_name = true #url中包含group名称</span><br><span class="line">    store_path0=/opt/fdfs_storage_data #与storage.conf中的路径保持一致</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">yum -y install pcre pcre-devel openssl openssl-devel</span><br><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf openresty-1.15.8.3.tar.gz</span><br><span class="line">cd openresty-1.15.8.3</span><br><span class="line">./configure \</span><br><span class="line">    --with-luajit \</span><br><span class="line">    --with-http_stub_status_module \</span><br><span class="line">    --with-http_ssl_module \</span><br><span class="line">    --with-http_realip_module \</span><br><span class="line">    --with-http_gzip_static_module \</span><br><span class="line">    --add-module=/usr/local/src/fastdfs-nginx-module-1.22/src</span><br><span class="line">gmake</span><br><span class="line">gmake install</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">vim /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">    error_log  logs/error.log;</span><br><span class="line">    pid      logs/nginx.pid;</span><br><span class="line">    server&#123;</span><br><span class="line">        server_name  192.168.75.5; </span><br><span class="line">    &#125;</span><br><span class="line">/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line"># 浏览器访问，出现openresty欢迎页面</span><br><span class="line"></span><br><span class="line"># 设置nginx开机启动</span><br><span class="line">echo &quot;/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf&quot; | tee -a /etc/rc.d/rc.local</span><br><span class="line"></span><br><span class="line">vim /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">    server&#123;</span><br><span class="line">        location /group1/M00/ &#123;</span><br><span class="line">            root /opt/fdfs_storage/data;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">/usr/local/openresty/nginx/sbin/nginx -s reload</span><br><span class="line"></span><br><span class="line"># 参考上面测试的那一步图片url地址：http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">使用nginxf访问的话，实际地址是：http://192.168.75.5/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">需要把tracker使用的8080端口去掉，否则无法访问</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 进一步完善nginx配置文件</span><br><span class="line">    # 这个server设置的是storage nginx</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       9991;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location ~/group1/M00 &#123;</span><br><span class="line">            root /opt/fastdfs_storage/data;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # 若访问不到图片需要配置这个软连接</span><br><span class="line">    # ln -s /opt/fastdfs_storage_data/data/ /opt/fastdfs_storage_data/data/M00</span><br><span class="line">    </span><br><span class="line">    # 这个server设置的是tracker nginx</span><br><span class="line">    upstream fdfs_group1 &#123;</span><br><span class="line">        server 127.0.0.1:9991;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        </span><br><span class="line">        location /group1/M00 &#123;</span><br><span class="line">            proxy_pass http://fdfs_group1;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed Apr 08 2020 18:05:48 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;软件下载&quot;&gt;&lt;a href=&quot;#软件下载&quot; class=&quot;headerlink&quot; title=&quot;软件下载&quot;&gt;&lt;/a&gt;软件下载&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 已经事先把所需软件下载好并上传到/usr/local/src目录了&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs-client-java/archive/V1.28.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://openresty.org/download/openresty-1.15.8.3.tar.gz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h1 id=&quot;基础环境设置&quot;&gt;&lt;a href=&quot;#基础环境设置&quot; class=&quot;headerlink&quot; title=&quot;基础环境设置&quot;&gt;&lt;/a&gt;基础环境设置&lt;/h1&gt;&lt;h2 id=&quot;安装依赖组件&quot;&gt;&lt;a href=&quot;#安装依赖组件&quot; class=&quot;headerlink&quot; title=&quot;安装依赖组件&quot;&gt;&lt;/a&gt;安装依赖组件&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum -y install  gcc gcc-c++ libevent&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;yum -y groupinstall &amp;apos;Development Tools&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;
    
    </summary>
    
      <category term="nginx" scheme="https://yongnights.github.io/categories/nginx/"/>
    
      <category term="FastDFS" scheme="https://yongnights.github.io/categories/nginx/FastDFS/"/>
    
    
      <category term="nginx" scheme="https://yongnights.github.io/tags/nginx/"/>
    
      <category term="FastDFS" scheme="https://yongnights.github.io/tags/FastDFS/"/>
    
  </entry>
  
  <entry>
    <title>FastAPI快速入门</title>
    <link href="https://yongnights.github.io/2020/01/15/fastapi%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
    <id>https://yongnights.github.io/2020/01/15/fastapi快速入门/</id>
    <published>2020-01-15T02:30:32.629Z</published>
    <updated>2020-01-15T02:45:12.585Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Jan 15 2020 18:06:02 GMT+0800 (GMT+08:00) --><p>fastapi是高性能的web框架。他的主要特点是：</p><ul><li>快速编码</li><li>减少人为bug</li><li>直观</li><li>简易</li><li>具有交互式文档</li><li>基于API的开放标准（并与之完全兼容）：OpenAPI（以前称为Swagger）和JSON Schema。</li></ul><p>技术背景：python3.6+、Starlette、Pydantic</p><p>官方文档地址：<a href="https://fastapi.tiangolo.com/" target="_blank" rel="noopener">https://fastapi.tiangolo.com/</a></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install fastapi</span><br><span class="line">pip install uvicorn</span><br></pre></td></tr></table></figure><a id="more"></a><h1 id="quick-start"><a href="#quick-start" class="headerlink" title="quick start"></a>quick start</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># main.py</span><br><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line">@app.get(&quot;/&quot;)</span><br><span class="line">def read_root():</span><br><span class="line">    return &#123;&quot;Hello&quot;: &quot;World&quot;&#125;</span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">def read_item(item_id: int, q: str = None):</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id, &quot;q&quot;: q&#125;</span><br></pre></td></tr></table></figure><p>或者<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># If your code uses async / await, use async def:</span><br><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/&quot;)</span><br><span class="line">async def read_root():</span><br><span class="line">    return &#123;&quot;Hello&quot;: &quot;World&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">async def read_item(item_id: int, q: str = None):</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id, &quot;q&quot;: q&#125;</span><br></pre></td></tr></table></figure><p></p><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uvicorn main:app --reload</span><br></pre></td></tr></table></figure><p>看到如下提示，证明运行成功</p><p><img src="/fastapi快速入门.assets/1.png" alt></p><pre><code>main: 表示app所在文件名, the file main.py (the Python &quot;module&quot;).app：FastAPI实例, the object created inside of main.py with the line app = FastAPI().reload：debug模式，可以自动重启,make the server restart after code changes. Only do this for development.</code></pre><p>试着请求<a href="http://127.0.0.1:8000/items/5?q=somequery，会看到如下返回" target="_blank" rel="noopener">http://127.0.0.1:8000/items/5?q=somequery，会看到如下返回</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;item_id&quot;: 5, &quot;q&quot;: &quot;somequery&quot;&#125;</span><br></pre></td></tr></table></figure><p></p><h1 id="交互文档"><a href="#交互文档" class="headerlink" title="交互文档"></a>交互文档</h1><p>试着打开<a href="http://127.0.0.1:8000/docs" target="_blank" rel="noopener">http://127.0.0.1:8000/docs</a><br><img src="/fastapi快速入门.assets/2.png" alt></p><h1 id="API文档"><a href="#API文档" class="headerlink" title="API文档"></a>API文档</h1><p>试着打开<a href="http://127.0.0.1:8000/redoc" target="_blank" rel="noopener">http://127.0.0.1:8000/redoc</a><br><img src="/fastapi快速入门.assets/3.png" alt></p><h1 id="update"><a href="#update" class="headerlink" title="update"></a>update</h1><p>通过上面的例子，我们已经用fastapi完成了第一个web服务，现在我们再添加一个接口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line">from pydantic import BaseModel</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Item(BaseModel):</span><br><span class="line">    name: str</span><br><span class="line">    price: float</span><br><span class="line">    is_offer: bool = None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/&quot;)</span><br><span class="line">def read_root():</span><br><span class="line">    return &#123;&quot;Hello&quot;: &quot;World&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">def read_item(item_id: int, q: str = None):</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id, &quot;q&quot;: q&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.put(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">def update_item(item_id: int, item: Item):</span><br><span class="line">    return &#123;&quot;item_name&quot;: item.name, &quot;item_id&quot;: item_id&#125;</span><br></pre></td></tr></table></figure><p>此时会发现，服务自动重启了，这是因为我们在启动命令后添加了–reload。再次查看文档，发现同样发生了改变。<br>到此，你已经可以快速的用fastapi搭建起服务了～</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed Jan 15 2020 18:06:02 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;fastapi是高性能的web框架。他的主要特点是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;快速编码&lt;/li&gt;&lt;li&gt;减少人为bug&lt;/li&gt;&lt;li&gt;直观&lt;/li&gt;&lt;li&gt;简易&lt;/li&gt;&lt;li&gt;具有交互式文档&lt;/li&gt;&lt;li&gt;基于API的开放标准（并与之完全兼容）：OpenAPI（以前称为Swagger）和JSON Schema。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;技术背景：python3.6+、Starlette、Pydantic&lt;/p&gt;&lt;p&gt;官方文档地址：&lt;a href=&quot;https://fastapi.tiangolo.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://fastapi.tiangolo.com/&lt;/a&gt;&lt;/p&gt;&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip install fastapi&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install uvicorn&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Python" scheme="https://yongnights.github.io/categories/Python/"/>
    
      <category term="FastAPI" scheme="https://yongnights.github.io/categories/Python/FastAPI/"/>
    
    
      <category term="Python" scheme="https://yongnights.github.io/tags/Python/"/>
    
      <category term="FastAPI" scheme="https://yongnights.github.io/tags/FastAPI/"/>
    
  </entry>
  
</feed>
