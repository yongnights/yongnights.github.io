<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>个人博客</title>
  
  <subtitle>记录工作中的点点滴滴</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yongnights.github.io/"/>
  <updated>2020-04-14T09:17:25.005Z</updated>
  <id>https://yongnights.github.io/</id>
  
  <author>
    <name>永夜初晗凝碧天</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>EFK-5 ES集群开启用户认证</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-5%EF%BC%9AES%E9%9B%86%E7%BE%A4%E5%BC%80%E5%90%AF%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%20/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-5：ES集群开启用户认证 /</id>
    <published>2020-04-14T08:55:14.913Z</published>
    <updated>2020-04-14T09:17:25.005Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:58 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483826&amp;idx=1&amp;sn=583e9a526050682ae060f601eced917b&amp;chksm=fa769a9ccd01138a8740171769d1149a5df706ab3523eb0cbb5697293bda6e46954641d49f99&amp;mpshare=1&amp;scene=1&amp;srcid=01245nkmqHupjQF7csKql1i5&amp;sharer_sharetime=1579865464558&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483826&amp;idx=1&amp;sn=583e9a526050682ae060f601eced917b&amp;chksm=fa769a9ccd01138a8740171769d1149a5df706ab3523eb0cbb5697293bda6e46954641d49f99&amp;mpshare=1&amp;scene=1&amp;srcid=01245nkmqHupjQF7csKql1i5&amp;sharer_sharetime=1579865464558&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>基于ES内置及自定义用户实现kibana和filebeat的认证</p><a id="more"></a><p><img src="/elk/elk5.png" alt></p><h1 id="关闭服务"><a href="#关闭服务" class="headerlink" title="关闭服务"></a>关闭服务</h1><p>先关闭所有ElasticSearch、kibana、filebeat进程</p><h1 id="elasticsearch-修改elasticsearch-yml配置"><a href="#elasticsearch-修改elasticsearch-yml配置" class="headerlink" title="elasticsearch-修改elasticsearch.yml配置"></a>elasticsearch-修改elasticsearch.yml配置</h1><p>按以上表格对应的实例新增conf目录下elasticsearch.yml配置参数<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 在所有实例上加上以下配置</span><br><span class="line"></span><br><span class="line"># 开启本地用户</span><br><span class="line"></span><br><span class="line">xpack.security.enabled: true</span><br><span class="line"></span><br><span class="line"># xpack的版本</span><br><span class="line"></span><br><span class="line">xpack.license.self_generated.type: basic</span><br></pre></td></tr></table></figure><p></p><h1 id="elasticsearch-开启服务"><a href="#elasticsearch-开启服务" class="headerlink" title="elasticsearch-开启服务"></a>elasticsearch-开启服务</h1><p>开启所有ES服务<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch ./bin/elasticsearch</span><br></pre></td></tr></table></figure><p></p><h1 id="elasticsearch-建立本地内置用户"><a href="#elasticsearch-建立本地内置用户" class="headerlink" title="elasticsearch-建立本地内置用户"></a>elasticsearch-建立本地内置用户</h1><p>本地内置elastic、apmsystem、kibana、logstashsystem、beatssystem、remotemonitoring_user用户<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 在其中一台master节点操作</span><br><span class="line"></span><br><span class="line"># interactive 自定密码 auto自动生密码</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-setup-passwords interactive</span><br><span class="line"></span><br><span class="line"># 输入elastic密码</span><br><span class="line"></span><br><span class="line"># 输入apm_system密码</span><br><span class="line"></span><br><span class="line"># 输入kibana密码</span><br><span class="line"></span><br><span class="line"># 输入logstash_system密码</span><br><span class="line"></span><br><span class="line"># 输入beats_system密码</span><br><span class="line"></span><br><span class="line"># 输入remote_monitoring_user密码</span><br></pre></td></tr></table></figure><p></p><h2 id="测试内部用户"><a href="#测试内部用户" class="headerlink" title="测试内部用户"></a>测试内部用户</h2><p>通过base64将elastic用户进行加密，格式为“elastic:elastic的密码“<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 例如以下格式</span><br><span class="line"></span><br><span class="line">curl -H &quot;Authorization: Basic ZWxhc3RpYzplbGFzdGkxMjM0NTY3OA==&quot; &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><p></p><p>如果不通过Basic访问或base64加密错误会报以下错误:<br>“status”: 401</p><h1 id="kibana-创建私钥库"><a href="#kibana-创建私钥库" class="headerlink" title="kibana-创建私钥库"></a>kibana-创建私钥库</h1><h2 id="在192-168-1-21创建私钥库"><a href="#在192-168-1-21创建私钥库" class="headerlink" title="在192.168.1.21创建私钥库"></a>在192.168.1.21创建私钥库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/kibana/</span><br><span class="line"></span><br><span class="line"># 创建密钥库</span><br><span class="line"></span><br><span class="line">sudo -u kibana ./bin/kibana-keystore create</span><br><span class="line"></span><br><span class="line"># 连接ES用户名，这里输入kibana</span><br><span class="line"></span><br><span class="line">sudo -u kibana ./bin/kibana-keystore add elasticsearch.username</span><br><span class="line"></span><br><span class="line"># 连接ES密码，这里输入刚刚设置kibana的密码</span><br><span class="line"></span><br><span class="line">sudo -u kibana ./bin/kibana-keystore add elasticsearch.password</span><br></pre></td></tr></table></figure><h2 id="在192-168-1-21确认私钥库"><a href="#在192-168-1-21确认私钥库" class="headerlink" title="在192.168.1.21确认私钥库"></a>在192.168.1.21确认私钥库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u kibana ./bin/kibana-keystore list</span><br></pre></td></tr></table></figure><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u kibana /opt/kibana/bin/kibana -c /opt/kibana/config/kibana.yml</span><br></pre></td></tr></table></figure><h1 id="filebeat-服务器上创建密钥库"><a href="#filebeat-服务器上创建密钥库" class="headerlink" title="filebeat-服务器上创建密钥库"></a>filebeat-服务器上创建密钥库</h1><h2 id="在192-168-1-11创建filebeat密钥库"><a href="#在192-168-1-11创建filebeat密钥库" class="headerlink" title="在192.168.1.11创建filebeat密钥库"></a>在192.168.1.11创建filebeat密钥库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/filebeat/</span><br><span class="line"></span><br><span class="line">#创建密钥库</span><br><span class="line"></span><br><span class="line">./filebeat keystore create</span><br><span class="line"></span><br><span class="line">#创建test-filebeat用户私钥</span><br><span class="line"></span><br><span class="line">./filebeat keystore add test-filebeat</span><br></pre></td></tr></table></figure><h2 id="确认filebeat密钥库"><a href="#确认filebeat密钥库" class="headerlink" title="确认filebeat密钥库"></a>确认filebeat密钥库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./filebeat keystore list</span><br></pre></td></tr></table></figure><h1 id="filebeat-配置filebeat-yml"><a href="#filebeat-配置filebeat-yml" class="headerlink" title="filebeat-配置filebeat.yml"></a>filebeat-配置filebeat.yml</h1><h2 id="配置filebeat-yml"><a href="#配置filebeat-yml" class="headerlink" title="配置filebeat.yml"></a>配置filebeat.yml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"># 文件输入</span><br><span class="line"></span><br><span class="line">filebeat.inputs:</span><br><span class="line"></span><br><span class="line">  # 文件输入类型</span><br><span class="line"></span><br><span class="line">  - type: log</span><br><span class="line"></span><br><span class="line">    # 开启加载</span><br><span class="line"></span><br><span class="line">    enabled: true</span><br><span class="line"></span><br><span class="line">    # 文件位置</span><br><span class="line"></span><br><span class="line">    paths:</span><br><span class="line"></span><br><span class="line">      - /var/log/nginx/access.log</span><br><span class="line"></span><br><span class="line">    # 自定义参数</span><br><span class="line"></span><br><span class="line">    fields:</span><br><span class="line"></span><br><span class="line">      type: nginx_access # 类型是nginx_access,和上面fields.type是一致的</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 输出至elasticsearch</span><br><span class="line"></span><br><span class="line">output.elasticsearch:</span><br><span class="line"></span><br><span class="line">  # 连接ES集群的用户名</span><br><span class="line"></span><br><span class="line">  username: test-filebeat</span><br><span class="line"></span><br><span class="line">  # 连接ES集群的密码</span><br><span class="line"></span><br><span class="line">  password: &quot;$&#123;test-filebeat密码&#125;&quot;</span><br><span class="line"></span><br><span class="line">  # elasticsearch集群</span><br><span class="line"></span><br><span class="line">  hosts: [&quot;http://192.168.1.31:9200&quot;,</span><br><span class="line"></span><br><span class="line">          &quot;http://192.168.1.32:9200&quot;,</span><br><span class="line"></span><br><span class="line">          &quot;http://192.168.1.33:9200&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  # 索引配置</span><br><span class="line"></span><br><span class="line">  indices:</span><br><span class="line"></span><br><span class="line">    # 索引名</span><br><span class="line"></span><br><span class="line">    - index: &quot;nginx_access_%&#123;+yyy.MM&#125;&quot;</span><br><span class="line"></span><br><span class="line">      # 当类型是nginx_access时使用此索引</span><br><span class="line"></span><br><span class="line">      when.equals:</span><br><span class="line"></span><br><span class="line">        fields.type: &quot;nginx_access&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 关闭自带模板</span><br><span class="line"></span><br><span class="line">setup.template.enabled: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 开启日志记录</span><br><span class="line"></span><br><span class="line">logging.to_files: true</span><br><span class="line"></span><br><span class="line"># 日志等级</span><br><span class="line"></span><br><span class="line">logging.level: info</span><br><span class="line"></span><br><span class="line"># 日志文件</span><br><span class="line"></span><br><span class="line">logging.files:</span><br><span class="line"></span><br><span class="line">  # 日志位置</span><br><span class="line"></span><br><span class="line">  path: /opt/logs/filebeat/</span><br><span class="line"></span><br><span class="line">  # 日志名字</span><br><span class="line"></span><br><span class="line">  name: filebeat</span><br><span class="line"></span><br><span class="line">  # 日志轮转期限，必须要2~1024</span><br><span class="line"></span><br><span class="line">  keepfiles: 7</span><br><span class="line"></span><br><span class="line">  # 日志轮转权限</span><br><span class="line"></span><br><span class="line">  permissions: 0600</span><br></pre></td></tr></table></figure><h2 id="启动filebeat"><a href="#启动filebeat" class="headerlink" title="启动filebeat"></a>启动filebeat</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/filebeat/filebeat -e -c /opt/filebeat/filebeat.yml -d &quot;publish&quot;</span><br></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><h2 id="写入一条数据"><a href="#写入一条数据" class="headerlink" title="写入一条数据"></a>写入一条数据</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -I &quot;http://192.168.1.11&quot;</span><br></pre></td></tr></table></figure><h2 id="在kibana中查看"><a href="#在kibana中查看" class="headerlink" title="在kibana中查看"></a>在kibana中查看</h2><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="kibana角色权限相关文档链接"><a href="#kibana角色权限相关文档链接" class="headerlink" title="kibana角色权限相关文档链接"></a>kibana角色权限相关文档链接</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.elastic.co/guide/en/elasticsearch/reference/7.3/security-privileges.html#privileges-list-cluster</span><br></pre></td></tr></table></figure><h2 id="base64加密解密网站链接"><a href="#base64加密解密网站链接" class="headerlink" title="base64加密解密网站链接"></a>base64加密解密网站链接</h2><p><a href="https://tool.oschina.net/encrypt?type=3" target="_blank" rel="noopener">https://tool.oschina.net/encrypt?type=3</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:58 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483826&amp;amp;idx=1&amp;amp;sn=583e9a526050682ae060f601eced917b&amp;amp;chksm=fa769a9ccd01138a8740171769d1149a5df706ab3523eb0cbb5697293bda6e46954641d49f99&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=01245nkmqHupjQF7csKql1i5&amp;amp;sharer_sharetime=1579865464558&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483826&amp;amp;idx=1&amp;amp;sn=583e9a526050682ae060f601eced917b&amp;amp;chksm=fa769a9ccd01138a8740171769d1149a5df706ab3523eb0cbb5697293bda6e46954641d49f99&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=01245nkmqHupjQF7csKql1i5&amp;amp;sharer_sharetime=1579865464558&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;基于ES内置及自定义用户实现kibana和filebeat的认证&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>EFK-4 ElasticSearch集群TLS加密通讯</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-4%EF%BC%9AElasticSearch%E9%9B%86%E7%BE%A4TLS%E5%8A%A0%E5%AF%86%E9%80%9A%E8%AE%AF%20/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-4：ElasticSearch集群TLS加密通讯 /</id>
    <published>2020-04-14T08:54:19.306Z</published>
    <updated>2020-04-14T09:17:20.508Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483822&amp;idx=1&amp;sn=6813b22eb5bd3a727a56e0fb5ba3f7fb&amp;chksm=fa769a80cd011396cb6717124ebb9fb17bbff2f9d1fbcae50578cb2959225055cce0268d3633&amp;mpshare=1&amp;scene=1&amp;srcid=1205igKg8cJK4Owayo9UNt4Q&amp;sharer_sharetime=1575553256278&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483822&amp;idx=1&amp;sn=6813b22eb5bd3a727a56e0fb5ba3f7fb&amp;chksm=fa769a80cd011396cb6717124ebb9fb17bbff2f9d1fbcae50578cb2959225055cce0268d3633&amp;mpshare=1&amp;scene=1&amp;srcid=1205igKg8cJK4Owayo9UNt4Q&amp;sharer_sharetime=1575553256278&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>基于TLS实现ElasticSearch集群加密通讯，为ES集群创建CA、CERT证书，实现ElasticSearch集群之间数据通过TLS进行双向加密交互。</p><a id="more"></a><p><img src="/elk/elk4.png" alt></p><h1 id="Step1-关闭服务"><a href="#Step1-关闭服务" class="headerlink" title="Step1. 关闭服务"></a>Step1. 关闭服务</h1><p>首先，需要停止所有ElasticSearch、kibana、filebeat服务，待证书配置完成后再启动</p><h1 id="Step2-创建CA证书"><a href="#Step2-创建CA证书" class="headerlink" title="Step2. 创建CA证书"></a>Step2. 创建CA证书</h1><p>找任一一台ElasticSearch节点服务器操作即可<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/elasticsearch/</span><br><span class="line"># --days: 表示有效期多久</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-certutil ca --days 3660</span><br></pre></td></tr></table></figure><p></p><p>务必将生成的CA证书，传到安全地方永久存储，因为后期若需要新增ES节点，还会用到该证书<br>请将elastic-stack-ca.p12证书传到所有ES实例服务器上</p><h1 id="Step3-创建CERT证书"><a href="#Step3-创建CERT证书" class="headerlink" title="Step3. 创建CERT证书"></a>Step3. 创建CERT证书</h1><p>按上面表格进入相对应的目录创建CERT证书<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 在ES目录中建立证书目录及给予elasticsearch权限</span><br><span class="line">mkdir -p config/certs;chown elasticsearch.elasticsearch config/certs -R</span><br><span class="line"></span><br><span class="line"># 每一个实例一个证书</span><br><span class="line"># --ca CA证书的文件名，必选参数</span><br><span class="line"># --dns 服务器名，多服务器名用逗号隔开，可选参数</span><br><span class="line"># --ip 服务器IP，多IP用逗号隔开，可选参数</span><br><span class="line"># --out 输出到哪里，可选参数</span><br><span class="line"># --days 有效期多久，可选参数</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 --ip $&#123;本机IP&#125;,127.0.0.1 --out config/certs/cert.p12 --days 3660</span><br><span class="line"># 例如elasticsearch-master-1（192.168.1.31）执行命令：sudo -u elasticsearch ./bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 --ip 192.168.1.31,127.0.0.1 --out config/certs/cert.p12 --days 3660</span><br></pre></td></tr></table></figure><p></p><p>如果想批量生成CERT证书，请自行查阅附录链接，不过批量生成有时会碰到生成的证书不可用，因此建议一台一台生成</p><h1 id="Step4-创建密钥库"><a href="#Step4-创建密钥库" class="headerlink" title="Step4. 创建密钥库"></a>Step4. 创建密钥库</h1><p>按上面表格进入相对应的目录创建密钥库<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 每一个实例都要操作</span><br><span class="line"># 创建密钥库</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-keystore create</span><br><span class="line"># PKCS＃12文件的密码</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password</span><br><span class="line"># 信任库的密码</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password</span><br></pre></td></tr></table></figure><p></p><p>确认keystore、truststore已录入至密钥库<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch ./bin/elasticsearch-keystore list</span><br></pre></td></tr></table></figure><p></p><h1 id="Step5-删除CA证书"><a href="#Step5-删除CA证书" class="headerlink" title="Step5. 删除CA证书"></a>Step5. 删除CA证书</h1><p>由于上面创建的elastic-stack-ca.p12含有私钥，因此为了安全，建议将该文件删除（请务必提前备份好，因为后期增加节点还会用到）<br>按上面表格进入相对应的目录删除CA证书<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -f elastic-stack-ca.p12</span><br></pre></td></tr></table></figure><p></p><h1 id="Step6-修改elasticsearch-yml配置"><a href="#Step6-修改elasticsearch-yml配置" class="headerlink" title="Step6. 修改elasticsearch.yml配置"></a>Step6. 修改elasticsearch.yml配置</h1><p>按上面表格对应的实例配置conf目录下elasticsearch.yml<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 在所有实例上加上以下配置</span><br><span class="line"># 开启transport.ssl认证</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line"># xpack认证方式 full为主机或IP认证及证书认证，certificates为证书认证，不对主机和IP认证，默认为full</span><br><span class="line">xpack.security.transport.ssl.verification_mode: full</span><br><span class="line"># xpack包含私钥和证书的PKCS＃12文件的路径</span><br><span class="line">xpack.security.transport.ssl.keystore.path: certs/cert.p12</span><br><span class="line"># xpack包含要信任的证书的PKCS＃12文件的路径</span><br><span class="line">xpack.security.transport.ssl.truststore.path: certs/cert.p12</span><br></pre></td></tr></table></figure><p></p><h1 id="Step7-启动服务"><a href="#Step7-启动服务" class="headerlink" title="Step7. 启动服务"></a>Step7. 启动服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 开启所有ES实例</span><br><span class="line">sudo -u elasticsearch ./bin/elasticsearch</span><br><span class="line"></span><br><span class="line"># 开启filebeat</span><br><span class="line">/opt/filebeat/filebeat -e -c /opt/filebeat/filebeat.yml -d &quot;publish&quot;</span><br><span class="line"></span><br><span class="line"># 开启kibana</span><br><span class="line">sudo -u kibana /opt/kibana/bin/kibana -c /opt/kibana/config/kibana.yml</span><br></pre></td></tr></table></figure><h1 id="附-参考文档"><a href="#附-参考文档" class="headerlink" title="附. 参考文档"></a>附. 参考文档</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-tls.html</span><br><span class="line">https://www.elastic.co/guide/en/elasticsearch/reference/7.3/certutil.html</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483822&amp;amp;idx=1&amp;amp;sn=6813b22eb5bd3a727a56e0fb5ba3f7fb&amp;amp;chksm=fa769a80cd011396cb6717124ebb9fb17bbff2f9d1fbcae50578cb2959225055cce0268d3633&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1205igKg8cJK4Owayo9UNt4Q&amp;amp;sharer_sharetime=1575553256278&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483822&amp;amp;idx=1&amp;amp;sn=6813b22eb5bd3a727a56e0fb5ba3f7fb&amp;amp;chksm=fa769a80cd011396cb6717124ebb9fb17bbff2f9d1fbcae50578cb2959225055cce0268d3633&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1205igKg8cJK4Owayo9UNt4Q&amp;amp;sharer_sharetime=1575553256278&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;基于TLS实现ElasticSearch集群加密通讯，为ES集群创建CA、CERT证书，实现ElasticSearch集群之间数据通过TLS进行双向加密交互。&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>EFK-3 ES多实例部署</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-3%EF%BC%9A%20ES%E5%A4%9A%E5%AE%9E%E4%BE%8B%E9%83%A8%E7%BD%B2%20/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-3： ES多实例部署 /</id>
    <published>2020-04-14T08:53:36.243Z</published>
    <updated>2020-04-14T09:17:12.874Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483816&amp;idx=1&amp;sn=bfaf70613bcb775ccf5d40c2871a05a8&amp;chksm=fa769a86cd011390f22ff178071a580a8f17791e57166dfc8463984a5613c11875ef2ebb2ad7&amp;mpshare=1&amp;scene=1&amp;srcid=11253n8AXjLegAeaoHiCssEs&amp;sharer_sharetime=1574686178097&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483816&amp;idx=1&amp;sn=bfaf70613bcb775ccf5d40c2871a05a8&amp;chksm=fa769a86cd011390f22ff178071a580a8f17791e57166dfc8463984a5613c11875ef2ebb2ad7&amp;mpshare=1&amp;scene=1&amp;srcid=11253n8AXjLegAeaoHiCssEs&amp;sharer_sharetime=1574686178097&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>基于ElasticSearch多实例架构，实现资源合理分配、冷热数据分离。<br>ES多实例部署，将不同热度的数据存在不同的磁盘上，实现了数据冷热分离、资源合理分配。<br>在一个集群中部署多个ES实例，来实现资源合理分配。例如data服务器存在SSD与SAS硬盘，可以将热数据存放到SSD，而冷数据存放到SAS，实现数据冷热分离。</p><a id="more"></a><p><img src="/elk/elk3.png" alt></p><h1 id="192-168-1-51-elasticsearch-data部署双实例"><a href="#192-168-1-51-elasticsearch-data部署双实例" class="headerlink" title="192.168.1.51 elasticsearch-data部署双实例"></a>192.168.1.51 elasticsearch-data部署双实例</h1><h2 id="索引迁移"><a href="#索引迁移" class="headerlink" title="索引迁移"></a>索引迁移</h2><p>（此步不能忽略）：将192.168.1.51上的索引放到其它2台data节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.1.52,192.168.1.53&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="确认当前索引存储位置"><a href="#确认当前索引存储位置" class="headerlink" title="确认当前索引存储位置"></a>确认当前索引存储位置</h2><p>确认所有索引不在192.168.1.51节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="停掉192-168-1-51的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"><a href="#停掉192-168-1-51的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘" class="headerlink" title="停掉192.168.1.51的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"></a>停掉192.168.1.51的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 安装包下载和部署请参考第一篇《EFK-1: 快速指南》</span><br><span class="line"></span><br><span class="line">cd /opt/software/</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch /opt/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch-7.3.2 /opt/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch-* -R</span><br><span class="line"></span><br><span class="line">rm -rf /data/SAS/*</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /data/* -R</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/* -R</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"># SAS实例/opt/elasticsearch-SAS/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.51-SAS</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.51</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br><span class="line"></span><br><span class="line"># SSD实例/opt/elasticsearch-SSD/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.51-SSD</span><br><span class="line"></span><br><span class="line">    path.data: /data/SSD</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.51</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9201</span><br><span class="line"></span><br><span class="line">    transport.port: 9301</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br></pre></td></tr></table></figure><h2 id="SAS实例和SSD实例启动方式"><a href="#SAS实例和SSD实例启动方式" class="headerlink" title="SAS实例和SSD实例启动方式"></a>SAS实例和SSD实例启动方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch-SAS/bin/elasticsearch</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch /opt/elasticsearch-SSD/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="确认SAS和SSD已启2实例"><a href="#确认SAS和SSD已启2实例" class="headerlink" title="确认SAS和SSD已启2实例"></a>确认SAS和SSD已启2实例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h1 id="192-168-1-52-elasticsearch-data部署双实例"><a href="#192-168-1-52-elasticsearch-data部署双实例" class="headerlink" title="192.168.1.52 elasticsearch-data部署双实例"></a>192.168.1.52 elasticsearch-data部署双实例</h1><h2 id="索引迁移-1"><a href="#索引迁移-1" class="headerlink" title="索引迁移"></a>索引迁移</h2><p>（此步不能忽略）：将192.168.1.52上的索引放到其它2台data节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.1.51,192.168.1.53&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="确认当前索引存储位置-1"><a href="#确认当前索引存储位置-1" class="headerlink" title="确认当前索引存储位置"></a>确认当前索引存储位置</h2><p>确认所有索引不在192.168.1.52节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="停掉192-168-1-52的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"><a href="#停掉192-168-1-52的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘" class="headerlink" title="停掉192.168.1.52的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"></a>停掉192.168.1.52的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 安装包下载和部署请参考第一篇《EFK-1: 快速指南》</span><br><span class="line"></span><br><span class="line">cd /opt/software/</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch /opt/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch-7.3.2 /opt/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch-* -R</span><br><span class="line"></span><br><span class="line">rm -rf /data/SAS/*</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /data/* -R</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/* -R</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"># SAS实例/opt/elasticsearch-SAS/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.52-SAS</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.52</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br><span class="line"></span><br><span class="line"># SSD实例/opt/elasticsearch-SSD/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.52-SSD</span><br><span class="line"></span><br><span class="line">    path.data: /data/SSD</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.52</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9201</span><br><span class="line"></span><br><span class="line">    transport.port: 9301</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br></pre></td></tr></table></figure><h2 id="SAS实例和SSD实例启动方式-1"><a href="#SAS实例和SSD实例启动方式-1" class="headerlink" title="SAS实例和SSD实例启动方式"></a>SAS实例和SSD实例启动方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch-SAS/bin/elasticsearch</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch /opt/elasticsearch-SSD/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="确认SAS和SSD已启2实例-1"><a href="#确认SAS和SSD已启2实例-1" class="headerlink" title="确认SAS和SSD已启2实例"></a>确认SAS和SSD已启2实例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h1 id="192-168-1-53-elasticsearch-data部署双实例"><a href="#192-168-1-53-elasticsearch-data部署双实例" class="headerlink" title="192.168.1.53 elasticsearch-data部署双实例"></a>192.168.1.53 elasticsearch-data部署双实例</h1><h2 id="索引迁移-2"><a href="#索引迁移-2" class="headerlink" title="索引迁移"></a>索引迁移</h2><p>（此步不能忽略）：一定要做这步，将192.168.1.53上的索引放到其它2台data节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.1.51,192.168.1.52&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="确认当前索引存储位置-2"><a href="#确认当前索引存储位置-2" class="headerlink" title="确认当前索引存储位置"></a>确认当前索引存储位置</h2><p>确认所有索引不在192.168.1.52节点上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="停掉192-168-1-53的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"><a href="#停掉192-168-1-53的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘" class="headerlink" title="停掉192.168.1.53的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘"></a>停掉192.168.1.53的进程，修改目录结构及配置：请自行按SSD和SAS硬盘挂载好数据盘</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 安装包下载和部署请参考第一篇《EFK-1: 快速指南》</span><br><span class="line"></span><br><span class="line">cd /opt/software/</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch /opt/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/</span><br><span class="line"></span><br><span class="line">mv /opt/elasticsearch-7.3.2 /opt/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch-* -R</span><br><span class="line"></span><br><span class="line">rm -rf /data/SAS/*</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /data/* -R</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/* -R</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"># SAS实例/opt/elasticsearch-SAS/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.53-SAS</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SAS</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.53</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br><span class="line"></span><br><span class="line"># SSD实例/opt/elasticsearch-SSD/config/elasticsearch.yml配置</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.53-SSD</span><br><span class="line"></span><br><span class="line">    path.data: /data/SSD</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch-SSD</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.53</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    http.port: 9201</span><br><span class="line"></span><br><span class="line">    transport.port: 9301</span><br><span class="line"></span><br><span class="line">    # discovery.seed_hosts和cluster.initial_master_nodes 一定要带上端口号，不然会走http.port和transport.port端口</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31:9300&quot;,&quot;192.168.1.32:9300&quot;,&quot;192.168.1.33:9300&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本机只允行启2个实例</span><br><span class="line"></span><br><span class="line">    node.max_local_storage_nodes: 2</span><br></pre></td></tr></table></figure><h2 id="SAS实例和SSD实例启动方式-2"><a href="#SAS实例和SSD实例启动方式-2" class="headerlink" title="SAS实例和SSD实例启动方式"></a>SAS实例和SSD实例启动方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch-SAS/bin/elasticsearch</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch /opt/elasticsearch-SSD/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="确认SAS和SSD已启2实例-2"><a href="#确认SAS和SSD已启2实例-2" class="headerlink" title="确认SAS和SSD已启2实例"></a>确认SAS和SSD已启2实例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><h2 id="将所有索引移到SSD硬盘上"><a href="#将所有索引移到SSD硬盘上" class="headerlink" title="将所有索引移到SSD硬盘上"></a>将所有索引移到SSD硬盘上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 下面的参数会在后面的文章讲解，此处照抄即可</span><br><span class="line"></span><br><span class="line">curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.include._host_ip&quot;: &quot;&quot;,</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.include._host&quot;: &quot;&quot;,</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.include._name&quot;: &quot;&quot;,</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.include._ip&quot;: &quot;&quot;,</span><br><span class="line"></span><br><span class="line">  &quot;index.routing.allocation.require._name&quot;: &quot;*-SSD&quot;</span><br><span class="line"></span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h2 id="确认所有索引全在SSD硬盘上"><a href="#确认所有索引全在SSD硬盘上" class="headerlink" title="确认所有索引全在SSD硬盘上"></a>确认所有索引全在SSD硬盘上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</span><br></pre></td></tr></table></figure><h2 id="将nginx9月份的日志索引迁移到SAS硬盘上"><a href="#将nginx9月份的日志索引迁移到SAS硬盘上" class="headerlink" title="将nginx9月份的日志索引迁移到SAS硬盘上"></a>将nginx9月份的日志索引迁移到SAS硬盘上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT &quot;192.168.1.31:9200/nginx_*_2019.09/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index.routing.allocation.require._name&quot;: &quot;*-SAS&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h2 id="确认nginx9月份的日志索引迁移到SAS硬盘上"><a href="#确认nginx9月份的日志索引迁移到SAS硬盘上" class="headerlink" title="确认nginx9月份的日志索引迁移到SAS硬盘上"></a>确认nginx9月份的日志索引迁移到SAS硬盘上</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/shards&quot;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483816&amp;amp;idx=1&amp;amp;sn=bfaf70613bcb775ccf5d40c2871a05a8&amp;amp;chksm=fa769a86cd011390f22ff178071a580a8f17791e57166dfc8463984a5613c11875ef2ebb2ad7&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=11253n8AXjLegAeaoHiCssEs&amp;amp;sharer_sharetime=1574686178097&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483816&amp;amp;idx=1&amp;amp;sn=bfaf70613bcb775ccf5d40c2871a05a8&amp;amp;chksm=fa769a86cd011390f22ff178071a580a8f17791e57166dfc8463984a5613c11875ef2ebb2ad7&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=11253n8AXjLegAeaoHiCssEs&amp;amp;sharer_sharetime=1574686178097&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;基于ElasticSearch多实例架构，实现资源合理分配、冷热数据分离。&lt;br&gt;ES多实例部署，将不同热度的数据存在不同的磁盘上，实现了数据冷热分离、资源合理分配。&lt;br&gt;在一个集群中部署多个ES实例，来实现资源合理分配。例如data服务器存在SSD与SAS硬盘，可以将热数据存放到SSD，而冷数据存放到SAS，实现数据冷热分离。&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>EFK-2 ElasticSearch高性能高可用架构</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-2%EF%BC%9AElasticSearch%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-2：ElasticSearch高性能高可用架构/</id>
    <published>2020-04-14T08:53:02.596Z</published>
    <updated>2020-04-14T09:17:15.695Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483811&amp;idx=1&amp;sn=a413dea65f8f64abb24d82feea55db5b&amp;chksm=fa769a8dcd01139b1da8794914e10989c6a39a99971d8013e9d3b26766b80d5833e2fbaf0ab8&amp;mpshare=1&amp;scene=1&amp;srcid=1125tjbylqn3EdoMtaX2p73J&amp;sharer_sharetime=1574686271229&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483811&amp;idx=1&amp;sn=a413dea65f8f64abb24d82feea55db5b&amp;chksm=fa769a8dcd01139b1da8794914e10989c6a39a99971d8013e9d3b26766b80d5833e2fbaf0ab8&amp;mpshare=1&amp;scene=1&amp;srcid=1125tjbylqn3EdoMtaX2p73J&amp;sharer_sharetime=1574686271229&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd</a></p><p>阐述了EFK的data/ingest/master角色的用途及分别部署三节点，在实现性能最大化的同时保障高可用</p><a id="more"></a><p><img src="/elk/elk2.png" alt></p><h1 id="elasticsearch-data"><a href="#elasticsearch-data" class="headerlink" title="elasticsearch-data"></a>elasticsearch-data</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>3台均执行相同的安装步骤<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/elasticsearch</span><br><span class="line"></span><br><span class="line">useradd elasticsearch -d /opt/elasticsearch -s /sbin/nologin</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch -R</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/elasticsearch -R</span><br><span class="line"></span><br><span class="line"># 数据盘需要elasticsearch写权限</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /data/SAS -R</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 限制一个进程可以拥有的VMA(虚拟内存区域)的数量要超过262144，不然elasticsearch会报max virtual memory areas vm.max_map_count [65535] is too low, increase to at least [262144]</span><br><span class="line"></span><br><span class="line">echo &quot;vm.max_map_count = 655350&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p></p><h2 id="elasticsearch-data配置"><a href="#elasticsearch-data配置" class="headerlink" title="elasticsearch-data配置"></a>elasticsearch-data配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.51 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.51</span><br><span class="line"></span><br><span class="line">    # 数据盘位置，如果有多个硬盘位置，用&quot;,&quot;隔开</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.51</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 关闭ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    # 开启data功能</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"># 192.168.1.52 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.52</span><br><span class="line"></span><br><span class="line">    # 数据盘位置，如果有多个硬盘位置，用&quot;,&quot;隔开</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.52</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 关闭ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    # 开启data功能</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br><span class="line"></span><br><span class="line"># 192.168.1.53 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.53</span><br><span class="line"></span><br><span class="line">    # 数据盘位置，如果有多个硬盘位置，用&quot;,&quot;隔开</span><br><span class="line"></span><br><span class="line">    path.data: /data/SAS</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.53</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 关闭ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: false</span><br><span class="line"></span><br><span class="line">    # 开启data功能</span><br><span class="line"></span><br><span class="line">    node.data: true</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-data启动"><a href="#elasticsearch-data启动" class="headerlink" title="elasticsearch-data启动"></a>elasticsearch-data启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="elasticsearch集群状态"><a href="#elasticsearch集群状态" class="headerlink" title="elasticsearch集群状态"></a>elasticsearch集群状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/health?v&quot;</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-data状态"><a href="#elasticsearch-data状态" class="headerlink" title="elasticsearch-data状态"></a>elasticsearch-data状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-data参数说明"><a href="#elasticsearch-data参数说明" class="headerlink" title="elasticsearch-data参数说明"></a>elasticsearch-data参数说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">status: green  # 集群健康状态</span><br><span class="line"></span><br><span class="line">node.total: 6  # 有6台机子组成集群</span><br><span class="line"></span><br><span class="line">node.data: 6  # 有6个节点的存储</span><br><span class="line"></span><br><span class="line">node.role: d  # 只拥有data角色</span><br><span class="line"></span><br><span class="line">node.role: i  # 只拥有ingest角色</span><br><span class="line"></span><br><span class="line">node.role: m  # 只拥有master角色</span><br><span class="line"></span><br><span class="line">node.role: mid  # 拥master、ingest、data角色</span><br></pre></td></tr></table></figure><h1 id="elasticsearch-ingest"><a href="#elasticsearch-ingest" class="headerlink" title="elasticsearch-ingest"></a>elasticsearch-ingest</h1><p>新增三台ingest节点加入集群，同时关闭master和data功能</p><h2 id="elasticsearch-ingest安装"><a href="#elasticsearch-ingest安装" class="headerlink" title="elasticsearch-ingest安装"></a>elasticsearch-ingest安装</h2><p>3台es均执行相同的安装步骤<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/elasticsearch</span><br><span class="line"></span><br><span class="line">useradd elasticsearch -d /opt/elasticsearch -s /sbin/nologin</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch -R</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/elasticsearch -R</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 限制一个进程可以拥有的VMA(虚拟内存区域)的数量要超过262144，不然elasticsearch会报max virtual memory areas vm.max_map_count [65535] is too low, increase to at least [262144]</span><br><span class="line"></span><br><span class="line">echo &quot;vm.max_map_count = 655350&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p></p><h2 id="elasticsearch-ingest配置"><a href="#elasticsearch-ingest配置" class="headerlink" title="elasticsearch-ingest配置"></a>elasticsearch-ingest配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.41 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.41</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.41</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 开启ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: true</span><br><span class="line"></span><br><span class="line">    # 关闭data功能</span><br><span class="line"></span><br><span class="line">    node.data: false</span><br><span class="line"></span><br><span class="line"># 192.168.1.42 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.42</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.42</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 开启ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: true</span><br><span class="line"></span><br><span class="line">    # 关闭data功能</span><br><span class="line"></span><br><span class="line">    node.data: false</span><br><span class="line"></span><br><span class="line"># 192.168.1.43 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.43</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.43</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭master功能</span><br><span class="line"></span><br><span class="line">    node.master: false</span><br><span class="line"></span><br><span class="line">    # 开启ingest功能</span><br><span class="line"></span><br><span class="line">    node.ingest: true</span><br><span class="line"></span><br><span class="line">    # 关闭data功能</span><br><span class="line"></span><br><span class="line">    node.data: false</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-ingest启动"><a href="#elasticsearch-ingest启动" class="headerlink" title="elasticsearch-ingest启动"></a>elasticsearch-ingest启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -u elasticsearch /opt/elasticsearch/bin/elasticsearch</span><br></pre></td></tr></table></figure><h2 id="elasticsearch集群状态-1"><a href="#elasticsearch集群状态-1" class="headerlink" title="elasticsearch集群状态"></a>elasticsearch集群状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/health?v&quot;</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-ingest状态"><a href="#elasticsearch-ingest状态" class="headerlink" title="elasticsearch-ingest状态"></a>elasticsearch-ingest状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</span><br></pre></td></tr></table></figure><h2 id="elasticsearch-ingest参数说明"><a href="#elasticsearch-ingest参数说明" class="headerlink" title="elasticsearch-ingest参数说明"></a>elasticsearch-ingest参数说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    status: green  # 集群健康状态</span><br><span class="line"></span><br><span class="line">    node.total: 9  # 有9台机子组成集群</span><br><span class="line"></span><br><span class="line">    node.data: 6  # 有6个节点的存储</span><br><span class="line"></span><br><span class="line">    node.role: d  # 只拥有data角色</span><br><span class="line"></span><br><span class="line">    node.role: i  # 只拥有ingest角色</span><br><span class="line"></span><br><span class="line">    node.role: m  # 只拥有master角色</span><br><span class="line"></span><br><span class="line">    node.role: mid  # 拥master、ingest、data角色</span><br><span class="line">```            </span><br><span class="line"></span><br><span class="line"># elasticsearch-master</span><br><span class="line">首先，将上一篇《EFK-1》中部署的3台es（192.168.1.31、192.168.1.32、192.168.1.33）改成只有master的功能， 因此需要先将这3台上的索引数据迁移到本次所做的data节点中</span><br><span class="line">## 索引迁移</span><br><span class="line">一定要做这步，将之前的索引放到data节点上</span><br></pre></td></tr></table></figure><pre><code>curl -X PUT &quot;192.168.1.31:9200/*/_settings?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;{  &quot;index.routing.allocation.include._ip&quot;: &quot;192.168.1.51,192.168.1.52,192.168.1.53&quot;}&apos;</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 确认当前索引存储位置</span><br><span class="line">确认所有索引不在192.168.1.31、192.168.1.32、192.168.1.33节点上</span><br></pre></td></tr></table></figure><pre><code>curl &quot;http://192.168.1.31:9200/_cat/shards?h=n&quot;</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## elasticsearch-master配置</span><br><span class="line">注意事项：修改配置，重启进程，需要一台一台执行，要确保第一台成功后，再执行下一台。</span><br></pre></td></tr></table></figure><h1 id="192-168-1-31-opt-elasticsearch-config-elasticsearch-yml"><a href="#192-168-1-31-opt-elasticsearch-config-elasticsearch-yml" class="headerlink" title="192.168.1.31 /opt/elasticsearch/config/elasticsearch.yml"></a>192.168.1.31 /opt/elasticsearch/config/elasticsearch.yml</h1><pre><code>cluster.name: my-applicationnode.name: 192.168.1.31path.logs: /opt/logs/elasticsearchnetwork.host: 192.168.1.31discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;#开启master功能node.master: true#关闭ingest功能node.ingest: false#关闭data功能node.data: false</code></pre><h1 id="192-168-1-32-opt-elasticsearch-config-elasticsearch-yml"><a href="#192-168-1-32-opt-elasticsearch-config-elasticsearch-yml" class="headerlink" title="192.168.1.32 /opt/elasticsearch/config/elasticsearch.yml"></a>192.168.1.32 /opt/elasticsearch/config/elasticsearch.yml</h1><pre><code>cluster.name: my-applicationnode.name: 192.168.1.32path.logs: /opt/logs/elasticsearchnetwork.host: 192.168.1.32discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;#开启master功能node.master: true#关闭ingest功能node.ingest: false#关闭data功能node.data: false</code></pre><h1 id="192-168-1-33-opt-elasticsearch-config-elasticsearch-yml"><a href="#192-168-1-33-opt-elasticsearch-config-elasticsearch-yml" class="headerlink" title="192.168.1.33 /opt/elasticsearch/config/elasticsearch.yml"></a>192.168.1.33 /opt/elasticsearch/config/elasticsearch.yml</h1><pre><code>cluster.name: my-applicationnode.name: 192.168.1.33path.logs: /opt/logs/elasticsearchnetwork.host: 192.168.1.33discovery.seed_hosts: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]cluster.initial_master_nodes: [&quot;192.168.1.31&quot;,&quot;192.168.1.32&quot;,&quot;192.168.1.33&quot;]http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;#开启master功能node.master: true#关闭ingest功能node.ingest: false#关闭data功能node.data: false</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">## elasticsearch集群状态</span><br></pre></td></tr></table></figure><pre><code>curl &quot;http://192.168.1.31:9200/_cat/health?v&quot;</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">## elasticsearch-master状态</span><br></pre></td></tr></table></figure><pre><code>curl &quot;http://192.168.1.31:9200/_cat/nodes?v&quot;</code></pre><p><code>`</code></p><p><strong>至此，当node.role里所有服务器都不再出现“mid”，则表示一切顺利完成。</strong></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483811&amp;amp;idx=1&amp;amp;sn=a413dea65f8f64abb24d82feea55db5b&amp;amp;chksm=fa769a8dcd01139b1da8794914e10989c6a39a99971d8013e9d3b26766b80d5833e2fbaf0ab8&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1125tjbylqn3EdoMtaX2p73J&amp;amp;sharer_sharetime=1574686271229&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483811&amp;amp;idx=1&amp;amp;sn=a413dea65f8f64abb24d82feea55db5b&amp;amp;chksm=fa769a8dcd01139b1da8794914e10989c6a39a99971d8013e9d3b26766b80d5833e2fbaf0ab8&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1125tjbylqn3EdoMtaX2p73J&amp;amp;sharer_sharetime=1574686271229&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#rd&lt;/a&gt;&lt;/p&gt;&lt;p&gt;阐述了EFK的data/ingest/master角色的用途及分别部署三节点，在实现性能最大化的同时保障高可用&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>EFK-1 快速指南</title>
    <link href="https://yongnights.github.io/2020/04/14/EFK-1%EF%BC%9A%E5%BF%AB%E9%80%9F%E6%8C%87%E5%8D%97/"/>
    <id>https://yongnights.github.io/2020/04/14/EFK-1：快速指南/</id>
    <published>2020-04-14T08:52:17.408Z</published>
    <updated>2020-04-14T09:16:58.163Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --><p>转载自:<br><a href="https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483801&amp;idx=1&amp;sn=11fee5756c8770688238624802ac51ea&amp;chksm=fa769ab7cd0113a1ad19241290abe374b857227eebe989b3ba6b671b1eca855d380b76eeedde&amp;mpshare=1&amp;scene=1&amp;srcid=1125q5BPyFOD05H2trj4UdOf&amp;sharer_sharetime=1574686325386&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;mid=2247483801&amp;idx=1&amp;sn=11fee5756c8770688238624802ac51ea&amp;chksm=fa769ab7cd0113a1ad19241290abe374b857227eebe989b3ba6b671b1eca855d380b76eeedde&amp;mpshare=1&amp;scene=1&amp;srcid=1125q5BPyFOD05H2trj4UdOf&amp;sharer_sharetime=1574686325386&amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#</a></p><p>阐述了EFK的安装部署，其中ES的架构为三节点，即master、ingest、data角色同时部署在三台服务器上。</p><a id="more"></a><p><img src="/elk/elk1.png" alt></p><h1 id="elasticsearch安装：3台es均执行相同的安装步骤"><a href="#elasticsearch安装：3台es均执行相同的安装步骤" class="headerlink" title="elasticsearch安装：3台es均执行相同的安装步骤"></a>elasticsearch安装：3台es均执行相同的安装步骤</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/software &amp;&amp; cd /opt/software</span><br><span class="line"></span><br><span class="line">wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf elasticsearch-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv elasticsearch-7.3.2 /opt/elasticsearch</span><br><span class="line"></span><br><span class="line">useradd elasticsearch -d /opt/elasticsearch -s /sbin/nologin</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/elasticsearch -R</span><br><span class="line"></span><br><span class="line">chown elasticsearch.elasticsearch /opt/logs/elasticsearch -R</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 限制一个进程可以拥有的VMA(虚拟内存区域)的数量要超过262144，不然elasticsearch会报max virtual memory areas vm.max_map_count [65535] is too low, increase to at least [262144]</span><br><span class="line"></span><br><span class="line">echo &quot;vm.max_map_count = 655350&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><h1 id="filebeat安装"><a href="#filebeat安装" class="headerlink" title="filebeat安装"></a>filebeat安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/software &amp;&amp; cd /opt/software</span><br><span class="line"></span><br><span class="line">wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/logs/filebeat/</span><br><span class="line"></span><br><span class="line">tar -zxvf filebeat-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv filebeat-7.3.2-linux-x86_64 /opt/filebeat</span><br></pre></td></tr></table></figure><h1 id="kibana安装"><a href="#kibana安装" class="headerlink" title="kibana安装"></a>kibana安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/software &amp;&amp; cd /opt/software</span><br><span class="line"></span><br><span class="line">wget https://artifacts.elastic.co/downloads/kibana/kibana-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf kibana-7.3.2-linux-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line">mv kibana-7.3.2-linux-x86_64 /opt/kibana</span><br><span class="line"></span><br><span class="line">useradd kibana -d /opt/kibana -s /sbin/nologin</span><br><span class="line"></span><br><span class="line">chown kibana.kibana /opt/kibana -R</span><br></pre></td></tr></table></figure><h1 id="nginx安装"><a href="#nginx安装" class="headerlink" title="nginx安装"></a>nginx安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 只在192.168.1.11安装</span><br><span class="line"></span><br><span class="line">yum install -y nginx</span><br><span class="line"></span><br><span class="line">/usr/sbin/nginx -c /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><h1 id="elasticsearch配置"><a href="#elasticsearch配置" class="headerlink" title="elasticsearch配置"></a>elasticsearch配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.31 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    # 集群名字</span><br><span class="line"></span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点名字</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.31</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 日志位置</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问IP</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.31</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问</span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点运输端口</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 集群中其他主机的列表</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 首次启动全新的Elasticsearch集群时，在第一次选举中便对其票数进行计数的master节点的集合</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 启用跨域资源共享</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 只要有2台数据或主节点已加入集群，就可以恢复</span><br><span class="line"></span><br><span class="line">    gateway.recover_after_nodes: 2</span><br><span class="line"></span><br><span class="line"># 192.168.1.32 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    # 集群名字</span><br><span class="line"></span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点名字</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.32</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 日志位置</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问IP</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.32</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问</span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点运输端口</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 集群中其他主机的列表</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 首次启动全新的Elasticsearch集群时，在第一次选举中便对其票数进行计数的master节点的集合</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 启用跨域资源共享</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 只要有2台数据或主节点已加入集群，就可以恢复</span><br><span class="line"></span><br><span class="line">    gateway.recover_after_nodes: 2</span><br><span class="line"></span><br><span class="line"># 192.168.1.33 /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line">    # 集群名字</span><br><span class="line"></span><br><span class="line">    cluster.name: my-application</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点名字</span><br><span class="line"></span><br><span class="line">    node.name: 192.168.1.33</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 日志位置</span><br><span class="line"></span><br><span class="line">    path.logs: /opt/logs/elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问IP</span><br><span class="line"></span><br><span class="line">    network.host: 192.168.1.33</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点访问</span><br><span class="line"></span><br><span class="line">    http.port: 9200</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 节点运输端口</span><br><span class="line"></span><br><span class="line">    transport.port: 9300</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 集群中其他主机的列表</span><br><span class="line"></span><br><span class="line">    discovery.seed_hosts: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 首次启动全新的Elasticsearch集群时，在第一次选举中便对其票数进行计数的master节点的集合</span><br><span class="line"></span><br><span class="line">    cluster.initial_master_nodes: [&quot;192.168.1.31&quot;, &quot;192.168.1.32&quot;, &quot;192.168.1.33&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 启用跨域资源共享</span><br><span class="line"></span><br><span class="line">    http.cors.enabled: true</span><br><span class="line"></span><br><span class="line">    http.cors.allow-origin: &quot;*&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 只要有2台数据或主节点已加入集群，就可以恢复</span><br><span class="line"></span><br><span class="line">    gateway.recover_after_nodes: 2</span><br></pre></td></tr></table></figure><h1 id="filebeat配置"><a href="#filebeat配置" class="headerlink" title="filebeat配置"></a>filebeat配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.11 /opt/filebeat/filebeat.yml</span><br><span class="line">    # 文件输入</span><br><span class="line"></span><br><span class="line">    filebeat.inputs:</span><br><span class="line"></span><br><span class="line">      # 文件输入类型</span><br><span class="line"></span><br><span class="line">      - type: log</span><br><span class="line"></span><br><span class="line">        # 开启加载</span><br><span class="line"></span><br><span class="line">        enabled: true</span><br><span class="line"></span><br><span class="line">        # 文件位置</span><br><span class="line"></span><br><span class="line">        paths:</span><br><span class="line"></span><br><span class="line">          - /var/log/nginx/access.log</span><br><span class="line"></span><br><span class="line">        # 自定义参数</span><br><span class="line"></span><br><span class="line">        fields:</span><br><span class="line"></span><br><span class="line">          type: nginx_access  # 类型是nginx_access,和上面fields.type是一致的</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 输出至elasticsearch</span><br><span class="line"></span><br><span class="line">    output.elasticsearch:</span><br><span class="line"></span><br><span class="line">      # elasticsearch集群</span><br><span class="line"></span><br><span class="line">      hosts: [&quot;http://192.168.1.31:9200&quot;,</span><br><span class="line"></span><br><span class="line">              &quot;http://192.168.1.32:9200&quot;,</span><br><span class="line"></span><br><span class="line">              &quot;http://192.168.1.33:9200&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">      # 索引配置</span><br><span class="line"></span><br><span class="line">      indices:</span><br><span class="line"></span><br><span class="line">        # 索引名</span><br><span class="line"></span><br><span class="line">        - index: &quot;nginx_access_%&#123;+yyy.MM&#125;&quot;</span><br><span class="line"></span><br><span class="line">          # 当类型是nginx_access时使用此索引</span><br><span class="line"></span><br><span class="line">          when.equals:</span><br><span class="line"></span><br><span class="line">            fields.type: &quot;nginx_access&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 关闭自带模板</span><br><span class="line"></span><br><span class="line">    setup.template.enabled: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 开启日志记录</span><br><span class="line"></span><br><span class="line">    logging.to_files: true</span><br><span class="line"></span><br><span class="line">    # 日志等级</span><br><span class="line"></span><br><span class="line">    logging.level: info</span><br><span class="line"></span><br><span class="line">    # 日志文件</span><br><span class="line"></span><br><span class="line">    logging.files:</span><br><span class="line"></span><br><span class="line">      # 日志位置</span><br><span class="line"></span><br><span class="line">      path: /opt/logs/filebeat/</span><br><span class="line"></span><br><span class="line">      # 日志名字</span><br><span class="line"></span><br><span class="line">      name: filebeat</span><br><span class="line"></span><br><span class="line">      # 日志轮转期限，必须要2~1024</span><br><span class="line"></span><br><span class="line">      keepfiles: 7</span><br><span class="line"></span><br><span class="line">      # 日志轮转权限</span><br><span class="line"></span><br><span class="line">      permissions: 0600</span><br></pre></td></tr></table></figure><h1 id="kibana配置"><a href="#kibana配置" class="headerlink" title="kibana配置"></a>kibana配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 192.168.1.21 /opt/kibana/config/kibana.yml</span><br><span class="line">    # 本节点访问端口</span><br><span class="line"></span><br><span class="line">    server.port: 5601</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点IP</span><br><span class="line"></span><br><span class="line">    server.host: &quot;192.168.1.21&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # 本节点名字</span><br><span class="line"></span><br><span class="line">    server.name: &quot;192.168.1.21&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    # elasticsearch集群IP</span><br><span class="line"></span><br><span class="line">    elasticsearch.hosts: [&quot;http://192.168.1.31:9200&quot;,</span><br><span class="line"></span><br><span class="line">                          &quot;http://192.168.1.32:9200&quot;,</span><br><span class="line"></span><br><span class="line">                          &quot;http://192.168.1.33:9200&quot;]</span><br></pre></td></tr></table></figure><h1 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># elasticsearch启动（3台es均启动）</span><br><span class="line"></span><br><span class="line">sudo -u elasticsearch /opt/elasticsearch/bin/elasticsearch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># filebeat启动</span><br><span class="line"></span><br><span class="line">/opt/filebeat/filebeat -e -c /opt/filebeat/filebeat.yml -d &quot;publish&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># kibana启动</span><br><span class="line"></span><br><span class="line">sudo -u kibana /opt/kibana/bin/kibana -c /opt/kibana/config/kibana.yml</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 17:22:57 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;转载自:&lt;br&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483801&amp;amp;idx=1&amp;amp;sn=11fee5756c8770688238624802ac51ea&amp;amp;chksm=fa769ab7cd0113a1ad19241290abe374b857227eebe989b3ba6b671b1eca855d380b76eeedde&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1125q5BPyFOD05H2trj4UdOf&amp;amp;sharer_sharetime=1574686325386&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s?__biz=MzUyNzk0NTI4MQ==&amp;amp;mid=2247483801&amp;amp;idx=1&amp;amp;sn=11fee5756c8770688238624802ac51ea&amp;amp;chksm=fa769ab7cd0113a1ad19241290abe374b857227eebe989b3ba6b671b1eca855d380b76eeedde&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1125q5BPyFOD05H2trj4UdOf&amp;amp;sharer_sharetime=1574686325386&amp;amp;sharer_shareid=6ec87ec9a11a0c18d61cde7663a9ef87#&lt;/a&gt;&lt;/p&gt;&lt;p&gt;阐述了EFK的安装部署，其中ES的架构为三节点，即master、ingest、data角色同时部署在三台服务器上。&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>基于ELK Nginx日志分析</title>
    <link href="https://yongnights.github.io/2020/04/14/%E5%9F%BA%E4%BA%8EELK%20Nginx%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%20/"/>
    <id>https://yongnights.github.io/2020/04/14/基于ELK Nginx日志分析 /</id>
    <published>2020-04-14T03:13:53.149Z</published>
    <updated>2020-04-14T03:28:03.059Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 14 2020 11:28:55 GMT+0800 (GMT+08:00) --><h1 id="配置Nginx-日志"><a href="#配置Nginx-日志" class="headerlink" title="配置Nginx 日志"></a>配置Nginx 日志</h1><p>Nginx 默认的access 日志为log格式，需要logstash 进行正则匹配和清洗处理，从而极大的增加了logstash的压力 所以我们Nginx 的日志修改为json 格式 。<br>Nginx access 日志和 Nginx error 日志<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    include       /etc/nginx/mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    log_format  json  &apos;&#123;&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos;</span><br><span class="line">                      &apos;&quot;server_addr&quot;:&quot;$server_addr&quot;,&apos;</span><br><span class="line">                      &apos;&quot;hostname&quot;:&quot;$hostname&quot;,&apos;</span><br><span class="line">                      &apos;&quot;remote_add&quot;:&quot;$remote_addr&quot;,&apos;</span><br><span class="line">                      &apos;&quot;request_method&quot;:&quot;$request_method&quot;,&apos;</span><br><span class="line">                      &apos;&quot;scheme&quot;:&quot;$scheme&quot;,&apos;</span><br><span class="line">                      &apos;&quot;server_name&quot;:&quot;$server_name&quot;,&apos;</span><br><span class="line">                      &apos;&quot;http_referer&quot;:&quot;$http_referer&quot;,&apos;</span><br><span class="line">                      &apos;&quot;request_uri&quot;:&quot;$request_uri&quot;,&apos;</span><br><span class="line">                      &apos;&quot;args&quot;:&quot;$args&quot;,&apos;</span><br><span class="line">                      &apos;&quot;body_bytes_sent&quot;:$body_bytes_sent,&apos;</span><br><span class="line">                      &apos;&quot;status&quot;: $status,&apos;</span><br><span class="line">                      &apos;&quot;request_time&quot;:$request_time,&apos;</span><br><span class="line">                      &apos;&quot;upstream_response_time&quot;:&quot;$upstream_response_time&quot;,&apos;</span><br><span class="line">                      &apos;&quot;upstream_addr&quot;:&quot;$upstream_addr&quot;,&apos;</span><br><span class="line">                      &apos;&quot;http_user_agent&quot;:&quot;$http_user_agent&quot;,&apos;</span><br><span class="line">                      &apos;&quot;https&quot;:&quot;$https&quot;&apos;</span><br><span class="line">                      &apos;&#125;&apos;;</span><br><span class="line">    access_log  /var/log/nginx/access.log json;</span><br></pre></td></tr></table></figure><p></p><a id="more"></a><p>针对不同的虚拟主机配置Nginx日志<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">access_log  /var/log/nginx/80.access.log json;</span><br><span class="line">error_log  /var/log/nginx/80.error.log error;</span><br><span class="line">access_log  /var/log/nginx/8001.access.log json;</span><br><span class="line">error_log  /var/log/nginx/8001.error.log error;</span><br></pre></td></tr></table></figure><p></p><h1 id="Nginx-error-log-类型"><a href="#Nginx-error-log-类型" class="headerlink" title="Nginx error_log 类型"></a>Nginx error_log 类型</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ debug | info | notice | warn | error | crit ]</span><br></pre></td></tr></table></figure><p>例如：error_log /var/log/nginx/8001.error.log crit;<br>解释：日志文件存储在/var/log/nginx/8001.error.log 文件中，错误类型为 crit ，也就是记录最少错误信息（debug最详细 crit最少）；</p><h1 id="filebeat-配置"><a href="#filebeat-配置" class="headerlink" title="filebeat 配置"></a>filebeat 配置</h1><p>针对<em>.access.log 和 </em>.error.log 的日志进行不同的标签封装<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@elk-node1 nginx]# egrep -v &quot;*#|^$&quot; /etc/filebeat/filebeat.yml </span><br><span class="line">filebeat.inputs:</span><br><span class="line">- type: log</span><br><span class="line">  enabled: true</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/nginx/*.access.log</span><br><span class="line">  tags: [&quot;nginx.access&quot;]</span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/nginx/*.error.log</span><br><span class="line">  tags: [&quot;nginx.error&quot;]</span><br><span class="line">filebeat.config.modules:</span><br><span class="line">  path: $&#123;path.config&#125;/modules.d/*.yml</span><br><span class="line">  reload.enabled: false</span><br><span class="line">setup.template.settings:</span><br><span class="line">  index.number_of_shards: 3</span><br><span class="line">setup.kibana:</span><br><span class="line">output.logstash:</span><br><span class="line">  hosts: [&quot;192.168.99.186:6044&quot;]</span><br><span class="line">processors:</span><br><span class="line">  - add_host_metadata: ~</span><br><span class="line">  - add_cloud_metadata: ~</span><br><span class="line">``` </span><br><span class="line"># logstash 配置</span><br><span class="line">## 查看logstash 安装已经安装插件</span><br></pre></td></tr></table></figure><p></p><p>/usr/share/logstash/bin/logstash-plugin list<br>[root@elk-node2 ~]#/usr/share/logstash/bin/logstash-plugin list |grep geoip<br>logstash-filter-geoip<br>/usr/share/logstash/bin/logstash-plugin install logstash-filter-geoip<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## Nginx 日志清洗规则</span><br></pre></td></tr></table></figure><p></p><p>[root@elk-node2 ~]# cat /etc/logstash/conf.d/nginx.conf<br>input {<br>beats {<br>port =&gt; 6044<br>}</p><p>}</p><p>filter {<br>if “nginx.access” in [tags] {<br>json {<br>source =&gt; “message”<br>remove_field =&gt; “message”<br>}<br>date {<br>match =&gt; [“timestamp” , “dd/MMM/YYYY:HH:mm:ss Z” ]<br>}<br>useragent {<br>target =&gt; “agent”<br>source =&gt; “http_user_agent”<br>}<br>geoip {</p><pre><code>         #target =&gt; &quot;geoip&quot;         source =&gt; &quot;remote_add&quot;         fields =&gt; [&quot;city_name&quot;, &quot;country_code2&quot;, &quot;country_name&quot;, &quot;region_name&quot;,&quot;longitude&quot;,&quot;latitude&quot;,&quot;ip&quot;]         add_field =&gt; [&quot;[geoip][coordinates]&quot;,&quot;%{[geoip][longitude]}&quot;]         add_field =&gt; [&quot;[geoip][coordinates]&quot;,&quot;%{[geoip][latitude]}&quot;]    }    mutate {        convert =&gt; [&quot;[geoip][coordinates]&quot;,&quot;float&quot;]     }}</code></pre><p>else if “nginx.error” in [tags] {<br>mutate {<br>remove_field =&gt; [“@timestamp”]<br>}<br>grok {<br>match =&gt; {“message” =&gt; “(?<datetime>%{YEAR}[./-]%{MONTHNUM}[./-]%{MONTHDAY}[- ]%{TIME}) [%{LOGLEVEL:severity}] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?&lt;real_ip&gt;%{IP}|%{HOSTNAME}))(?:, server: %{IPORHOST:domain}?)(?:, request: %{QS:request})?(?:, upstream: (?<upstream>\”%{URI}\”|%{QS}))?(?:, host: %{QS:request_host})?(?:, referrer: \”%{URI:referrer}\”)?”}<br>}<br>date {<br>match =&gt; [“datetime”, “yyyy/MM/dd HH:mm:ss”]<br>target =&gt; “@timestamp”<br>}<br>mutate {<br>remove_field =&gt; [“message”]<br>}<br>}<br>}</upstream></datetime></p><p>output{<br>stdout{codec =&gt; rubydebug}</p><pre><code>if &quot;nginx.access&quot; in [tags]{    elasticsearch{        index =&gt; &quot;logstash-nginx.access-%{+YYYY.MM.dd}&quot;        hosts =&gt; [&quot;192.168.99.186:9200&quot;]    }}else if &quot;nginx.error&quot; in [tags]{    elasticsearch {        index =&gt; &quot;nginx.error-%{+YYYY.MM.dd}&quot;        hosts =&gt; [&quot;192.168.99.186:9200&quot;]    }}</code></pre><p>}<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">注意：source 可以是任意处理后的字段，需要注意的是 IP 必须是公网 IP，否则logstash 的返回的geoip字段为空</span><br><span class="line"></span><br><span class="line">## Logstash解析</span><br><span class="line">Logstash 分为 Input、Output、Filter、Codec 等多种plugins。</span><br><span class="line">- Input：数据的输入源也支持多种插件，如elk官网的beats、file、graphite、http、kafka、redis、exec等等。</span><br><span class="line">- Output：数据的输出目的也支持多种插件，如本文的elasticsearch，当然这可能也是最常用的一种输出。以及exec、stdout终端、graphite、http、zabbix、nagios、redmine等等。</span><br><span class="line">- Filter：使用过滤器根据日志事件的特征，对数据事件进行处理过滤后，在输出。支持grok、date、geoip、mutate、ruby、json、kv、csv、checksum、dns、drop、xml等等。</span><br><span class="line">- Codec：编码插件，改变事件数据的表示方式，它可以作为对输入或输出运行该过滤。和其它产品结合，如rubydebug、graphite、fluent、nmap等等。</span><br><span class="line"></span><br><span class="line">## 配置文件的含义</span><br><span class="line">input</span><br><span class="line">filebeat  传入</span><br><span class="line"></span><br><span class="line">filter</span><br><span class="line">grok：数据结构化转换工具</span><br><span class="line">match：匹配条件格式</span><br><span class="line">geoip：该过滤器从geoip中匹配ip字段，显示该ip的地理位置</span><br><span class="line">source：ip来源字段　 </span><br><span class="line">target：指定插入的logstash字段目标存储为geoip　 </span><br><span class="line">add_field: 增加的字段，坐标经度　 </span><br><span class="line">add_field: 增加的字段，坐标纬度</span><br><span class="line">mutate：数据的修改、删除、类型转换　 </span><br><span class="line">convert：将坐标转为float类型　 </span><br><span class="line">replace：替换一个字段　 </span><br><span class="line">remove_field：移除message 的内容，因为数据已经过滤了一份，这里不必在用到该字段了，不然会相当于存两份　 </span><br><span class="line">date: 时间处理，该插件很实用，主要是用你日志文件中事件的事件来对timestamp进行转换　 </span><br><span class="line">match：匹配到timestamp字段后，修改格式为`dd/MMM/yyyy:HH:mm:ss Z` </span><br><span class="line">mutate：数据修改　 </span><br><span class="line">remove_field：移除timestamp字段。 </span><br><span class="line"></span><br><span class="line">output</span><br><span class="line">elasticsearch：输出到es中</span><br><span class="line">host：es的主机ip＋端口或者es 的FQDN＋端口</span><br><span class="line">index：为日志创建索引logstash-nginx-access-*，这里也就是kibana那里添加索引时的名称</span><br><span class="line"></span><br><span class="line"># Kibana 配置</span><br><span class="line">注意：默认配置中Kibana的访问日志会记录在/var/log/message 中，使用logging.quiet参数关闭日志</span><br></pre></td></tr></table></figure><p></p><p>[root@elk-node1 nginx]# egrep -v “*#|^$” /etc/kibana/kibana.yml<br>server.port: 5601<br>server.host: “192.168.99.185”<br>elasticsearch.hosts: [“<a href="http://192.168.99.185:9200&quot;]" target="_blank" rel="noopener">http://192.168.99.185:9200&quot;]</a><br>kibana.index: “.kibana”<br>logging.quiet: true<br>i18n.locale: “zh-CN”<br>tilemap.url: ‘<a href="http://webrd02.is.autonavi.com/appmaptile?lang=zh_cn&amp;size=1&amp;scale=1&amp;style=7&amp;x={x}&amp;y={y}&amp;z={z}&#39;" target="_blank" rel="noopener">http://webrd02.is.autonavi.com/appmaptile?lang=zh_cn&amp;size=1&amp;scale=1&amp;style=7&amp;x={x}&amp;y={y}&amp;z={z}&#39;</a><br><code>`</code><br>配置“tilemap.url:”参数使Kibana使用高德地图</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 14 2020 11:28:55 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;配置Nginx-日志&quot;&gt;&lt;a href=&quot;#配置Nginx-日志&quot; class=&quot;headerlink&quot; title=&quot;配置Nginx 日志&quot;&gt;&lt;/a&gt;配置Nginx 日志&lt;/h1&gt;&lt;p&gt;Nginx 默认的access 日志为log格式，需要logstash 进行正则匹配和清洗处理，从而极大的增加了logstash的压力 所以我们Nginx 的日志修改为json 格式 。&lt;br&gt;Nginx access 日志和 Nginx error 日志&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;http &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    include       /etc/nginx/mime.types;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    default_type  application/octet-stream;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    log_format  json  &amp;apos;&amp;#123;&amp;quot;@timestamp&amp;quot;:&amp;quot;$time_iso8601&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;server_addr&amp;quot;:&amp;quot;$server_addr&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;hostname&amp;quot;:&amp;quot;$hostname&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;remote_add&amp;quot;:&amp;quot;$remote_addr&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;request_method&amp;quot;:&amp;quot;$request_method&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;scheme&amp;quot;:&amp;quot;$scheme&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;server_name&amp;quot;:&amp;quot;$server_name&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;http_referer&amp;quot;:&amp;quot;$http_referer&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;request_uri&amp;quot;:&amp;quot;$request_uri&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;args&amp;quot;:&amp;quot;$args&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;body_bytes_sent&amp;quot;:$body_bytes_sent,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;status&amp;quot;: $status,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;request_time&amp;quot;:$request_time,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;upstream_response_time&amp;quot;:&amp;quot;$upstream_response_time&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;upstream_addr&amp;quot;:&amp;quot;$upstream_addr&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;http_user_agent&amp;quot;:&amp;quot;$http_user_agent&amp;quot;,&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;quot;https&amp;quot;:&amp;quot;$https&amp;quot;&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                      &amp;apos;&amp;#125;&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    access_log  /var/log/nginx/access.log json;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="nginx" scheme="https://yongnights.github.io/categories/elk/nginx/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="nginx" scheme="https://yongnights.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Linux日志切割方法[Logrotate、python、shell实现方式]</title>
    <link href="https://yongnights.github.io/2020/04/10/Linux%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%E6%96%B9%E6%B3%95%5BLogrotate%E3%80%81python%E3%80%81shell%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%5D/"/>
    <id>https://yongnights.github.io/2020/04/10/Linux日志切割方法[Logrotate、python、shell实现方式]/</id>
    <published>2020-04-10T10:05:58.456Z</published>
    <updated>2020-04-10T10:06:45.966Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Apr 10 2020 18:07:52 GMT+0800 (GMT+08:00) --><p><strong>Linux日志切割方法[Logrotate、python、shell实现方式]</strong></p><p>​ 对于Linux系统安全来说，日志文件是极其重要的工具。不知为何，我发现很多运维同学的服务器上都运行着一些诸如每天切分Nginx日志之类的cron脚本，大家似乎遗忘了Logrotate，争相发明自己的轮子，这真是让人沮丧啊！就好比明明身边躺着现成的性感美女，大家却忙着自娱自乐，罪过！logrotate程序是一个日志文件管理工具。用于分割日志文件，删除旧的日志文件，并创建新的日志文件，起到“转储”作用。可以节省磁盘空间。下面就对logrotate日志轮转操作做一梳理记录。</p><p><strong>1、什么是轮转？</strong></p><p><strong>日志轮循（轮转）：日志轮转，切割，备份，归档</strong></p><h2 id="2、为什么需要轮转？"><a href="#2、为什么需要轮转？" class="headerlink" title="2、为什么需要轮转？"></a><strong>2、为什么需要轮转？</strong></h2><p>☆ 避免日志过大占满/var/log的文件系统</p><p>☆ 方便日志查看 ☆ 将丢弃系统中最旧的日志文件，以节省空间 ☆ 日志轮转的程序是logrotate</p><p>☆ logrotate本身不是系统守护进程，它是通过计划任务crond每天执行</p><a id="more"></a><h2 id="3、安装与配置logrotate"><a href="#3、安装与配置logrotate" class="headerlink" title="3、安装与配置logrotate"></a><strong>3、安装与配置logrotate</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install logrotate -y</span><br></pre></td></tr></table></figure><p>3.1、配置文件介绍</p><p>Linux系统默认安装logrotate工具，它默认的配置文件在：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>/etc/logrotate.conf</span><br><span class="line"><span class="meta">#</span>/etc/logrotate.d/</span><br></pre></td></tr></table></figure><p>logrotate.conf 是主要的配置文件，logrotate.d 是一个目录，该目录里的所有文件都会被主动的读入/etc/logrotate.conf中执行。另外，如果 /etc/logrotate.d/ 里面的文件中没有设定一些细节，则会以/etc/logrotate.conf这个文件的设定来作为默认值。</p><p>logrotate是基于cron来运行的，其脚本是/etc/cron.daily/logrotate，日志轮转是系统自动完成的。实际运行时，Logrotate会调用配置文件/etc/logrotate.conf。可以在/etc/logrotate.d目录里放置自定义好的配置文件，用来覆盖Logrotate的缺省值。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# cat /etc/cron.daily/logrotate</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then </span><br><span class="line">/usr/bin/logger -t logrotate "ALERT exited abnormally with [$EXITVALUE]"</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p><strong>注意：如果等不及cron自动执行日志轮转，想手动强制切割日志，需要加 -f 参数；不过正式执行前最好通过Debug选项来验证一下（-d参数），这对调试也很重要</strong>！</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> /usr/sbin/logrotate -f /etc/logrotate.d/nginx</span><br><span class="line"><span class="meta">#</span> /usr/sbin/logrotate -d -f /etc/logrotate.d/nginx</span><br></pre></td></tr></table></figure><p><strong>logrotate命令格式</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">logrotate [OPTION...] &lt;configfile&gt;</span><br><span class="line">-d, --debug ：debug模式，测试配置文件是否有错误。</span><br><span class="line">-f, --force ：强制转储文件。</span><br><span class="line">-m, --mail=command ：压缩日志后，发送日志到指定邮箱。</span><br><span class="line">-s, --state=statefile ：使用指定的状态文件。</span><br><span class="line">-v, --verbose ：显示转储过程。</span><br></pre></td></tr></table></figure><p><strong>根据日志切割设置进行操作，并显示详细信息</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# /usr/sbin/logrotate -v /etc/logrotate.conf</span><br><span class="line">[root@huanqiu_web1 ~]# /usr/sbin/logrotate -v /etc/logrotate.d/php</span><br></pre></td></tr></table></figure><p><strong>根据日志切割设置进行执行，并显示详细信息,但是不进行具体操作，debug模式</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# /usr/sbin/logrotate -d /etc/logrotate.conf</span><br><span class="line">[root@huanqiu_web1 ~]# /usr/sbin/logrotate -d /etc/logrotate.d/nginx</span><br></pre></td></tr></table></figure><p><strong>查看各log文件的具体执行情况</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@fangfull_web1 ~]# cat /var/lib/logrotate.status</span><br></pre></td></tr></table></figure><h3 id="3-2、logrotate配置文件"><a href="#3-2、logrotate配置文件" class="headerlink" title="3.2、logrotate配置文件"></a>3.2、logrotate配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> vim /etc/logrotate.conf</span><br><span class="line">1 # see "man logrotate" for details</span><br><span class="line">2 # rotate log files weekly</span><br><span class="line">3 weekly</span><br><span class="line">4 # 以7天为一个周期(每周轮转)syslog子配置文件：</span><br><span class="line">5 # keep 4 weeks worth of backlogs</span><br><span class="line">6 rotate 4</span><br><span class="line"><span class="meta">#</span> 一次将存储4个归档日志。对于第五个归档，时间最久的归档将被删除</span><br><span class="line">7 8</span><br><span class="line"><span class="meta">#</span> create new (empty) log files after rotating old ones</span><br><span class="line">9 create</span><br><span class="line"><span class="meta">#</span> 当老的转储文件被归档后,创建一个新的空的转储文件重新记录,权限和原来的转储文件权限一样</span><br><span class="line">10</span><br><span class="line">11 # use date as a suffix of the rotated file</span><br><span class="line">12 dateext</span><br><span class="line"><span class="meta">#</span> 用日期来做轮转之后的文件的后缀名</span><br><span class="line">13</span><br><span class="line">14 # uncomment this if you want your log files compressed</span><br><span class="line">15 #compress</span><br><span class="line"><span class="meta">#</span> 指定不压缩转储文件,如需压缩去掉注释就可以了，主要是通过gzip压缩</span><br><span class="line">16</span><br><span class="line">17 # RPM packages drop log rotation information into this directory</span><br><span class="line">18 include /etc/logrotate.d</span><br><span class="line"><span class="meta">#</span> 加载外部目录</span><br><span class="line">19</span><br><span class="line">20 # no packages own wtmp and btmp -- we'll rotate them here</span><br><span class="line">21 /var/log/wtmp &#123;</span><br><span class="line">22 monthly 表示此文件是每月轮转，而不会用到上面的每周轮转</span><br><span class="line">23 create 0664 root utmp 轮转之后创建新文件，权限是0664，属于root用户和utmp组</span><br><span class="line">24 minsize 1M 文件大于1M，而且周期到了，才会轮转</span><br><span class="line"><span class="meta">#</span> size 1M 文件大小大于1M立马轮转，不管有没有到周期</span><br><span class="line">25 rotate 1 保留1份日志文件，每1个月备份一次日志文件</span><br><span class="line">26 &#125;</span><br><span class="line">27</span><br><span class="line">28 /var/log/btmp &#123;</span><br><span class="line">29 missingok 如果日志文件不存在，不报错</span><br><span class="line">30 monthly</span><br><span class="line">31 create 0600 root utmp</span><br><span class="line">32 rotate 1</span><br><span class="line">33 &#125;</span><br><span class="line">34</span><br><span class="line">35 # system-specific logs may be also be configured here.</span><br></pre></td></tr></table></figure><h3 id="3-3、syslog-子配置文件"><a href="#3-3、syslog-子配置文件" class="headerlink" title="3.3、syslog 子配置文件"></a>3.3、syslog 子配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@yunwei ~]# cat /etc/logrotate.d/syslog</span><br><span class="line">//这个子配置文件，没有指定的参数都会以默认方式轮转</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">/var/log/messages</span><br><span class="line">/var/log/secure</span><br><span class="line">/var/log/spooler</span><br><span class="line">&#123;</span><br><span class="line">sharedscripts</span><br><span class="line">不管有多少个文件待轮转，prerotate 和 postrotate 代码只执行一次</span><br><span class="line">postrotate日志轮转常见参数：</span><br><span class="line">4、实践：SSH服务日志轮转</span><br><span class="line">要求：</span><br><span class="line">☆ 每天进行轮转，保留5天的日志文件</span><br><span class="line">☆ 日志文件大小大于5M进行轮转，不管是否到轮转周期</span><br><span class="line">思路：</span><br><span class="line">☆ 将ssh服务的日志单独记录 /var/log/ssh.log</span><br><span class="line">☆ 修改logrotate程序的主配置文件或者在/etc/logrotate.d/目录创建一个文件</span><br><span class="line">轮转完后执行postrotate 和 endscript 之间的shell代码</span><br><span class="line">/bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">上面这一句话表示轮转后对rsyslog的pid进行刷新（但pid其实不变)</span><br><span class="line">endscript</span><br><span class="line">&#125; </span><br><span class="line">思考：</span><br><span class="line">为什么轮转后需要对rsyslog的pid进行刷新呢？</span><br></pre></td></tr></table></figure><h3 id="3-4、日志轮转常见参数"><a href="#3-4、日志轮转常见参数" class="headerlink" title="3.4、日志轮转常见参数"></a>3.4、日志轮转常见参数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">常用的指令解释，这些指令都可以在man logrotate 中找得到。</span><br><span class="line">daily 指定转储周期为每天</span><br><span class="line">monthly 指定转储周期为每月</span><br><span class="line">weekly &lt;-- 每周轮转一次(monthly)</span><br><span class="line">rotate 4 &lt;-- 同一个文件最多轮转4次，4次之后就删除该文件</span><br><span class="line">create 0664 root utmp &lt;-- 轮转之后创建新文件，权限是0664，属于root用户和utmp组</span><br><span class="line">dateext &lt;-- 用日期来做轮转之后的文件的后缀名</span><br><span class="line">compress &lt;-- 用gzip对轮转后的日志进行压缩</span><br><span class="line">minsize 30K &lt;-- 文件大于30K，而且周期到了，才会轮转</span><br><span class="line">size 30k &lt;-- 文件必须大于30K才会轮转，而且文件只要大于30K就会轮转不管周期是否已到</span><br><span class="line">missingok &lt;-- 如果日志文件不存在，不报错</span><br><span class="line">notifempty &lt;-- 如果日志文件是空的，不轮转</span><br><span class="line">delaycompress &lt;-- 下一次轮转的时候才压缩</span><br><span class="line">sharedscripts &lt;-- 不管有多少文件待轮转，prerotate和postrotate 代码只执行一次</span><br><span class="line">prerotate &lt;-- 如果符合轮转的条件</span><br><span class="line">则在轮转之前执行prerotate和endscript 之间的shell代码</span><br><span class="line">postrotate &lt;-- 轮转完后执行postrotate 和 endscript 之间的shell代码</span><br></pre></td></tr></table></figure><h3 id="3-5、logrotate默认生效以及相关配置进行解释"><a href="#3-5、logrotate默认生效以及相关配置进行解释" class="headerlink" title="3.5、logrotate默认生效以及相关配置进行解释"></a>3.5、logrotate默认生效以及相关配置进行解释</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">Logrotate是基于CRON来运行的，其脚本是/etc/cron.daily/logrotate，</span><br><span class="line">实际运行时，Logrotate会调用配置文件/etc/logrotate.conf。</span><br><span class="line">[root@test ~]# cat /etc/cron.daily/logrotate</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then</span><br><span class="line">    /usr/bin/logger -t logrotate "ALERT exited abnormally with [$EXITVALUE]"</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br><span class="line">   </span><br><span class="line">  </span><br><span class="line">Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，</span><br><span class="line">具体可以查询CRON的配置文件/etc/anacrontab（老版本的文件是/etc/crontab）</span><br><span class="line">[root@test ~]# cat /etc/anacrontab</span><br><span class="line"><span class="meta">#</span> /etc/anacrontab: configuration file for anacron</span><br><span class="line">   </span><br><span class="line"><span class="meta">#</span> See anacron(8) and anacrontab(5) for details.</span><br><span class="line">   </span><br><span class="line">SHELL=/bin/sh</span><br><span class="line">PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">MAILTO=root</span><br><span class="line"><span class="meta">#</span> the maximal random delay added to the base delay of the jobs</span><br><span class="line">RANDOM_DELAY=45                                                                  </span><br><span class="line">//这个是随机的延迟时间，表示最大45分钟</span><br><span class="line"><span class="meta">#</span> the jobs will be started during the following hours only</span><br><span class="line">START_HOURS_RANGE=3-22                                                          </span><br><span class="line"> //这个是开始时间</span><br><span class="line">   </span><br><span class="line"><span class="meta">#</span>period in days   delay in minutes   job-identifier   command</span><br><span class="line">1 5 cron.daily    nice run-parts /etc/cron.daily</span><br><span class="line">7 25  cron.weekly   nice run-parts /etc/cron.weekly</span><br><span class="line">@monthly 45 cron.monthly    nice run-parts /etc/cron.monthly</span><br><span class="line">   </span><br><span class="line">第一个是Recurrence period</span><br><span class="line">第二个是延迟时间</span><br><span class="line">所以cron.daily会在3:22+(5,45)这个时间段执行，/etc/cron.daily是个文件夹</span><br><span class="line">   </span><br><span class="line">通过默认/etc/anacrontab文件配置，会发现logrotate自动切割日志文件的默认时间是凌晨3点多。</span><br><span class="line">   </span><br><span class="line">=====================================================================================</span><br><span class="line">现在需要将切割时间调整到每天的晚上12点，即每天切割的日志是前一天的0-24点之间的内容。</span><br><span class="line">操作如下：</span><br><span class="line">[root@kevin ~]# mv /etc/anacrontab /etc/anacrontab.bak          //取消日志自动轮转的设置</span><br><span class="line"> </span><br><span class="line">[root@G6-bs02 logrotate.d]# cat nstc_nohup.out</span><br><span class="line">/data/nstc/nohup.out &#123;</span><br><span class="line">rotate 30</span><br><span class="line">dateext</span><br><span class="line">daily</span><br><span class="line">copytruncate</span><br><span class="line">compress</span><br><span class="line">notifempty</span><br><span class="line">missingok</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">[root@G6-bs02 logrotate.d]# cat syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">/var/log/messages</span><br><span class="line">/var/log/secure</span><br><span class="line">/var/log/history</span><br><span class="line">&#123;</span><br><span class="line">    sharedscripts</span><br><span class="line">    compress</span><br><span class="line">    rotate 30</span><br><span class="line">    daily</span><br><span class="line">    dateext</span><br><span class="line">    postrotate</span><br><span class="line">    /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">结合crontab进行自定义的定时轮转操作</span><br><span class="line">[root@kevin ~]# crontab -l</span><br><span class="line"><span class="meta">#</span>log logrotate</span><br><span class="line">59 23 * * * /usr/sbin/logrotate -f /etc/logrotate.d/syslog &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">59 23 * * * /usr/sbin/logrotate -f /etc/logrotate.d/nstc_nohup.out &gt;/dev/null 2&gt;&amp;1</span><br><span class="line"> </span><br><span class="line">[root@G6-bs02 ~]# ll /data/nstc/nohup.out*</span><br><span class="line">-rw------- 1 app app 33218 1月  25 09:43 /data/nstc/nohup.out</span><br><span class="line">-rw------- 1 app app 67678 1月  25 23:59 /data/nstc/nohup.out-20180125.gz</span><br></pre></td></tr></table></figure><h2 id="4、相关案例"><a href="#4、相关案例" class="headerlink" title="4、相关案例"></a><strong>4、相关案例</strong></h2><h3 id="4-1、logrotate实现Nginx日志切割"><a href="#4-1、logrotate实现Nginx日志切割" class="headerlink" title="4.1、logrotate实现Nginx日志切割"></a>4.1、logrotate实现Nginx日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@master-server ~]# vim /etc/logrotate.d/nginx</span><br><span class="line">/usr/local/nginx/logs/*.log &#123;</span><br><span class="line">daily</span><br><span class="line">rotate 7</span><br><span class="line">missingok</span><br><span class="line">notifempty</span><br><span class="line">dateext</span><br><span class="line">sharedscripts</span><br><span class="line">postrotate</span><br><span class="line">    if [ -f /usr/local/nginx/logs/nginx.pid ]; then</span><br><span class="line">        kill -USR1 `cat /usr/local/nginx/logs/nginx.pid`</span><br><span class="line">    fi</span><br><span class="line">endscript</span><br><span class="line">&#125;</span><br><span class="line">kill -USR1 指的是Nginx平滑重启</span><br></pre></td></tr></table></figure><h3 id="4-2、shell脚本实现Nginx日志切割"><a href="#4-2、shell脚本实现Nginx日志切割" class="headerlink" title="4.2、shell脚本实现Nginx日志切割"></a>4.2、shell脚本实现Nginx日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@bastion-IDC ~]# vim /usr/local/sbin/logrotate-nginx.sh</span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line"><span class="meta">#</span>创建转储日志压缩存放目录</span><br><span class="line">mkdir -p /data/nginx_logs/days</span><br><span class="line"><span class="meta">#</span>手工对nginx日志进行切割转换</span><br><span class="line">/usr/sbin/logrotate -vf /etc/logrotate.d/nginx</span><br><span class="line"><span class="meta">#</span>当前时间</span><br><span class="line">time=$(date -d "yesterday" +"%Y-%m-%d")</span><br><span class="line"><span class="meta">#</span>进入转储日志存放目录</span><br><span class="line">cd /data/nginx_logs/days</span><br><span class="line"><span class="meta">#</span>对目录中的转储日志文件的文件名进行统一转换</span><br><span class="line">for i in $(ls ./ | grep "^\(.*\)\.[[:digit:]]$")</span><br><span class="line">do</span><br><span class="line">mv $&#123;i&#125; ./$(echo $&#123;i&#125;|sed -n 's/^\(.*\)\.\([[:digit:]]\)$/\1/p')-$(echo $time)</span><br><span class="line">done</span><br><span class="line"><span class="meta">#</span>对转储的日志文件进行压缩存放，并删除原有转储的日志文件，只保存压缩后的日志文件。以节约存储空间</span><br><span class="line">for i in $(ls ./ | grep "^\(.*\)\-\([[:digit:]-]\+\)$")</span><br><span class="line">do</span><br><span class="line">tar jcvf $&#123;i&#125;.bz2 ./$&#123;i&#125;</span><br><span class="line">rm -rf ./$&#123;i&#125;</span><br><span class="line">done</span><br><span class="line"><span class="meta">#</span>只保留最近7天的压缩转储日志文件</span><br><span class="line">find /data/nginx_logs/days/* -name "*.bz2" -mtime 7 -type f -exec rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure><p><strong>crontab定时执行</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@bastion-IDC ~# crontab -e</span><br><span class="line"><span class="meta">#</span>logrotate</span><br><span class="line">0 0 * * * /bin/bash -x /usr/local/sbin/logrotate-nginx.sh &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><p><strong>手动执行脚本</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@bastion-IDC ~]# /bin/bash -x /usr/local/sbin/logrotate-nginx.sh</span><br><span class="line">[root@bastion-IDC ~]# cd /data/nginx_logs/days</span><br><span class="line">[root@bastion-IDC days]# lshuantest.access_log-2017-01-18.bz2</span><br></pre></td></tr></table></figure><h3 id="4-3、PHP日志切割"><a href="#4-3、PHP日志切割" class="headerlink" title="4.3、PHP日志切割"></a>4.3、PHP日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# cat /etc/logrotate.d/php</span><br><span class="line">/Data/logs/php/*log &#123;</span><br><span class="line">    daily</span><br><span class="line">    rotate 365</span><br><span class="line">    missingok</span><br><span class="line">    notifempty</span><br><span class="line">    compress</span><br><span class="line">    dateext</span><br><span class="line">    sharedscripts</span><br><span class="line">    postrotate</span><br><span class="line">        if [ -f /Data/app/php5.6.26/var/run/php-fpm.pid ]; then</span><br><span class="line">            kill -USR1 `cat /Data/app/php5.6.26/var/run/php-fpm.pid`</span><br><span class="line">        fi</span><br><span class="line">    endscript</span><br><span class="line">    postrotate</span><br><span class="line">        /bin/chmod 644 /Data/logs/php/*gz</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">[root@huanqiu_web1 ~]# ll /Data/app/php5.6.26/var/run/php-fpm.pid</span><br><span class="line">-rw-r--r-- 1 root root 4 Dec 28 17:03 /Data/app/php5.6.26/var/run/php-fpm.pid</span><br><span class="line"> </span><br><span class="line">[root@huanqiu_web1 ~]# cd /Data/logs/php</span><br><span class="line">[root@huanqiu_web1 php]# ll</span><br><span class="line">total 25676</span><br><span class="line">-rw-r--r-- 1 root   root         0 Jun  1  2016 error.log</span><br><span class="line">-rw-r--r-- 1 nobody nobody     182 Aug 30  2015 error.log-20150830.gz</span><br><span class="line">-rw-r--r-- 1 nobody nobody     371 Sep  1  2015 error.log-20150901.gz</span><br><span class="line">-rw-r--r-- 1 nobody nobody     315 Sep  7  2015 error.log-20150907.gz</span><br><span class="line">.........</span><br></pre></td></tr></table></figure><h3 id="4-4、linux系统日志切割"><a href="#4-4、linux系统日志切割" class="headerlink" title="4.4、linux系统日志切割"></a>4.4、linux系统日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# cat /etc/logrotate.d/syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">/var/log/messages</span><br><span class="line">/var/log/secure</span><br><span class="line">/var/log/spooler</span><br><span class="line">&#123;</span><br><span class="line">    sharedscripts</span><br><span class="line">    postrotate</span><br><span class="line">    /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/messages*</span><br><span class="line">-rw------- 1 root root 34248975 Jan 19 18:42 /var/log/messages</span><br><span class="line">-rw------- 1 root root 51772994 Dec 25 03:11 /var/log/messages-20161225</span><br><span class="line">-rw------- 1 root root 51800210 Jan  1 03:05 /var/log/messages-20170101</span><br><span class="line">-rw------- 1 root root 51981366 Jan  8 03:36 /var/log/messages-20170108</span><br><span class="line">-rw------- 1 root root 51843025 Jan 15 03:40 /var/log/messages-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/cron*</span><br><span class="line">-rw------- 1 root root 2155681 Jan 19 18:43 /var/log/cron</span><br><span class="line">-rw------- 1 root root 2932618 Dec 25 03:11 /var/log/cron-20161225</span><br><span class="line">-rw------- 1 root root 2939305 Jan  1 03:06 /var/log/cron-20170101</span><br><span class="line">-rw------- 1 root root 2951820 Jan  8 03:37 /var/log/cron-20170108</span><br><span class="line">-rw------- 1 root root 3203992 Jan 15 03:41 /var/log/cron-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/secure*</span><br><span class="line">-rw------- 1 root root  275343 Jan 19 18:36 /var/log/secure</span><br><span class="line">-rw------- 1 root root 2111936 Dec 25 03:06 /var/log/secure-20161225</span><br><span class="line">-rw------- 1 root root 2772744 Jan  1 02:57 /var/log/secure-20170101</span><br><span class="line">-rw------- 1 root root 1115543 Jan  8 03:26 /var/log/secure-20170108</span><br><span class="line">-rw------- 1 root root  731599 Jan 15 03:40 /var/log/secure-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/spooler*</span><br><span class="line">-rw------- 1 root root 0 Jan 15 03:41 /var/log/spooler</span><br><span class="line">-rw------- 1 root root 0 Dec 18 03:21 /var/log/spooler-20161225</span><br><span class="line">-rw------- 1 root root 0 Dec 25 03:11 /var/log/spooler-20170101</span><br><span class="line">-rw------- 1 root root 0 Jan  1 03:06 /var/log/spooler-20170108</span><br><span class="line">-rw------- 1 root root 0 Jan  8 03:37 /var/log/spooler-20170115</span><br></pre></td></tr></table></figure><h3 id="4-5、Tomcat日志切割"><a href="#4-5、Tomcat日志切割" class="headerlink" title="4.5、Tomcat日志切割"></a>4.5、Tomcat日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_web1 ~]# cat /etc/logrotate.d/syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">/var/log/messages</span><br><span class="line">/var/log/secure</span><br><span class="line">/var/log/spooler</span><br><span class="line">&#123;</span><br><span class="line">    sharedscripts</span><br><span class="line">    postrotate</span><br><span class="line">    /bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/messages*</span><br><span class="line">-rw------- 1 root root 34248975 Jan 19 18:42 /var/log/messages</span><br><span class="line">-rw------- 1 root root 51772994 Dec 25 03:11 /var/log/messages-20161225</span><br><span class="line">-rw------- 1 root root 51800210 Jan  1 03:05 /var/log/messages-20170101</span><br><span class="line">-rw------- 1 root root 51981366 Jan  8 03:36 /var/log/messages-20170108</span><br><span class="line">-rw------- 1 root root 51843025 Jan 15 03:40 /var/log/messages-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/cron*</span><br><span class="line">-rw------- 1 root root 2155681 Jan 19 18:43 /var/log/cron</span><br><span class="line">-rw------- 1 root root 2932618 Dec 25 03:11 /var/log/cron-20161225</span><br><span class="line">-rw------- 1 root root 2939305 Jan  1 03:06 /var/log/cron-20170101</span><br><span class="line">-rw------- 1 root root 2951820 Jan  8 03:37 /var/log/cron-20170108</span><br><span class="line">-rw------- 1 root root 3203992 Jan 15 03:41 /var/log/cron-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/secure*</span><br><span class="line">-rw------- 1 root root  275343 Jan 19 18:36 /var/log/secure</span><br><span class="line">-rw------- 1 root root 2111936 Dec 25 03:06 /var/log/secure-20161225</span><br><span class="line">-rw------- 1 root root 2772744 Jan  1 02:57 /var/log/secure-20170101</span><br><span class="line">-rw------- 1 root root 1115543 Jan  8 03:26 /var/log/secure-20170108</span><br><span class="line">-rw------- 1 root root  731599 Jan 15 03:40 /var/log/secure-20170115</span><br><span class="line">[root@huanqiu_web1 ~]# ll /var/log/spooler*</span><br><span class="line">-rw------- 1 root root 0 Jan 15 03:41 /var/log/spooler</span><br><span class="line">-rw------- 1 root root 0 Dec 18 03:21 /var/log/spooler-20161225</span><br><span class="line">-rw------- 1 root root 0 Dec 25 03:11 /var/log/spooler-20170101</span><br><span class="line">-rw------- 1 root root 0 Jan  1 03:06 /var/log/spooler-20170108</span><br><span class="line">-rw------- 1 root root 0 Jan  8 03:37 /var/log/spooler-20170115</span><br></pre></td></tr></table></figure><h3 id="4-6、使用python脚本进行jumpserver日志切割"><a href="#4-6、使用python脚本进行jumpserver日志切割" class="headerlink" title="4.6、使用python脚本进行jumpserver日志切割"></a>4.6、使用python脚本进行jumpserver日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@test-vm01 mnt]# cat log_rotate.py</span><br><span class="line"><span class="meta">#</span>!/usr/bin/env python</span><br><span class="line">   </span><br><span class="line">import datetime,os,sys,shutil</span><br><span class="line">   </span><br><span class="line">log_path = '/opt/jumpserver/logs/'</span><br><span class="line">log_file = 'jumpserver.log'</span><br><span class="line">   </span><br><span class="line">yesterday = (datetime.datetime.now() - datetime.timedelta(days = 1))</span><br><span class="line">   </span><br><span class="line">try:</span><br><span class="line">    os.makedirs(log_path + yesterday.strftime('%Y') + os.sep + yesterday.strftime('%m'))</span><br><span class="line">except OSError,e:</span><br><span class="line">    print</span><br><span class="line">    print e</span><br><span class="line">    sys.exit()</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">shutil.move(log_path + log_file,log_path \</span><br><span class="line">            + yesterday.strftime('%Y') + os.sep \</span><br><span class="line">            + yesterday.strftime('%m') + os.sep \</span><br><span class="line">            + log_file + '_' + yesterday.strftime('%Y%m%d') + '.log')</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">os.popen("sudo /opt/jumpserver/service.sh restart")</span><br><span class="line"> </span><br><span class="line">手动执行这个脚本：</span><br><span class="line">[root@test-vm01 mnt]# chmod 755 log_rotate.py</span><br><span class="line">[root@test-vm01 mnt]# python log_rotate.py</span><br><span class="line"> </span><br><span class="line">查看日志切割后的效果：</span><br><span class="line">[root@test-vm01 mnt]# ls /opt/jumpserver/logs/</span><br><span class="line">2017  jumpserver.log </span><br><span class="line">[root@test-vm01 mnt]# ls /opt/jumpserver/logs/2017/</span><br><span class="line">09</span><br><span class="line">[root@test-vm01 mnt]# ls /opt/jumpserver/logs/2017/09/</span><br><span class="line">jumpserver.log_20170916.log</span><br><span class="line"> </span><br><span class="line">然后做每日的定时切割任务：</span><br><span class="line">[root@test-vm01 mnt]# crontab -e</span><br><span class="line">30 1 * * * /usr/bin/python /mnt/log_rotate.py &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure><h3 id="4-7、使用python脚本进行Nginx日志切割"><a href="#4-7、使用python脚本进行Nginx日志切割" class="headerlink" title="4.7、使用python脚本进行Nginx日志切割"></a>4.7、使用python脚本进行Nginx日志切割</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@test-vm01 mnt]# vim log_rotate.py</span><br><span class="line"><span class="meta">#</span>!/usr/bin/env python</span><br><span class="line">   </span><br><span class="line">import datetime,os,sys,shutil</span><br><span class="line">   </span><br><span class="line">log_path = '/app/nginx/logs/'</span><br><span class="line">log_file = 'www_access.log'</span><br><span class="line">   </span><br><span class="line">yesterday = (datetime.datetime.now() - datetime.timedelta(days = 1))</span><br><span class="line">   </span><br><span class="line">try:</span><br><span class="line">    os.makedirs(log_path + yesterday.strftime('%Y') + os.sep + yesterday.strftime('%m'))</span><br><span class="line">except OSError,e:</span><br><span class="line">    print</span><br><span class="line">    print e</span><br><span class="line">    sys.exit()</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">shutil.move(log_path + log_file,log_path \</span><br><span class="line">            + yesterday.strftime('%Y') + os.sep \</span><br><span class="line">            + yesterday.strftime('%m') + os.sep \</span><br><span class="line">            + log_file + '_' + yesterday.strftime('%Y%m%d') + '.log')</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">os.popen("sudo kill -USR1 `cat /app/nginx/logs/nginx.pid`")</span><br></pre></td></tr></table></figure><h2 id="5、logrotate无法自动轮询日志的解决办法"><a href="#5、logrotate无法自动轮询日志的解决办法" class="headerlink" title="5、logrotate无法自动轮询日志的解决办法"></a><strong>5、logrotate无法自动轮询日志的解决办法</strong></h2><p>起始原因：使用logrotate轮询nginx日志，配置好之后，发现nginx日志连续两天没被切割，这是为什么呢？？然后开始检查日志切割的配置文件是否有问题，检查后确定配置文件一切正常。于是怀疑是logrotate预定的cron没执行，查看了cron的日志，发现有一条”Dec 7 04:02:01 www crond[18959]: (root) CMD (run-parts /etc/cron.daily)”的日志，证明cron在04:02分时已经执行/etc/cron.daily目录下的程序。接着查看/etc /cron.daily/logrotate（这是logrotate自动轮转的脚本）的内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_test ~]# cat /etc/cron.daily/logrotate</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then</span><br><span class="line">    /usr/bin/logger -t logrotate "ALERT exited abnormally with [$EXITVALUE]"</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>有发现异常，配置好的日志轮转操作都是由这个脚本完成的，一切运行正常，脚本应该就没问题。 直接执行命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_test ~]# /usr/sbin/logrotate /etc/logrotate.conf</span><br></pre></td></tr></table></figure><p>这些系统日志是正常轮询了，但nginx日志却还是没轮询,接着强行启动记录文件维护操作，纵使logrotate指令认为没有需要，应该有可能是logroate认为nginx日志太小，不进行轮询。 故需要强制轮询，即在/etc/cron.daily/logrotate脚本中将 -t 参数替换成 -f 参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_test ~]# cat /etc/cron.daily/logrotate</span><br><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf &gt;/dev/null 2&gt;&amp;1</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then</span><br><span class="line">    /usr/bin/logger -f logrotate "ALERT exited abnormally with [$EXITVALUE]"</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p><strong>重启下cron服务</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@huanqiu_test ~]# /etc/init.d/crond restart</span><br><span class="line">Stopping crond: [ OK ]Starting crond: [ OK ]</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Fri Apr 10 2020 18:07:52 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;strong&gt;Linux日志切割方法[Logrotate、python、shell实现方式]&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;​ 对于Linux系统安全来说，日志文件是极其重要的工具。不知为何，我发现很多运维同学的服务器上都运行着一些诸如每天切分Nginx日志之类的cron脚本，大家似乎遗忘了Logrotate，争相发明自己的轮子，这真是让人沮丧啊！就好比明明身边躺着现成的性感美女，大家却忙着自娱自乐，罪过！logrotate程序是一个日志文件管理工具。用于分割日志文件，删除旧的日志文件，并创建新的日志文件，起到“转储”作用。可以节省磁盘空间。下面就对logrotate日志轮转操作做一梳理记录。&lt;/p&gt;&lt;p&gt;&lt;strong&gt;1、什么是轮转？&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;日志轮循（轮转）：日志轮转，切割，备份，归档&lt;/strong&gt;&lt;/p&gt;&lt;h2 id=&quot;2、为什么需要轮转？&quot;&gt;&lt;a href=&quot;#2、为什么需要轮转？&quot; class=&quot;headerlink&quot; title=&quot;2、为什么需要轮转？&quot;&gt;&lt;/a&gt;&lt;strong&gt;2、为什么需要轮转？&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;☆ 避免日志过大占满/var/log的文件系统&lt;/p&gt;&lt;p&gt;☆ 方便日志查看 ☆ 将丢弃系统中最旧的日志文件，以节省空间 ☆ 日志轮转的程序是logrotate&lt;/p&gt;&lt;p&gt;☆ logrotate本身不是系统守护进程，它是通过计划任务crond每天执行&lt;/p&gt;
    
    </summary>
    
      <category term="shell" scheme="https://yongnights.github.io/categories/shell/"/>
    
      <category term="Linux" scheme="https://yongnights.github.io/categories/shell/Linux/"/>
    
    
      <category term="Linux" scheme="https://yongnights.github.io/tags/Linux/"/>
    
      <category term="shell" scheme="https://yongnights.github.io/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>使用 Auditbeat 模块监控 shell 命令</title>
    <link href="https://yongnights.github.io/2020/04/03/%E4%BD%BF%E7%94%A8%20Auditbeat%20%E6%A8%A1%E5%9D%97%E7%9B%91%E6%8E%A7%20shell%20%E5%91%BD%E4%BB%A4/"/>
    <id>https://yongnights.github.io/2020/04/03/使用 Auditbeat 模块监控 shell 命令/</id>
    <published>2020-04-03T02:26:23.282Z</published>
    <updated>2020-04-03T02:38:18.649Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><blockquote><p>使用 Auditbeat 模块监控 shell 命令<br>Auditbeat Audited 模块可以用来监控所有用户在系统上执行的 shell 命令。在终端用户偶尔才会登录的服务器上，通常需要进行监控。<br>该示例是在 CentOS Linux 7.6 上使用 Auditbeat 7.4.2 RPM 软件包和 Elasticsearch Service（ESS）[<a href="https://www.elastic.co/products/elasticsearch/service]上的" target="_blank" rel="noopener">https://www.elastic.co/products/elasticsearch/service]上的</a> Elastic Stack ] 7.4.2 部署的。</p></blockquote><p><em>可以参考其中的思路，配置流程等，使用本机自建的ES，不使用Elasticsearch Service（ESS）集群</em></p><h1 id="禁用-Auditd"><a href="#禁用-Auditd" class="headerlink" title="禁用 Auditd"></a>禁用 Auditd</h1><p>系统守护进程 auditd 会影响 Auditbeat Audited 模块的正常使用，所以必须将其禁用。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 停止 auditd：</span><br><span class="line">service auditd stop</span><br><span class="line"></span><br><span class="line"># 禁用服务：</span><br><span class="line">systemctl disable auditd.service</span><br></pre></td></tr></table></figure><p></p><p>如果您在使用 Auditbeat Auditd 模块的同时也必须要运行 Audited 进程，那么在内核版本为 3.16 或者更高的情况下可以考虑设置 socket_type: multicast 参数。默认值为 unicast。有关此参数的更多信息，请参见文档[<a href="https://www.elastic.co/guide/en/beats/auditbeat/master/auditbeat-module-auditd.html#_configuration_options_14]的配置选项部分。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/master/auditbeat-module-auditd.html#_configuration_options_14]的配置选项部分。</a></p><a id="more"></a><h1 id="配置-Auditbeat"><a href="#配置-Auditbeat" class="headerlink" title="配置 Auditbeat"></a>配置 Auditbeat</h1><p>Auditbeat 守护进程将事件数据发送到一个 Elasticsearch Service（ESS）集群中。有关更多详细信息，请参见文档Auditbeat[<a href="https://www.elastic.co/guide/en/beats/auditbeat/master/configuring-howto-auditbeat.html]" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/master/configuring-howto-auditbeat.html]</a><br>中的配置部分。<br>要想获取工作示例，必须配置 Auditbeat 的 cloud.id 和 cloud.auth 参数，详情参见此文档[<a href="https://www.elastic.co/guide/en/beats/auditbeat/master/configure-cloud-id.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/master/configure-cloud-id.html]。</a><br>编辑 /etc/auditbeat/auditbeat.yml：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cloud.id: &lt;your_cloud_id&gt;</span><br><span class="line">cloud.auth: ingest_user:password</span><br></pre></td></tr></table></figure><p></p><p>如果您要将数据发送到 Elasticsearch 集群（例如本地实例），请参见此文档：[<a href="https://www.elastic.co/guide/en/beats/auditbeat/master/configure-cloud-id.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/master/configure-cloud-id.html]。</a></p><h1 id="Auditbeat-模块规则"><a href="#Auditbeat-模块规则" class="headerlink" title="Auditbeat 模块规则"></a>Auditbeat 模块规则</h1><p>Audited 模块订阅内核以接收系统事件。定义规则以捕获这些事件，并且使用Linux Auditctl 进程所使用的格式，详情参见此文档：[<a href="https://linux.die.net/man/8/auditctl]。" target="_blank" rel="noopener">https://linux.die.net/man/8/auditctl]。</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/auditbeat/audit.rules.d/rules.conf</span><br><span class="line">-a exit,always -F arch=b64 -F euid=0 -S execve -k root_acct</span><br><span class="line">-a exit,always -F arch=b32 -F euid=0 -S execve -k root_acct</span><br><span class="line">-a exit,always -F arch=b64 -F euid&gt;=1000 -S execve -k user_acct</span><br><span class="line">-a exit,always -F arch=b32 -F euid&gt;=1000 -S execve -k user_acct</span><br></pre></td></tr></table></figure><p></p><ul><li>euid 是用户的有效ID。0 代表会获取 root 用户和 uid &gt;=1000 或者权限更高的其他用户的所有活动。</li><li>-k<key>用于为事件分配任意“键”，它将显示在 tags 字段中。它还可以在 Kibana 中用来对事件进行过滤和分类。</key></li></ul><h1 id="Auditbeat-设置命令"><a href="#Auditbeat-设置命令" class="headerlink" title="Auditbeat 设置命令"></a>Auditbeat 设置命令</h1><p>运行Auditbeat 加载索引模板，读取 node pipelines，索引文件周期策略和Kibana 仪表板。<br><code>auditbeat -e setup</code><br>如果您不使用ESS，欢迎参考此文档[<a href="https://www.elastic.co/guide/en/beats/auditbeat/current/setup-kibana-endpoint.html]" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/current/setup-kibana-endpoint.html]</a> 来设置您的 Kibana 端点。</p><h1 id="开始使用"><a href="#开始使用" class="headerlink" title="开始使用"></a>开始使用</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">systemctl start auditbeat</span><br><span class="line"></span><br><span class="line"># 列出启用的规则：</span><br><span class="line">auditbeat show auditd-rules</span><br><span class="line">-a never,exit -S all -F pid=23617</span><br><span class="line">-a always,exit -F arch=b64 -S execve -F euid=root -F key=root_acct</span><br><span class="line">-a always,exit -F arch=b32 -S execve -F euid=root -F key=root_acct</span><br><span class="line">-a always,exit -F arch=b64 -S execve -F euid&gt;=vagrant -F key=user_acct</span><br><span class="line">-a always,exit -F arch=b32 -S execve -F euid&gt;=vagrant -F key=user_acct</span><br></pre></td></tr></table></figure><h1 id="监控数据"><a href="#监控数据" class="headerlink" title="监控数据"></a>监控数据</h1><p>当用户执行一些类似于 whoami，ls 以及 lsblk 的 shell 命令时，kibana 中就会发现这些事件。</p><ul><li>Kibana 会显示出 user.name，process.executable，process.args 和 tags 这些选定的字段。</li><li>过滤的字段是 user.name: root 和 auditd.data.syscall: execve。</li><li>每秒刷新一次数据。</li></ul><h1 id="TTY-审计"><a href="#TTY-审计" class="headerlink" title="TTY 审计"></a>TTY 审计</h1><p>当系统中发生 TTY 事件时，Auditbeat Audited 模块也可以接收它们。配置system-auth PAM 配置文件以启用 TTY。只有 root 用户的 TTY 事件将被实时记录。其他用户的事件通常会被缓冲直到 exit。TTY 审计会捕获系统内置命令像pwd，test 等。<br>追加以下内容到 /etc/pam.d/system-auth 便可以对所有用户启用审核，关于 pam_tty_audit 的详细信息，参见此文档：[<a href="https://linux.die.net/man/8/pam_tty_audit]。" target="_blank" rel="noopener">https://linux.die.net/man/8/pam_tty_audit]。</a><br><code>session required pam_tty_audit.so enable=*</code></p><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo su -</span><br><span class="line">Last login: Fri Nov 22 23:43:00 UTC 2019 on pts/0</span><br><span class="line">$ helllloooo there!</span><br><span class="line">-bash: helllloooo: command not found</span><br><span class="line">$ exit</span><br></pre></td></tr></table></figure><h1 id="Kibana-发现"><a href="#Kibana-发现" class="headerlink" title="Kibana 发现"></a>Kibana 发现</h1><h1 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h1><p>Auditbeat 还可以做什么：</p><ul><li>当一个文件在磁盘上更改（创建，更新或删除）时可以发送事件，得益于 file_integrity 模块，详情参考此文档：[<a href="https://www.elastic.co/guide/en/beats/auditbeat/current/auditbeat-module-file_integrity.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/current/auditbeat-module-file_integrity.html]。</a></li><li>通过 system 模块发送有关系统的指标，详情参考此文档：[<a href="https://www.elastic.co/guide/en/beats/auditbeat/current/auditbeat-module-system.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/current/auditbeat-module-system.html]。</a><br>该链接还提供了 Auditbeat 的相关文档，详情参考此文档：[<a href="https://www.elastic.co/guide/en/beats/auditbeat/current/index.html]。" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/auditbeat/current/index.html]。</a></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;blockquote&gt;&lt;p&gt;使用 Auditbeat 模块监控 shell 命令&lt;br&gt;Auditbeat Audited 模块可以用来监控所有用户在系统上执行的 shell 命令。在终端用户偶尔才会登录的服务器上，通常需要进行监控。&lt;br&gt;该示例是在 CentOS Linux 7.6 上使用 Auditbeat 7.4.2 RPM 软件包和 Elasticsearch Service（ESS）[&lt;a href=&quot;https://www.elastic.co/products/elasticsearch/service]上的&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.elastic.co/products/elasticsearch/service]上的&lt;/a&gt; Elastic Stack ] 7.4.2 部署的。&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;em&gt;可以参考其中的思路，配置流程等，使用本机自建的ES，不使用Elasticsearch Service（ESS）集群&lt;/em&gt;&lt;/p&gt;&lt;h1 id=&quot;禁用-Auditd&quot;&gt;&lt;a href=&quot;#禁用-Auditd&quot; class=&quot;headerlink&quot; title=&quot;禁用 Auditd&quot;&gt;&lt;/a&gt;禁用 Auditd&lt;/h1&gt;&lt;p&gt;系统守护进程 auditd 会影响 Auditbeat Audited 模块的正常使用，所以必须将其禁用。&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 停止 auditd：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;service auditd stop&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 禁用服务：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;systemctl disable auditd.service&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果您在使用 Auditbeat Auditd 模块的同时也必须要运行 Audited 进程，那么在内核版本为 3.16 或者更高的情况下可以考虑设置 socket_type: multicast 参数。默认值为 unicast。有关此参数的更多信息，请参见文档[&lt;a href=&quot;https://www.elastic.co/guide/en/beats/auditbeat/master/auditbeat-module-auditd.html#_configuration_options_14]的配置选项部分。&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.elastic.co/guide/en/beats/auditbeat/master/auditbeat-module-auditd.html#_configuration_options_14]的配置选项部分。&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Auditbeat" scheme="https://yongnights.github.io/categories/elk/Auditbeat/"/>
    
      <category term="shell" scheme="https://yongnights.github.io/categories/elk/Auditbeat/shell/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Auditbeat" scheme="https://yongnights.github.io/tags/Auditbeat/"/>
    
      <category term="shell" scheme="https://yongnights.github.io/tags/shell/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch：如何对PDF文件进行搜索</title>
    <link href="https://yongnights.github.io/2020/04/03/Elasticsearch%EF%BC%9A%E5%A6%82%E4%BD%95%E5%AF%B9PDF%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E6%90%9C%E7%B4%A2/"/>
    <id>https://yongnights.github.io/2020/04/03/Elasticsearch：如何对PDF文件进行搜索/</id>
    <published>2020-04-03T01:57:15.620Z</published>
    <updated>2020-04-03T02:25:31.514Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><blockquote><p>Elasticsearch 通常用于字符串，数字，日期等数据类型的检索，但是在 HCM、ERP 和电子商务等应用程序中经常存在对办公文档进行搜索的需求。今天的这篇文章中我们来讲一下如何实现 PDF、DOC、XLS 等办公文件的搜索，本解决方案适用于 Elasticsearch 5.0 以后的版本。</p></blockquote><h1 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h1><p>首先把我们的 .pdf 文件进行 Base64 处理，然后上传到 Elasticsearch 中的 ingest node 中进行处理。我们可以通过 Ingest attachment plugin 来使得 Elasticsearch 提取通用格式的文件附件比如 PPT、XLS及PDF。最终，数据进入到 Elasticsearch 的 data node 中以便让我们进行搜索。</p><h1 id="导入PDF文件到Elasticsearch中"><a href="#导入PDF文件到Elasticsearch中" class="headerlink" title="导入PDF文件到Elasticsearch中"></a>导入PDF文件到Elasticsearch中</h1><h2 id="准备PDF文件"><a href="#准备PDF文件" class="headerlink" title="准备PDF文件"></a>准备PDF文件</h2><p>我们可以使用 Word 或其它编辑软件来生产一个 PDF 文件，暂且我们叫这个文件的名字为 sample.pdf，而它的内容非常简单，在 sample.pdf 文件中，我们只有一句话：“I like this useful tool”。</p><h2 id="安装-Ingest-attachment-plugin"><a href="#安装-Ingest-attachment-plugin" class="headerlink" title="安装 Ingest attachment plugin"></a>安装 Ingest attachment plugin</h2><p>Ingest attachment plugin 允许 Elasticsearch 通过使用 Apache 文本提取库 Tika 提取通用格式（例如：PPT，XLS 和 PDF）的文件附件。Apache Tika 工具包可从一千多种不同的文件类型中检测并提取元数据和文本。所有这些文件类型都可以通过一个界面进行解析，从而使 Tika 对搜索引擎索引，内容分析，翻译等有用。<br>需要注意的是，源字段必须是 Base64 编码的二进制，如果不想增加在 Base64 之间来回转换的开销，则可以使用 CBOR 格式而不是 JSON，并将字段指定为字节数组而不是字符串表示形式，这样处理器将跳过 Base64 解码。<br>可以使用插件管理器安装此插件，该插件必须安装在集群中的每个节点上，并且每个节点必须在安装后重新启动。<br><code>sudo bin/elasticsearch-plugin install ingest-attachment</code><br>等我们安装好这个插件后，我们可以通过如下的命令来查看该插件是否已经被成功安装好了:<br><code>./bin/elasticsearch-plugin list</code></p><a id="more"></a><h2 id="创建-attachment-pipeline"><a href="#创建-attachment-pipeline" class="headerlink" title="创建 attachment pipeline"></a>创建 attachment pipeline</h2><p>在我们的 ingest node 上创建一个叫做 pdfattachment 的 pipleline：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PUT _ingest/pipeline/pdfattachment</span><br><span class="line">&#123;</span><br><span class="line">  &quot;description&quot;: &quot;Extract attachment information encoded in Base64 with UTF-8 charset&quot;,</span><br><span class="line">  &quot;processors&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;attachment&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;file&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h2 id="转换并上传PDF文件的内容到Elasticsearch中"><a href="#转换并上传PDF文件的内容到Elasticsearch中" class="headerlink" title="转换并上传PDF文件的内容到Elasticsearch中"></a>转换并上传PDF文件的内容到Elasticsearch中</h2><p>对于 Ingest attachment plugin 来说，它的数据必须是 Base64 的。我们可以在网站Base64 encoder 来进行转换，我们可以直接通过下面的脚本来进行操作：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">!/bin/bash</span><br><span class="line"></span><br><span class="line">encodedPdf=`cat sample.pdf | base64`</span><br><span class="line"></span><br><span class="line">json=&quot;&#123;\&quot;file\&quot;:\&quot;$&#123;encodedPdf&#125;\&quot;&#125;&quot;</span><br><span class="line"></span><br><span class="line">echo &quot;$json&quot; &gt; json.file</span><br><span class="line"></span><br><span class="line">curl -XPOST &apos;http://localhost:9200/pdf-test1/_doc?pipeline=pdfattachment&amp;pretty&apos; -H &apos;Content-Type: application/json&apos; -d @json.file</span><br></pre></td></tr></table></figure><p></p><p>在上面的脚本中，我们针对 sample.pdf 进行 Base64 的转换，并生成一个叫做 json.file 的文件。在最后，我们把这个 json.file 文件的内容通过 curl 指令上传到 Elasticsearch 中，我们可以在 Elasticsearch 中查看一个叫做 pdf-test1 的索引。</p><h1 id="查看索引并搜索"><a href="#查看索引并搜索" class="headerlink" title="查看索引并搜索"></a>查看索引并搜索</h1><p>可以通过如下的命令来查询 pdf-test1 索引：<br><code>GET pdf-test1/_search</code><br>可以看出来，我们的索引中有一个叫做 content 的字段，它包含了我们的 pdf 文件的内容，这个字段可以同我们进行搜索。在上面我们也看到了一个很大的一个字段 file，它含有我们转换过的 Base64 格式的内容。如果我们不想要这个字段，我们可以通过添加另外一个 remove processor 来除去这个字段：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">PUT _ingest/pipeline/pdfattachment</span><br><span class="line">&#123;</span><br><span class="line">  &quot;description&quot;: &quot;Extract attachment information encoded in Base64 with UTF-8 charset&quot;,</span><br><span class="line">  &quot;processors&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;attachment&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;file&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;remove&quot;: &#123;</span><br><span class="line">        &quot;field&quot;: &quot;file&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;blockquote&gt;&lt;p&gt;Elasticsearch 通常用于字符串，数字，日期等数据类型的检索，但是在 HCM、ERP 和电子商务等应用程序中经常存在对办公文档进行搜索的需求。今天的这篇文章中我们来讲一下如何实现 PDF、DOC、XLS 等办公文件的搜索，本解决方案适用于 Elasticsearch 5.0 以后的版本。&lt;/p&gt;&lt;/blockquote&gt;&lt;h1 id=&quot;实现原理&quot;&gt;&lt;a href=&quot;#实现原理&quot; class=&quot;headerlink&quot; title=&quot;实现原理&quot;&gt;&lt;/a&gt;实现原理&lt;/h1&gt;&lt;p&gt;首先把我们的 .pdf 文件进行 Base64 处理，然后上传到 Elasticsearch 中的 ingest node 中进行处理。我们可以通过 Ingest attachment plugin 来使得 Elasticsearch 提取通用格式的文件附件比如 PPT、XLS及PDF。最终，数据进入到 Elasticsearch 的 data node 中以便让我们进行搜索。&lt;/p&gt;&lt;h1 id=&quot;导入PDF文件到Elasticsearch中&quot;&gt;&lt;a href=&quot;#导入PDF文件到Elasticsearch中&quot; class=&quot;headerlink&quot; title=&quot;导入PDF文件到Elasticsearch中&quot;&gt;&lt;/a&gt;导入PDF文件到Elasticsearch中&lt;/h1&gt;&lt;h2 id=&quot;准备PDF文件&quot;&gt;&lt;a href=&quot;#准备PDF文件&quot; class=&quot;headerlink&quot; title=&quot;准备PDF文件&quot;&gt;&lt;/a&gt;准备PDF文件&lt;/h2&gt;&lt;p&gt;我们可以使用 Word 或其它编辑软件来生产一个 PDF 文件，暂且我们叫这个文件的名字为 sample.pdf，而它的内容非常简单，在 sample.pdf 文件中，我们只有一句话：“I like this useful tool”。&lt;/p&gt;&lt;h2 id=&quot;安装-Ingest-attachment-plugin&quot;&gt;&lt;a href=&quot;#安装-Ingest-attachment-plugin&quot; class=&quot;headerlink&quot; title=&quot;安装 Ingest attachment plugin&quot;&gt;&lt;/a&gt;安装 Ingest attachment plugin&lt;/h2&gt;&lt;p&gt;Ingest attachment plugin 允许 Elasticsearch 通过使用 Apache 文本提取库 Tika 提取通用格式（例如：PPT，XLS 和 PDF）的文件附件。Apache Tika 工具包可从一千多种不同的文件类型中检测并提取元数据和文本。所有这些文件类型都可以通过一个界面进行解析，从而使 Tika 对搜索引擎索引，内容分析，翻译等有用。&lt;br&gt;需要注意的是，源字段必须是 Base64 编码的二进制，如果不想增加在 Base64 之间来回转换的开销，则可以使用 CBOR 格式而不是 JSON，并将字段指定为字节数组而不是字符串表示形式，这样处理器将跳过 Base64 解码。&lt;br&gt;可以使用插件管理器安装此插件，该插件必须安装在集群中的每个节点上，并且每个节点必须在安装后重新启动。&lt;br&gt;&lt;code&gt;sudo bin/elasticsearch-plugin install ingest-attachment&lt;/code&gt;&lt;br&gt;等我们安装好这个插件后，我们可以通过如下的命令来查看该插件是否已经被成功安装好了:&lt;br&gt;&lt;code&gt;./bin/elasticsearch-plugin list&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/categories/elk/Elasticsearch/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch索引和查询性能调优的21条建议</title>
    <link href="https://yongnights.github.io/2020/04/03/Elasticsearch%E7%B4%A2%E5%BC%95%E5%92%8C%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%9A%8421%E6%9D%A1%E5%BB%BA%E8%AE%AE/"/>
    <id>https://yongnights.github.io/2020/04/03/Elasticsearch索引和查询性能调优的21条建议/</id>
    <published>2020-04-03T01:30:32.227Z</published>
    <updated>2020-04-03T01:49:18.635Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><h1 id="Elasticsearch部署建议"><a href="#Elasticsearch部署建议" class="headerlink" title="Elasticsearch部署建议"></a>Elasticsearch部署建议</h1><h2 id="1-选择合理的硬件配置：尽可能使用-SSD"><a href="#1-选择合理的硬件配置：尽可能使用-SSD" class="headerlink" title="1. 选择合理的硬件配置：尽可能使用 SSD"></a>1. 选择合理的硬件配置：尽可能使用 SSD</h2><p>Elasticsearch 最大的瓶颈往往是磁盘读写性能，尤其是随机读取性能。使用SSD（PCI-E接口SSD卡/SATA接口SSD盘）通常比机械硬盘（SATA盘/SAS盘）查询速度快5~10倍，写入性能提升不明显。<br>对于文档检索类查询性能要求较高的场景，建议考虑 SSD 作为存储，同时按照 1:10 的比例配置内存和硬盘。对于日志分析类查询并发要求较低的场景，可以考虑采用机械硬盘作为存储，同时按照 1:50 的比例配置内存和硬盘。单节点存储数据建议在2TB以内，不要超过5TB，避免查询速度慢、系统不稳定。</p><h2 id="2-给JVM配置机器一半的内存，但是不建议超过32G"><a href="#2-给JVM配置机器一半的内存，但是不建议超过32G" class="headerlink" title="2. 给JVM配置机器一半的内存，但是不建议超过32G"></a>2. 给JVM配置机器一半的内存，但是不建议超过32G</h2><p>修改 conf/jvm.options 配置，-Xms 和 -Xmx 设置为相同的值，推荐设置为机器内存的一半左右，剩余一半留给操作系统缓存使用。JVM 内存建议不要低于 2G，否则有可能因为内存不足导致 ES 无法正常启动或内存溢出，JVM 建议不要超过 32G，否则 JVM 会禁用内存对象指针压缩技术，造成内存浪费。机器内存大于 64G 内存时，推荐配置 -Xms30g -Xmx30g。JVM 堆内存较大时，内存垃圾回收暂停时间比较长，建议配置 ZGC 或 G1 垃圾回收算法。</p><h2 id="3-规模较大的集群配置专有主节点，避免脑裂问题"><a href="#3-规模较大的集群配置专有主节点，避免脑裂问题" class="headerlink" title="3. 规模较大的集群配置专有主节点，避免脑裂问题"></a>3. 规模较大的集群配置专有主节点，避免脑裂问题</h2><p>Elasticsearch 主节点负责集群元信息管理、index 的增删操作、节点的加入剔除，定期将最新的集群状态广播至各个节点。在集群规模较大时，建议配置专有主节点只负责集群管理，不存储数据，不承担数据读写压力。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 专有主节点配置(conf/elasticsearch.yml)：</span><br><span class="line">node.master:true</span><br><span class="line">node.data: false</span><br><span class="line">node.ingest:false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 数据节点配置(conf/elasticsearch.yml)：</span><br><span class="line">node.master:false</span><br><span class="line">node.data:true</span><br><span class="line">node.ingest:true</span><br></pre></td></tr></table></figure><p></p><p>Elasticsearch 默认每个节点既是候选主节点，又是数据节点。最小主节点数量参数 minimum_master_nodes 推荐配置为候选主节点数量一半以上，该配置告诉 Elasticsearch 当没有足够的 master 候选节点的时候，不进行 master 节点选举，等 master 节点足够了才进行选举。<br>例如对于 3 节点集群，最小主节点数量从默认值 1 改为 2。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 最小主节点数量配置(conf/elasticsearch.yml)：</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br></pre></td></tr></table></figure><p></p><a id="more"></a><h2 id="4-Linux操作系统调优"><a href="#4-Linux操作系统调优" class="headerlink" title="4. Linux操作系统调优"></a>4. Linux操作系统调优</h2><p>关闭交换分区，防止内存置换降低性能。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 将/etc/fstab 文件中包含swap的行注释掉</span><br><span class="line">sed -i &apos;/swap/s/^/#/&apos; /etc/fstab</span><br><span class="line">swapoff -a</span><br><span class="line"></span><br><span class="line"># 单用户可以打开的最大文件数量，可以设置为官方推荐的65536或更大些</span><br><span class="line">echo &quot;* - nofile 655360&quot; &gt;&gt; /etc/security/limits.conf</span><br><span class="line"></span><br><span class="line"># 单用户线程数调大</span><br><span class="line">echo &quot;* - nproc 131072&quot; &gt;&gt; /etc/security/limits.conf</span><br><span class="line"></span><br><span class="line"># 单进程可以使用的最大map内存区域数量</span><br><span class="line">echo &quot;vm.max_map_count = 655360&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line"># 参数修改立即生效</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p></p><h1 id="索引性能调优建议"><a href="#索引性能调优建议" class="headerlink" title="索引性能调优建议"></a>索引性能调优建议</h1><h2 id="1-设置合理的索引分片数和副本数"><a href="#1-设置合理的索引分片数和副本数" class="headerlink" title="1. 设置合理的索引分片数和副本数"></a>1. 设置合理的索引分片数和副本数</h2><p>索引分片数建议设置为集群节点的整数倍，初始数据导入时副本数设置为 0，生产环境副本数建议设置为 1（设置 1 个副本，集群任意 1 个节点宕机数据不会丢失；设置更多副本会占用更多存储空间，操作系统缓存命中率会下降，检索性能不一定提升）。单节点索引分片数建议不要超过 3 个，每个索引分片推荐 10-40GB 大小，索引分片数设置后不可以修改，副本数设置后可以修改。<br>Elasticsearch6.X 及之前的版本默认索引分片数为 5、副本数为 1，从 Elasticsearch7.0 开始调整为默认索引分片数为 1、副本数为 1。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"># 索引设置</span><br><span class="line">curl -XPUT http://localhost:9200/fulltext001?pretty -H &apos;Content-Type: application/json&apos;   </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;refresh_interval&quot;: &quot;30s&quot;,</span><br><span class="line">        &quot;merge.policy.max_merged_segment&quot;: &quot;1000mb&quot;,</span><br><span class="line">        &quot;translog.durability&quot;: &quot;async&quot;,</span><br><span class="line">        &quot;translog.flush_threshold_size&quot;: &quot;2gb&quot;,</span><br><span class="line">        &quot;translog.sync_interval&quot;: &quot;100s&quot;,</span><br><span class="line">        &quot;index&quot;: &#123;</span><br><span class="line">            &quot;number_of_shards&quot;: &quot;21&quot;,</span><br><span class="line">            &quot;number_of_replicas&quot;: &quot;0&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># mapping 设置</span><br><span class="line">curl -XPOST http://localhost:9200/fulltext001/doc/_mapping?pretty  -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;doc&quot;: &#123;</span><br><span class="line">        &quot;_all&quot;: &#123;</span><br><span class="line">            &quot;enabled&quot;: false</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;content&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                &quot;analyzer&quot;: &quot;ik_max_word&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;id&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 写入数据示例</span><br><span class="line">curl -XPUT &apos;http://localhost:9200/fulltext001/doc/1?pretty&apos; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;id&quot;: &quot;https://www.huxiu.com/article/215169.html&quot;,</span><br><span class="line">    &quot;content&quot;: &quot;“娃娃机，迷你KTV，VR体验馆，堪称商场三大标配‘神器’。”一家地处商业中心的大型综合体负责人告诉懂懂笔记，在过去的这几个月里，几乎所有的综合体都“标配”了这三种“设备”…&quot;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 修改副本数示例</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/fulltext001/_settings&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;number_of_replicas&quot;: 1</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="2-使用批量请求"><a href="#2-使用批量请求" class="headerlink" title="2. 使用批量请求"></a>2. 使用批量请求</h2><p>使用批量请求将产生比单文档索引请求好得多的性能。写入数据时调用批量提交接口，推荐每批量提交 5~15MB 数据。例如单条记录 1KB 大小，每批次提交 10000 条左右记录写入性能较优；单条记录 5KB 大小，每批次提交 2000 条左右记录写入性能较优。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 批量请求接口API</span><br><span class="line">curl -XPOST &quot;http://localhost:9200/_bulk&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;</span><br><span class="line">&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot; &#125; &#125;&#123; &quot;field1&quot; : &quot;value1&quot; &#125;</span><br><span class="line">&#123; &quot;delete&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot; &#125; &#125;</span><br><span class="line">&#123; &quot;create&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;3&quot; &#125; &#125;&#123; &quot;field1&quot; : &quot;value3&quot; &#125;</span><br><span class="line">&#123; &quot;update&quot; : &#123;&quot;_id&quot; : &quot;1&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_index&quot; : &quot;test&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;field2&quot; : &quot;value2&quot;&#125; &#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="3-通过多进程-线程发送数据"><a href="#3-通过多进程-线程发送数据" class="headerlink" title="3. 通过多进程/线程发送数据"></a>3. 通过多进程/线程发送数据</h2><p>单线程批量写入数据往往不能充分利用服务器 CPU 资源，可以尝试调整写入线程数或者在多个客户端上同时向 Elasticsearch 服务器提交写入请求。与批量调整大小请求类似，只有测试才能确定最佳的 worker 数量。可以通过逐渐增加工作任务数量来测试，直到集群上的 I/O 或 CPU 饱和。</p><h2 id="4-调大refresh-interval"><a href="#4-调大refresh-interval" class="headerlink" title="4. 调大refresh interval"></a>4. 调大refresh interval</h2><p>在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。<br>并不是所有的情况都需要每秒刷新。可能你正在使用 Elasticsearch 索引大量的日志文件，你可能想优化索引速度而不是近实时搜索，可以通过设置 refresh_interval，降低每个索引的刷新频率。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 设置 refresh interval API</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/index&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;refresh_interval&quot;: &quot;30s&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><p>refresh_interval 可以在已经存在的索引上进行动态更新，在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &quot;http://localhost:9200/index/_settings&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123; &quot;refresh_interval&quot;: -1 &#125;&apos;</span><br><span class="line"></span><br><span class="line">curl -XPUT &quot;http://localhost:9200/index/_settings&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123; &quot;refresh_interval&quot;: &quot;1s&quot; &#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="5-配置事务日志参数"><a href="#5-配置事务日志参数" class="headerlink" title="5. 配置事务日志参数"></a>5. 配置事务日志参数</h2><p>事务日志 translog 用于防止节点失败时的数据丢失。它的设计目的是帮助 shard 恢复操作，否则数据可能会从内存 flush 到磁盘时发生意外而丢失。事务日志 translog 的落盘(fsync)是 ES 在后台自动执行的，默认每 5 秒钟提交到磁盘上，或者当 translog 文件大小大于 512MB 提交，或者在每个成功的索引、删除、更新或批量请求时提交。<br>索引创建时，可以调整默认日志刷新间隔 5 秒，例如改为 60 秒，index.translog.sync_interval: “60s”。创建索引后，可以动态调整 translog 参数，”index.translog.durability”:”async” 相当于关闭了 index、bulk 等操作的同步 flush translog 操作，仅使用默认的定时刷新、文件大小阈值刷新的机制。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 动态设置 translog API</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/index&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;index.translog.durability&quot;: &quot;async&quot;,</span><br><span class="line">        &quot;translog.flush_threshold_size&quot;: &quot;2gb&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="6-设计mapping配置合适的字段类型"><a href="#6-设计mapping配置合适的字段类型" class="headerlink" title="6. 设计mapping配置合适的字段类型"></a>6. 设计mapping配置合适的字段类型</h2><p>Elasticsearch 在写入文档时，如果请求中指定的索引名不存在，会自动创建新索引，并根据文档内容猜测可能的字段类型。但这往往不是最高效的，我们可以根据应用场景来设计合理的字段类型。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 例如写入一条记录</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/twitter/doc/1?pretty&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;user&quot;: &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot;: &quot;2009-11-15T13:12:00&quot;,</span><br><span class="line">    &quot;message&quot;: &quot;Trying out Elasticsearch, so far so good?&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><p>查询 Elasticsearch 自动创建的索引 mapping，会发现将 post_date 字段自动识别为 date 类型，但是 message 和 user 字段被设置为 text、keyword 冗余字段，造成写入速度降低、占用更多磁盘空间。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;twitter&quot;: &#123;</span><br><span class="line">        &quot;mappings&quot;: &#123;</span><br><span class="line">            &quot;doc&quot;: &#123;</span><br><span class="line">                &quot;properties&quot;: &#123;</span><br><span class="line">                    &quot;message&quot;: &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                        &quot;fields&quot;: &#123;</span><br><span class="line">                            &quot;keyword&quot;: &#123;</span><br><span class="line">                                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                                &quot;ignore_above&quot;: 256</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;post_date&quot;: &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;date&quot;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    &quot;user&quot;: &#123;</span><br><span class="line">                        &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                        &quot;fields&quot;: &#123;</span><br><span class="line">                            &quot;keyword&quot;: &#123;</span><br><span class="line">                                &quot;type&quot;: &quot;keyword&quot;,</span><br><span class="line">                                &quot;ignore_above&quot;: 256</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;settings&quot;: &#123;</span><br><span class="line">            &quot;index&quot;: &#123;</span><br><span class="line">                &quot;number_of_shards&quot;: &quot;5&quot;,</span><br><span class="line">                &quot;number_of_replicas&quot;: &quot;1&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>根据业务场景设计索引配置合理的分片数、副本数，设置字段类型、分词器。如果不需要合并全部字段，禁用 _all 字段，通过 copy_to 来合并字段。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &quot;http://localhost:9200/twitter?pretty&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;index&quot;: &#123;</span><br><span class="line">            &quot;number_of_shards&quot;: &quot;20&quot;,</span><br><span class="line">            &quot;number_of_replicas&quot;: &quot;0&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line">curl -XPOST &quot;http://localhost:9200/twitter/doc/_mapping?pretty&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;doc&quot;: &#123;</span><br><span class="line">        &quot;_all&quot;: &#123;</span><br><span class="line">            &quot;enabled&quot;: false</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;user&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;post_date&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;date&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;message&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">                &quot;analyzer&quot;: &quot;cjk&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h1 id="查询性能调优建议"><a href="#查询性能调优建议" class="headerlink" title="查询性能调优建议"></a>查询性能调优建议</h1><h2 id="1-使用过滤器缓存和分片查询缓存"><a href="#1-使用过滤器缓存和分片查询缓存" class="headerlink" title="1. 使用过滤器缓存和分片查询缓存"></a>1. 使用过滤器缓存和分片查询缓存</h2><p>默认情况下，Elasticsearch 的查询会计算返回的每条数据与查询语句的相关度，但对于非全文索引的使用场景，用户并不关心查询结果与查询条件的相关度，只是想精确地查找目标数据。此时，可以通过 filter 来让 Elasticsearch 不计算评分，并且尽可能地缓存 filter 的结果集，供后续包含相同 filter 的查询使用，提高查询效率。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 普通查询</span><br><span class="line">curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">            &quot;user&quot;: &quot;kimchy&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 过滤器(filter)查询</span><br><span class="line">curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;filter&quot;: &#123;</span><br><span class="line">                &quot;match&quot;: &#123;</span><br><span class="line">                    &quot;user&quot;: &quot;kimchy&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><p>分片查询缓存的目的是缓存聚合、提示词结果和命中数（它不会缓存返回的文档，因此，它只在 search_type=count 时起作用）。<br>通过下面的参数我们可以设置分片缓存的大小，默认情况下是 JVM 堆的 1% 大小，当然我们也可以手动设置在 config/elasticsearch.yml 文件里。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">indices.requests.cache.size: 1%</span><br></pre></td></tr></table></figure><p></p><p>查看缓存占用内存情况(name 表示节点名, query_cache 表示过滤器缓存，request_cache 表示分片缓存，fielddata 表示字段数据缓存，segments 表示索引段)。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET &quot;http://localhost:9200/_cat/nodes?h=name,query_cache.memory_size,request_cache.memory_size,fielddata.memory_size,segments.memory&amp;v&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="2-使用路由-routing"><a href="#2-使用路由-routing" class="headerlink" title="2. 使用路由 routing"></a>2. 使用路由 routing</h2><p>Elasticsearch写入文档时，文档会通过一个公式路由到一个索引中的一个分片上。默认的公式如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shard_num = hash(_routing) % num_primary_shards</span><br></pre></td></tr></table></figure><p></p><p><code>_routing</code> 字段的取值，默认是 <code>_id</code> 字段，可以根据业务场景设置经常查询的字段作为路由字段。例如可以考虑将用户 id、地区作为路由字段，查询时可以过滤不必要的分片，加快查询速度。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># 写入时指定路由</span><br><span class="line">curl -XPUT &quot;http://localhost:9200/my_index/my_type/1?routing=user1&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;title&quot;: &quot;This is a document&quot;,</span><br><span class="line">    &quot;author&quot;: &quot;user1&quot;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 查询时不指定路由，需要查询所有分片</span><br><span class="line">curl -XGET &quot;http://localhost:9200/my_index/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">            &quot;title&quot;: &quot;document&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 返回结果</span><br><span class="line">&#123;</span><br><span class="line">    &quot;took&quot;: 2,</span><br><span class="line">    &quot;timed_out&quot;: false,</span><br><span class="line">    &quot;_shards&quot;: &#123;</span><br><span class="line">        &quot;total&quot;: 5,</span><br><span class="line">        &quot;successful&quot;: 5,</span><br><span class="line">        &quot;skipped&quot;: 0,</span><br><span class="line">        &quot;failed&quot;: 0</span><br><span class="line">    &#125;</span><br><span class="line">    ... ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询时指定路由，只需要查询1个分片</span><br><span class="line">curl -XGET &quot;http://localhost:9200/my_index/_search?routing=user1&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">            &quot;title&quot;: &quot;document&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line"></span><br><span class="line"># 返回结果</span><br><span class="line">&#123;</span><br><span class="line">    &quot;took&quot;: 1,</span><br><span class="line">    &quot;timed_out&quot;: false,</span><br><span class="line">    &quot;_shards&quot;: &#123;</span><br><span class="line">        &quot;total&quot;: 1,</span><br><span class="line">        &quot;successful&quot;: 1,</span><br><span class="line">        &quot;skipped&quot;: 0,</span><br><span class="line">        &quot;failed&quot;: 0</span><br><span class="line">    &#125;</span><br><span class="line">    ... ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h2 id="3-强制合并只读索引，关闭历史数据索引"><a href="#3-强制合并只读索引，关闭历史数据索引" class="headerlink" title="3. 强制合并只读索引，关闭历史数据索引"></a>3. 强制合并只读索引，关闭历史数据索引</h2><p>只读索引可以从合并成一个单独的大 segment 中收益，减少索引碎片，减少 JVM 堆常驻内存。强制合并索引操作会耗费大量磁盘 IO，尽量配置在业务低峰期(例如凌晨)执行。历史数据索引如果业务上不再支持查询请求，可以考虑关闭索引，减少 JVM 内存占用。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 索引forcemerge API</span><br><span class="line">curl -XPOST &quot;http://localhost:9200/abc20180923/_forcemerge?max_num_segments=1&quot;</span><br><span class="line"></span><br><span class="line"># 索引关闭API</span><br><span class="line">curl -XPOST &quot;http://localhost:9200/abc2017*/_close&quot;</span><br></pre></td></tr></table></figure><p></p><h2 id="4-配置合适的分词器"><a href="#4-配置合适的分词器" class="headerlink" title="4. 配置合适的分词器"></a>4. 配置合适的分词器</h2><p>Elasticsearch 内置了很多分词器，包括 standard、cjk、nGram 等，也可以安装自研/开源分词器。根据业务场景选择合适的分词器，避免全部采用默认 standard 分词器。</p><p>常用分词器：</p><ul><li>standard：默认分词，英文按空格切分，中文按照单个汉字切分。</li><li>cjk：根据二元索引对中日韩文分词，可以保证查全率。</li><li>nGram：可以将英文按照字母切分，结合ES的短语搜索(match_phrase)使用。</li><li>IK：比较热门的中文分词，能按照中文语义切分，可以自定义词典。</li><li>pinyin：可以让用户输入拼音，就能查找到相关的关键词。</li><li>aliws：阿里巴巴自研分词，支持多种模型和分词算法，词库丰富，分词结果准确，适用于电商等对查准要求高的场景。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 分词效果测试API</span><br><span class="line">curl -XPOST &quot;http://localhost:9200/_analyze&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;analyzer&quot;: &quot;ik_max_word&quot;,</span><br><span class="line">    &quot;text&quot;: &quot;南京市长江大桥&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><h2 id="5-配置查询聚合节点"><a href="#5-配置查询聚合节点" class="headerlink" title="5. 配置查询聚合节点"></a>5. 配置查询聚合节点</h2><p>查询聚合节点可以发送粒子查询请求到其他节点，收集和合并结果，以及响应发出查询的客户端。通过给查询聚合节点配置更高规格的 CPU 和内存，可以加快查询运算速度、提升缓存命中率。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 查询聚合节点配置(conf/elasticsearch.yml)：</span><br><span class="line">node.master:false</span><br><span class="line">node.data:false</span><br><span class="line">node.ingest:false</span><br></pre></td></tr></table></figure><p></p><h2 id="6-设置查询读取记录条数和字段"><a href="#6-设置查询读取记录条数和字段" class="headerlink" title="6. 设置查询读取记录条数和字段"></a>6. 设置查询读取记录条数和字段</h2><p>默认的查询请求通常返回排序后的前 10 条记录，最多一次读取 10000 条记录，通过 from 和 size 参数控制读取记录范围，避免一次读取过多的记录。通过 _source 参数可以控制返回字段信息，尽量避免读取大字段。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 查询请求示例</span><br><span class="line">curl -XGET http://localhost:9200/fulltext001/_search?pretty  -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d &apos;&#123;</span><br><span class="line">    &quot;from&quot;: 0,</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;_source&quot;: &quot;id&quot;,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;must&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;match&quot;: &#123;</span><br><span class="line">                        &quot;content&quot;: &quot;虎嗅&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;sort&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;id&quot;: &#123;</span><br><span class="line">                &quot;order&quot;: &quot;asc&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="7-设置-teminate-after-查询快速返回"><a href="#7-设置-teminate-after-查询快速返回" class="headerlink" title="7. 设置 teminate_after 查询快速返回"></a>7. 设置 teminate_after 查询快速返回</h2><p>如果不需要精确统计查询命中记录条数，可以配 teminate_after 指定每个 shard 最多匹配 N 条记录后返回，设置查询超时时间 timeout。在查询结果中可以通过 “terminated_early” 字段标识是否提前结束查询请求。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># teminate_after 查询语法示例</span><br><span class="line">curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;from&quot;: 0,</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;timeout&quot;: &quot;10s&quot;,</span><br><span class="line">    &quot;terminate_after&quot;: 1000,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot;: &#123;</span><br><span class="line">            &quot;filter&quot;: &#123;</span><br><span class="line">                &quot;term&quot;: &#123;</span><br><span class="line">                    &quot;user&quot;: &quot;elastic&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="8-避免查询深度翻页"><a href="#8-避免查询深度翻页" class="headerlink" title="8. 避免查询深度翻页"></a>8. 避免查询深度翻页</h2><p>Elasticsearch 默认只允许查看排序前 10000 条的结果，当翻页查看排序靠后的记录时，响应耗时一般较长。使用 search_after 方式查询会更轻量级，如果每次只需要返回 10 条结果，则每个 shard 只需要返回 search_after 之后的 10 个结果即可，返回的总数据量只是和 shard 个数以及本次需要的个数有关，和历史已读取的个数无关。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"># search_after查询语法示例</span><br><span class="line">curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; </span><br><span class="line">-d&apos;&#123;</span><br><span class="line">    &quot;size&quot;: 10,</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot;: &#123;</span><br><span class="line">            &quot;message&quot;: &quot;Elasticsearch&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;sort&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;_score&quot;: &#123;</span><br><span class="line">                &quot;order&quot;: &quot;desc&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;_id&quot;: &#123;</span><br><span class="line">                &quot;order&quot;: &quot;asc&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;search_after&quot;: [</span><br><span class="line">        0.84290016,     //上一次response中某个doc的score</span><br><span class="line">        &quot;1024&quot;          //上一次response中某个doc的id</span><br><span class="line">    ]</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure><p></p><h2 id="9-避免前缀模糊匹配"><a href="#9-避免前缀模糊匹配" class="headerlink" title="9. 避免前缀模糊匹配"></a>9. 避免前缀模糊匹配</h2><p>Elasticsearch 默认支持通过 <em>? 正则表达式来做模糊匹配，如果在一个数据量较大规模的索引上执行模糊匹配，尤其是前缀模糊匹配，通常耗时会比较长，甚至可能导致内存溢出。尽量避免在高并发查询请求的生产环境执行这类操作。<br>某客户需要对车牌号进行模糊查询，通过查询请求 “车牌号:</em>A8848*” 查询时，往往导致整个集群负载较高。通过对数据预处理，增加冗余字段 “车牌号.keyword”，并事先将所有车牌号按照1元、2元、3元…7元分词后存储至该字段，字段存储内容示例：沪,A,8,4,沪A,A8,88,84,48,沪A8…沪A88488。通过查询”车牌号.keyword:A8848”即可解决原来的性能问题。</p><h2 id="10-避免索引稀疏"><a href="#10-避免索引稀疏" class="headerlink" title="10. 避免索引稀疏"></a>10. 避免索引稀疏</h2><p>Elasticsearch6.X 之前的版本默认允许在一个 index 下面创建多个 type，Elasticsearch6.X 版本只允许创建一个 type，Elasticsearch7.X 版本只允许 type 值为 “_doc”。在一个索引下面创建多个字段不一样的 type，或者将几百个字段不一样的索引合并到一个索引中，会导致索引稀疏问题。<br>建议每个索引下只创建一个 type，字段不一样的数据分别独立创建 index，不要合并成一个大索引。每个查询请求根据需要去读取相应的索引，避免查询大索引扫描全部记录，加快查询速度。</p><h2 id="11-扩容集群节点个数，升级节点规格"><a href="#11-扩容集群节点个数，升级节点规格" class="headerlink" title="11. 扩容集群节点个数，升级节点规格"></a>11. 扩容集群节点个数，升级节点规格</h2><p>通常服务器节点数越多，服务器硬件配置规格越高，Elasticsearch 集群的处理能力越强。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;Elasticsearch部署建议&quot;&gt;&lt;a href=&quot;#Elasticsearch部署建议&quot; class=&quot;headerlink&quot; title=&quot;Elasticsearch部署建议&quot;&gt;&lt;/a&gt;Elasticsearch部署建议&lt;/h1&gt;&lt;h2 id=&quot;1-选择合理的硬件配置：尽可能使用-SSD&quot;&gt;&lt;a href=&quot;#1-选择合理的硬件配置：尽可能使用-SSD&quot; class=&quot;headerlink&quot; title=&quot;1. 选择合理的硬件配置：尽可能使用 SSD&quot;&gt;&lt;/a&gt;1. 选择合理的硬件配置：尽可能使用 SSD&lt;/h2&gt;&lt;p&gt;Elasticsearch 最大的瓶颈往往是磁盘读写性能，尤其是随机读取性能。使用SSD（PCI-E接口SSD卡/SATA接口SSD盘）通常比机械硬盘（SATA盘/SAS盘）查询速度快5~10倍，写入性能提升不明显。&lt;br&gt;对于文档检索类查询性能要求较高的场景，建议考虑 SSD 作为存储，同时按照 1:10 的比例配置内存和硬盘。对于日志分析类查询并发要求较低的场景，可以考虑采用机械硬盘作为存储，同时按照 1:50 的比例配置内存和硬盘。单节点存储数据建议在2TB以内，不要超过5TB，避免查询速度慢、系统不稳定。&lt;/p&gt;&lt;h2 id=&quot;2-给JVM配置机器一半的内存，但是不建议超过32G&quot;&gt;&lt;a href=&quot;#2-给JVM配置机器一半的内存，但是不建议超过32G&quot; class=&quot;headerlink&quot; title=&quot;2. 给JVM配置机器一半的内存，但是不建议超过32G&quot;&gt;&lt;/a&gt;2. 给JVM配置机器一半的内存，但是不建议超过32G&lt;/h2&gt;&lt;p&gt;修改 conf/jvm.options 配置，-Xms 和 -Xmx 设置为相同的值，推荐设置为机器内存的一半左右，剩余一半留给操作系统缓存使用。JVM 内存建议不要低于 2G，否则有可能因为内存不足导致 ES 无法正常启动或内存溢出，JVM 建议不要超过 32G，否则 JVM 会禁用内存对象指针压缩技术，造成内存浪费。机器内存大于 64G 内存时，推荐配置 -Xms30g -Xmx30g。JVM 堆内存较大时，内存垃圾回收暂停时间比较长，建议配置 ZGC 或 G1 垃圾回收算法。&lt;/p&gt;&lt;h2 id=&quot;3-规模较大的集群配置专有主节点，避免脑裂问题&quot;&gt;&lt;a href=&quot;#3-规模较大的集群配置专有主节点，避免脑裂问题&quot; class=&quot;headerlink&quot; title=&quot;3. 规模较大的集群配置专有主节点，避免脑裂问题&quot;&gt;&lt;/a&gt;3. 规模较大的集群配置专有主节点，避免脑裂问题&lt;/h2&gt;&lt;p&gt;Elasticsearch 主节点负责集群元信息管理、index 的增删操作、节点的加入剔除，定期将最新的集群状态广播至各个节点。在集群规模较大时，建议配置专有主节点只负责集群管理，不存储数据，不承担数据读写压力。&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 专有主节点配置(conf/elasticsearch.yml)：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.master:true&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.data: false&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.ingest:false&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 数据节点配置(conf/elasticsearch.yml)：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.master:false&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.data:true&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;node.ingest:true&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Elasticsearch 默认每个节点既是候选主节点，又是数据节点。最小主节点数量参数 minimum_master_nodes 推荐配置为候选主节点数量一半以上，该配置告诉 Elasticsearch 当没有足够的 master 候选节点的时候，不进行 master 节点选举，等 master 节点足够了才进行选举。&lt;br&gt;例如对于 3 节点集群，最小主节点数量从默认值 1 改为 2。&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 最小主节点数量配置(conf/elasticsearch.yml)：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;discovery.zen.minimum_master_nodes: 2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/categories/elk/Elasticsearch/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Logstash集成GaussDB(高斯DB)数据到Elasticsearch</title>
    <link href="https://yongnights.github.io/2020/04/03/Logstash%E9%9B%86%E6%88%90GaussDB(%E9%AB%98%E6%96%AFDB)%E6%95%B0%E6%8D%AE%E5%88%B0Elasticsearch/"/>
    <id>https://yongnights.github.io/2020/04/03/Logstash集成GaussDB(高斯DB)数据到Elasticsearch/</id>
    <published>2020-04-03T01:17:06.856Z</published>
    <updated>2020-04-03T01:30:57.339Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><h1 id="GaussDB-简介"><a href="#GaussDB-简介" class="headerlink" title="GaussDB 简介"></a>GaussDB 简介</h1><p>GaussDB 数据库分为 GaussDB T 和 GaussDB A，分别面向 OLTP 和 OLAP 的业务用户。<br>GaussDB T 数据库是华为公司全自研的分布式数据库，支持x86和华为鲲鹏硬件架构。基于创新性数据库内核，提供高并发事务实时处理能力、两地三中心金融级高可用能力和分布式高扩展能力。<br>GaussDB A 是一款具备分析及混合负载能力的分布式数据库，支持x86和华为鲲鹏硬件架构，支持行存储与列存储，提供PB级数据分析能力、多模分析能力和实时处理能力，用于数据仓库、数据集市、实时分析、实时决策和混合负载等场景，广泛应用于金融、政府、电信等行业核心系统。</p><h1 id="Logstash-的-jdbc-input-plugin"><a href="#Logstash-的-jdbc-input-plugin" class="headerlink" title="Logstash 的 jdbc input plugin"></a>Logstash 的 jdbc input plugin</h1><p>参考 Logstash的 Jdbc input plugin 的官方文档，该插件可以通过JDBC接口将任何数据库中的数据导入 Logstash。周期性加载或一次加载，每一行是一个 event，列转成 filed。我们先解读下文档里提到的重要配置项。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">jdbc_driver_library：JDBC驱动包路径。</span><br><span class="line">jdbc_driver_class：JDBC驱动程序类。</span><br><span class="line">jdbc_connection_string：JDBC连接串。</span><br><span class="line">jdbc_user：数据库用户名。</span><br><span class="line">jdbc_password：数据库用户口令。</span><br><span class="line">statement_filepath：SQL语句所在文件路径。</span><br><span class="line">scheduler：调度计划。</span><br></pre></td></tr></table></figure><p></p><a id="more"></a><p>以上参数已经支持了周期性加载或一次性加载。如果想按字段的自增列或时间戳来集成数据，还需要以下参数：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sql_last_value：这个参数内置在sql语句里。作为条件的变量值。</span><br><span class="line">last_run_metadata_path：sql_last_value 上次运行值所在的文件路径。</span><br><span class="line">use_column_value：设置为时true时，将定义的 tracking_column 值用作 :sql_last_value。默认false。</span><br><span class="line">tracking_column：值设置为将被跟踪的列。</span><br><span class="line">tracking_column_type：跟踪列的类型。目前仅支持数字和时间戳。</span><br><span class="line">record_last_run：上次运行 sql_last_value 值是否保存到 last_run_metadata_path。默认true。</span><br><span class="line">clean_run：是否应保留先前的运行状态。默认false。</span><br></pre></td></tr></table></figure><p></p><p>另外如果想使用预编译语句，语句里用？作为占位符，再增加以下参数：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">use_prepared_statements：设置为 true 时，启用预编译语句。</span><br><span class="line">prepared_statement_name：预编译语句名称。</span><br><span class="line">prepared_statement_bind_values：数组类型，存放绑定值。:sql_last_value 可以作为预定义参数。</span><br></pre></td></tr></table></figure><p></p><p>参考：<a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-inputs-jdbc.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/7.5/plugins-inputs-jdbc.html</a></p><h1 id="对接-GaussDB-T"><a href="#对接-GaussDB-T" class="headerlink" title="对接 GaussDB T"></a>对接 GaussDB T</h1><p>按每分钟一次频率的周期性来加载 GaussDB T 的会话信息到 Elasticsearch 中，input 区域的配置如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    jdbc &#123;</span><br><span class="line">      jdbc_connection_string =&gt; &quot;jdbc:zenith:@vip:40000&quot;</span><br><span class="line">      jdbc_user =&gt; &quot;omm&quot;</span><br><span class="line">      jdbc_password =&gt; &quot;omm_password&quot;</span><br><span class="line">      jdbc_driver_library =&gt; &quot;/opt/gs/com.huawei.gauss.jdbc.ZenithDriver-GaussDB_100_1.0.1.SPC2.B003.jar&quot;</span><br><span class="line">      jdbc_driver_class =&gt; &quot;com.huawei.gauss.jdbc.ZenithDriver&quot;</span><br><span class="line">      statement_filepath =&gt; &quot;/opt/statement_filepath/gs_100_session.sql&quot;</span><br><span class="line">      schedule =&gt; &quot;*/1 * * * *&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>statement_filepath 路径文件里配置的sql如下：<br></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> dv_sessions</span><br></pre></td></tr></table></figure><p></p><p>启动 logstash，可以看到logstash 日志中显示有<code>select * from dv_sessions</code>的信息</p><h1 id="对接-GaussDB-A"><a href="#对接-GaussDB-A" class="headerlink" title="对接 GaussDB A"></a>对接 GaussDB A</h1><p>按字段的时间戳来增量加载数据，注意 GaussDB A 的驱动和 GaussDB T 是不同的。input 区域的配置如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    jdbc &#123;</span><br><span class="line">      jdbc_connection_string =&gt; &quot;jdbc:postgresql://vip:25308/postgres&quot;</span><br><span class="line">      jdbc_user =&gt; &quot;monitor&quot;</span><br><span class="line">      jdbc_password =&gt; &quot;monitor_password&quot;</span><br><span class="line">      jdbc_driver_library =&gt; &quot;/opt/gsdriver/gsjdbc4.jar&quot;</span><br><span class="line">      jdbc_driver_class =&gt; &quot;org.postgresql.Driver&quot;</span><br><span class="line">      statement_filepath =&gt; &quot;/opt/statement_filepath/gauss_active_session.sql&quot;</span><br><span class="line">      schedule =&gt; &quot;*/1 * * * *&quot;</span><br><span class="line">      record_last_run =&gt; &quot;true&quot;</span><br><span class="line">      use_column_value =&gt; &quot;true&quot;</span><br><span class="line">      tracking_column =&gt; &quot;sample_time&quot;</span><br><span class="line">      tracking_column_type =&gt; &quot;timestamp&quot;</span><br><span class="line">      clean_run =&gt; &quot;false&quot;</span><br><span class="line">      last_run_metadata_path =&gt; &quot;/opt/last_run_metadata_path/gauss_last_sample_time&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>statement_filepath 路径文件里配置的sql如下，注意里面的预定义变量 :sql_last_value。<br></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> clustername,coorname,sample_time,datid,datname,pid,usesysid,usename,application_name,abbrev(client_addr) <span class="keyword">AS</span> client_addr,client_hostname,client_port,backend_start,xact_start,query_start,state_change,waiting,<span class="keyword">enqueue</span>,state,resource_pool,query_id,<span class="keyword">query</span> <span class="keyword">from</span> monitor.ash_pg_stat_activity_r <span class="keyword">where</span> sample_time &gt; :sql_last_value</span><br></pre></td></tr></table></figure><p></p><p>last_run_metadata_path 路径下的文件内容：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--- 2020-02-05 12:10:00.000000000 +08:00</span><br></pre></td></tr></table></figure><p></p><p>启动 logstash，可以看到 logstash 日志，注意 :sql_last_value的地方</p><h1 id="数据-output-到-Elasticsearch"><a href="#数据-output-到-Elasticsearch" class="headerlink" title="数据 output 到 Elasticsearch"></a>数据 output 到 Elasticsearch</h1><p>logstash 的 output 区域的配置如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">output &#123;       </span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;https://vip:9200&quot;] </span><br><span class="line">        index =&gt; &quot;gauss_active_session-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        document_type =&gt; &quot;gauss_active_session&quot;</span><br><span class="line">        user =&gt; &quot;elastic&quot;</span><br><span class="line">        password =&gt; &quot;elastic_password&quot;</span><br><span class="line">        ssl =&gt; true</span><br><span class="line">        cacert =&gt; &quot;../es_client-ca.cer&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>登入 kibana 查看，按每分钟增量加载的会话表数据已经集成到了 elasticsearch，后续就可以开始做数据分析和可视化了。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;GaussDB-简介&quot;&gt;&lt;a href=&quot;#GaussDB-简介&quot; class=&quot;headerlink&quot; title=&quot;GaussDB 简介&quot;&gt;&lt;/a&gt;GaussDB 简介&lt;/h1&gt;&lt;p&gt;GaussDB 数据库分为 GaussDB T 和 GaussDB A，分别面向 OLTP 和 OLAP 的业务用户。&lt;br&gt;GaussDB T 数据库是华为公司全自研的分布式数据库，支持x86和华为鲲鹏硬件架构。基于创新性数据库内核，提供高并发事务实时处理能力、两地三中心金融级高可用能力和分布式高扩展能力。&lt;br&gt;GaussDB A 是一款具备分析及混合负载能力的分布式数据库，支持x86和华为鲲鹏硬件架构，支持行存储与列存储，提供PB级数据分析能力、多模分析能力和实时处理能力，用于数据仓库、数据集市、实时分析、实时决策和混合负载等场景，广泛应用于金融、政府、电信等行业核心系统。&lt;/p&gt;&lt;h1 id=&quot;Logstash-的-jdbc-input-plugin&quot;&gt;&lt;a href=&quot;#Logstash-的-jdbc-input-plugin&quot; class=&quot;headerlink&quot; title=&quot;Logstash 的 jdbc input plugin&quot;&gt;&lt;/a&gt;Logstash 的 jdbc input plugin&lt;/h1&gt;&lt;p&gt;参考 Logstash的 Jdbc input plugin 的官方文档，该插件可以通过JDBC接口将任何数据库中的数据导入 Logstash。周期性加载或一次加载，每一行是一个 event，列转成 filed。我们先解读下文档里提到的重要配置项。&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;jdbc_driver_library：JDBC驱动包路径。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdbc_driver_class：JDBC驱动程序类。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdbc_connection_string：JDBC连接串。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdbc_user：数据库用户名。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;jdbc_password：数据库用户口令。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;statement_filepath：SQL语句所在文件路径。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;scheduler：调度计划。&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="elk" scheme="https://yongnights.github.io/categories/elk/"/>
    
      <category term="Logstash" scheme="https://yongnights.github.io/categories/elk/Logstash/"/>
    
      <category term="GaussDB" scheme="https://yongnights.github.io/categories/elk/Logstash/GaussDB/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/categories/elk/Logstash/GaussDB/Elasticsearch/"/>
    
    
      <category term="elk" scheme="https://yongnights.github.io/tags/elk/"/>
    
      <category term="Elasticsearch" scheme="https://yongnights.github.io/tags/Elasticsearch/"/>
    
      <category term="Logstash" scheme="https://yongnights.github.io/tags/Logstash/"/>
    
      <category term="GaussDB" scheme="https://yongnights.github.io/tags/GaussDB/"/>
    
  </entry>
  
  <entry>
    <title>详细说明-CentOS7部署FastDFS+nginx模块</title>
    <link href="https://yongnights.github.io/2020/04/02/%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E-CentOS7%E9%83%A8%E7%BD%B2FastDFS+nginx%E6%A8%A1%E5%9D%97/"/>
    <id>https://yongnights.github.io/2020/04/02/详细说明-CentOS7部署FastDFS+nginx模块/</id>
    <published>2020-04-02T03:57:08.447Z</published>
    <updated>2020-04-02T06:47:32.648Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --><h1 id="软件下载"><a href="#软件下载" class="headerlink" title="软件下载"></a>软件下载</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 已经事先把所需软件下载好并上传到/usr/local/src目录了</span><br><span class="line">https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs-client-java/archive/V1.28.tar.gz</span><br><span class="line">https://openresty.org/download/openresty-1.15.8.3.tar.gz</span><br></pre></td></tr></table></figure><h1 id="基础环境设置"><a href="#基础环境设置" class="headerlink" title="基础环境设置"></a>基础环境设置</h1><h2 id="安装依赖组件"><a href="#安装依赖组件" class="headerlink" title="安装依赖组件"></a>安装依赖组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install  gcc gcc-c++ libevent</span><br><span class="line">yum -y groupinstall &apos;Development Tools&apos;</span><br></pre></td></tr></table></figure><p><code><a id="more"></a></code></p><h2 id="安装libfastcommon"><a href="#安装libfastcommon" class="headerlink" title="安装libfastcommon"></a>安装libfastcommon</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf libfastcommon-1.0.43.tar.gz</span><br><span class="line">cd libfastcommon-1.0.43</span><br><span class="line">./make.sh</span><br><span class="line">./make.sh install</span><br><span class="line"></span><br><span class="line"># 检查文件是否存在，确保在/usr/lib路径下有libfastcommon.so和libfdfsclient.so</span><br><span class="line">ll /usr/lib | grep &quot;libf&quot;</span><br><span class="line">lrwxrwxrwx   1 root root     27 Apr  2 10:07 libfastcommon.so -&gt; /usr/lib64/libfastcommon.so</span><br><span class="line">-rwxr-xr-x   1 root root 356664 Apr  2 10:15 libfdfsclient.so</span><br></pre></td></tr></table></figure><h2 id="安装fastdfs"><a href="#安装fastdfs" class="headerlink" title="安装fastdfs"></a>安装fastdfs</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf fastdfs-6.06.tar.gz</span><br><span class="line">cd fastdfs-6.06</span><br><span class="line">./make.sh</span><br><span class="line">./make.sh install</span><br><span class="line"></span><br><span class="line"># FastDFS的配置文件默认安装到/etc/fdfs目录下</span><br><span class="line"></span><br><span class="line"># 安装成功后将fastdfs-6.06/conf下的俩文件拷贝到/etc/fdfs/下</span><br><span class="line">cd conf</span><br><span class="line">cp http.conf mime.types /etc/fdfs/</span><br><span class="line">cd /etc/fdfs/</span><br><span class="line">[root@bogon fdfs]# ll</span><br><span class="line">total 68</span><br><span class="line">-rw-r--r-- 1 root root  1909 Apr  2 10:15 client.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root   965 Apr  2 10:16 http.conf</span><br><span class="line">-rw-r--r-- 1 root root 31172 Apr  2 10:16 mime.types</span><br><span class="line">-rw-r--r-- 1 root root 10246 Apr  2 10:15 storage.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root   620 Apr  2 10:15 storage_ids.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root  9138 Apr  2 10:15 tracker.conf.sample</span><br></pre></td></tr></table></figure><h3 id="fdfs-trackerd配置并启动"><a href="#fdfs-trackerd配置并启动" class="headerlink" title="fdfs_trackerd配置并启动"></a>fdfs_trackerd配置并启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 创建tracker工作目录,storage存储目录(选择大磁盘空间)等</span><br><span class="line">mkdir -p /opt/&#123;fdfs_tracker,fdfs_storage,fdfs_storage_data&#125;</span><br><span class="line"></span><br><span class="line">cd /etc/fdfs/</span><br><span class="line">cp tracker.conf.sample tracker.conf</span><br><span class="line">vim tracker.conf</span><br><span class="line">    disabled = false # 配置tracker.conf这个配置文件是否生效，因为在启动fastdfs服务端进程时需要指定配置文件，所以需要使次配置文件生效。false是生效，true是屏蔽。</span><br><span class="line">    bind_addr = # 程序的监听地址，如果不设定则监听所有地址，可以设置本地ip地址</span><br><span class="line">    port = 22122 #tracker监听的端口</span><br><span class="line">    base_path = /opt/fdfs_tracker # tracker保存data和logs的路径</span><br><span class="line">    http.server_port=8080 # http服务端口，保持默认</span><br><span class="line"></span><br><span class="line"># 启动fdfs_trackerd</span><br><span class="line">/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</span><br><span class="line"></span><br><span class="line"># 查看/opt/fdfs_tracker目录，发现目录下多了data和logs两个目录</span><br><span class="line"></span><br><span class="line"># 查看端口号，验证启动情况</span><br><span class="line">[root@bogon fdfs]# ps -ef | grep fdfs</span><br><span class="line">root       2119      1  0 10:22 ?        00:00:00 /usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</span><br><span class="line">[root@bogon fdfs]# ss -tulnp | grep 22122</span><br><span class="line">tcp    LISTEN     0      128       *:22122      *:*    users:((&quot;fdfs_trackerd&quot;,pid=2119,fd=5))</span><br><span class="line"></span><br><span class="line"># 命令行选项</span><br><span class="line">Usage: /usr/bin/fdfs_trackerd &lt;config_file&gt; [start|stop|restart]</span><br><span class="line"></span><br><span class="line"># 设置开机自启动</span><br><span class="line">echo &quot;/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart&quot; | tee -a /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h3 id="fdfs-storage配置并启动"><a href="#fdfs-storage配置并启动" class="headerlink" title="fdfs_storage配置并启动"></a>fdfs_storage配置并启动</h3><p>与tracker不同的是，storage还需要一个目录用来存储数据，所以在上面步骤中另外多建了两个目录fdfs_storage_data,fdfs_storage<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp storage.conf.sample storage.conf</span><br><span class="line">vim storage.conf</span><br><span class="line">    disabled=false # 启用这个配置文件</span><br><span class="line">    group_name=group1 #组名，根据实际情况修改，文件链接中会用到</span><br><span class="line">    port=23000 #设置storage的端口号，默认是23000，同一个组的storage端口号必须一致</span><br><span class="line">    base_path = /opt/fdfs_storage # #设置storage数据文件和日志目录，注意,这个目录最好有大于50G的磁盘空间</span><br><span class="line">    store_path_count=1 #存储路径个数，需要和store_path个数匹配 </span><br><span class="line">    store_path0 = /opt/fdfs_storage_data # 实际保存文件的路径，注意,这个目录最好有大于50G的磁盘空间</span><br><span class="line">    tracker_server = 192.168.75.5:22122 # tracker监听地址和端口号，要与tracker.conf文件中设置的保持一致</span><br><span class="line">    http.server_port=8888 #设置 http 端口号</span><br><span class="line">    </span><br><span class="line"># 启动fdfs_storaged</span><br><span class="line">/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</span><br><span class="line"></span><br><span class="line"># 查看端口号，验证启动情况</span><br><span class="line">[root@bogon fdfs]# ps -ef | grep &quot;fdfs_storaged&quot;</span><br><span class="line">root       2194      1  7 10:36 ?        00:00:01 /usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</span><br><span class="line">[root@bogon fdfs]# ss -tulnp | grep &quot;fdfs&quot;</span><br><span class="line">tcp    LISTEN     0      128       *:23000      *:*     users:((&quot;fdfs_storaged&quot;,pid=2194,fd=5))</span><br><span class="line">tcp    LISTEN     0      128       *:22122      *:*     users:((&quot;fdfs_trackerd&quot;,pid=2119,fd=5))</span><br><span class="line"></span><br><span class="line"># 命令行选项</span><br><span class="line">Usage: /usr/bin/fdfs_trackerd &lt;config_file&gt; [start|stop|restart]</span><br><span class="line"></span><br><span class="line"># 设置开机自启动</span><br><span class="line">echo &quot;/usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart&quot; | tee -a /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><p></p><h3 id="校验整合"><a href="#校验整合" class="headerlink" title="校验整合"></a>校验整合</h3><p>要确定一下，storage是否注册到了tracker中去<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/fdfs_monitor /etc/fdfs/storage.conf</span><br></pre></td></tr></table></figure><p></p><p>成功后可以看到：ip_addr = 192.168.75.5 ACTIVE</p><h3 id="使用FastDFS自带工具测试"><a href="#使用FastDFS自带工具测试" class="headerlink" title="使用FastDFS自带工具测试"></a>使用FastDFS自带工具测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp client.conf.sample client.conf</span><br><span class="line">vim client.conf</span><br><span class="line">    base_path = /opt/fdfs_tracker # tracker服务器文件路径</span><br><span class="line">    tracker_server = 192.168.75.5:22122 #tracker服务器IP地址和端口号</span><br><span class="line">    http.tracker_server_port = 8080 # tracker服务器的http端口号,必须和tracker的设置对应起来</span><br></pre></td></tr></table></figure><p>上传一张图片1.jpg到Centos服务器上的 /tmp 目录下，进行测试，命令如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/fdfs_test /etc/fdfs/client.conf upload /tmp/1.jpg</span><br><span class="line">This is FastDFS client test program v6.06</span><br><span class="line"></span><br><span class="line">Copyright (C) 2008, Happy Fish / YuQing</span><br><span class="line"></span><br><span class="line">FastDFS may be copied only under the terms of the GNU General</span><br><span class="line">Public License V3, which may be found in the FastDFS source kit.</span><br><span class="line">Please visit the FastDFS Home Page http://www.fastken.com/ </span><br><span class="line">for more detail.</span><br><span class="line"></span><br><span class="line">[2020-04-02 10:47:57] DEBUG - base_path=/opt/fdfs_tracker, connect_timeout=5, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0</span><br><span class="line"></span><br><span class="line">tracker_query_storage_store_list_without_group: </span><br><span class="line">        server 1. group_name=, ip_addr=192.168.75.5, port=23000</span><br><span class="line"></span><br><span class="line">group_name=group1, ip_addr=192.168.75.5, port=23000</span><br><span class="line">storage_upload_by_filename</span><br><span class="line">group_name=group1, remote_filename=M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">source ip address: 192.168.75.5</span><br><span class="line">file timestamp=2020-04-02 10:47:58</span><br><span class="line">file size=2402082</span><br><span class="line">file crc32=779422649</span><br><span class="line">example file url: http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">storage_upload_slave_by_filename</span><br><span class="line">group_name=group1, remote_filename=M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br><span class="line">source ip address: 192.168.75.5</span><br><span class="line">file timestamp=2020-04-02 10:47:58</span><br><span class="line">file size=2402082</span><br><span class="line">file crc32=779422649</span><br><span class="line">example file url: http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br></pre></td></tr></table></figure><p></p><p>以上图中的文件地址：<a href="http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg对应storage服务器上的/opt/fdfs_storage_data/data/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg文件" target="_blank" rel="noopener">http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg对应storage服务器上的/opt/fdfs_storage_data/data/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg文件</a>;</p><blockquote><p>组名：group1<br>磁盘：M00<br>目录：00/00<br>文件名称：wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg<br>注意图片路径中的8080端口,这个是tracker的端口</p></blockquote><p>上传的图片会被上传到我们创建的fdfs_storage_data目录下，会有四个图片文件:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon 00]# pwd</span><br><span class="line">/opt/fdfs_storage_data/data/00/00</span><br><span class="line">[root@bogon 00]# ll</span><br><span class="line">total 4704</span><br><span class="line">-rw-r--r-- 1 root root 2402082 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br><span class="line">-rw-r--r-- 1 root root      49 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg-m</span><br><span class="line">-rw-r--r-- 1 root root 2402082 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">-rw-r--r-- 1 root root      49 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg-m</span><br></pre></td></tr></table></figure><p></p><p>data下有256个1级目录，每级目录下又有256个2级子目录，总共65536个文件，新写的文件会以hash的方式被路由到其中某个子目录下，然后将文件数据直接作为一个本地文件存储到该目录中。</p><h2 id="FastDFS和nginx结合使用"><a href="#FastDFS和nginx结合使用" class="headerlink" title="FastDFS和nginx结合使用"></a>FastDFS和nginx结合使用</h2><p>FastDFS通过Tracker服务器,将文件放在Storage服务器存储,但是同组之间的服务器需要复制文件,有延迟的问题.<br>假设Tracker服务器将文件上传到了172.20.132.57,文件ID已经返回客户端,这时,后台会将这个文件复制到172.20.132.57,如果复制没有完成,客户端就用这个ID在172.20.132.57取文件,肯定会出现错误。<br>这个fastdfs-nginx-module可以重定向连接到源服务器取文件,避免客户端由于复制延迟的问题,出现错误。<br>正是这样，FastDFS需要结合nginx，所以取消原来对HTTP的直接支持。</p><h3 id="在tracker上安装-nginx"><a href="#在tracker上安装-nginx" class="headerlink" title="在tracker上安装 nginx"></a>在tracker上安装 nginx</h3><p>在每个tracker上安装nginx的主要目的是做负载均衡及实现高可用。如果只有一台tracker服务器可以不配置nginx.<br>一个tracker对应多个storage，通过nginx对storage负载均衡;</p><h3 id="在storage上安装nginx-openresty"><a href="#在storage上安装nginx-openresty" class="headerlink" title="在storage上安装nginx(openresty)"></a>在storage上安装nginx(openresty)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src/</span><br><span class="line">tar -zxvf fastdfs-nginx-module-1.22.tar.gz</span><br><span class="line">cd fastdfs-nginx-module-1.22/src</span><br><span class="line">cp mod_fastdfs.conf /etc/fdfs/</span><br><span class="line">vim /etc/fdfs/mod_fastdfs.conf</span><br><span class="line">    base_path=/opt/fdfs_storage # 与storage.conf配置中的保持一致</span><br><span class="line">    tracker_server=192.168.75.5:22122 #tracker服务器的IP地址以及端口号</span><br><span class="line">    url_have_group_name = true # url中包含group名称</span><br><span class="line">    store_path0=/opt/fdfs_storage_data #与storage.conf中的路径保持一致</span><br><span class="line">    group_count = 1 #设置组的个数</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">yum -y install pcre pcre-devel openssl openssl-devel zlib zlib-devel </span><br><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf openresty-1.15.8.3.tar.gz</span><br><span class="line">cd openresty-1.15.8.3</span><br><span class="line">./configure \</span><br><span class="line">    --with-luajit \</span><br><span class="line">    --with-http_stub_status_module \</span><br><span class="line">    --with-http_ssl_module \</span><br><span class="line">    --with-http_realip_module \</span><br><span class="line">    --with-http_gzip_static_module \</span><br><span class="line">    --add-module=/usr/local/src/fastdfs-nginx-module-1.22/src</span><br><span class="line">gmake</span><br><span class="line">gmake install</span><br><span class="line"></span><br><span class="line"># 修改配置文件</span><br><span class="line">vim /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">    error_log  logs/error.log;</span><br><span class="line">    pid      logs/nginx.pid;</span><br><span class="line">    server&#123;</span><br><span class="line">        server_name  192.168.75.5; </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line"></span><br><span class="line"># 浏览器访问，出现openresty欢迎页面</span><br><span class="line"></span><br><span class="line"># 设置nginx开机启动</span><br><span class="line">echo &quot;/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf&quot; | tee -a /etc/rc.d/rc.local</span><br><span class="line"></span><br><span class="line"># 再次修改配置文件，加载fastdfs模块</span><br><span class="line">vim /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">    server&#123;</span><br><span class="line">        location /group1/M00/ &#123;</span><br><span class="line">            root /opt/fdfs_storage/data;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"># 重载nginx</span><br><span class="line">/usr/local/openresty/nginx/sbin/nginx -s reload</span><br><span class="line"></span><br><span class="line"># 参考上面测试的那一步图片url地址：http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">使用nginxf访问的话，实际地址是：http://192.168.75.5/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">需要把tracker使用的8080端口去掉，否则无法访问</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 进一步完善nginx配置文件</span><br><span class="line">    # 这个server设置的是storage nginx</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       9991;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location ~/group1/M00 &#123;</span><br><span class="line">            root /opt/fastdfs_storage/data;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # 若访问不到图片需要配置这个软连接</span><br><span class="line">    # ln -s /opt/fastdfs_storage_data/data/ /opt/fastdfs_storage_data/data/M00</span><br><span class="line">    </span><br><span class="line">    # 这个server设置的是tracker nginx</span><br><span class="line">    upstream fdfs_group1 &#123;</span><br><span class="line">        server 127.0.0.1:9991;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        </span><br><span class="line">        location /group1/M00 &#123;</span><br><span class="line">            proxy_pass http://fdfs_group1;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h1 id="搭建集群"><a href="#搭建集群" class="headerlink" title="搭建集群"></a>搭建集群</h1><h2 id="集群规划-单tracker-双storage"><a href="#集群规划-单tracker-双storage" class="headerlink" title="集群规划(单tracker,双storage)"></a>集群规划(单tracker,双storage)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">虚拟机     IP                 说明</span><br><span class="line">tracker 192.168.75.5 tracker 服务器</span><br><span class="line">storage01 192.168.75.6 storage01服务器【group1】</span><br><span class="line">storage02 192.168.75.7 storage02服务器【group2】</span><br></pre></td></tr></table></figure><h2 id="软件清单"><a href="#软件清单" class="headerlink" title="软件清单"></a>软件清单</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fastdfs-6.06.tar.gz</span><br><span class="line">fastdfs-client-java-1.28.tar.gz</span><br><span class="line">fastdfs-nginx-module-1.22.tar.gz</span><br><span class="line">libfastcommon-1.0.43.tar.gz</span><br><span class="line">openresty-1.15.8.3.tar.gz</span><br></pre></td></tr></table></figure><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><h3 id="1-tracker服务器"><a href="#1-tracker服务器" class="headerlink" title="1.tracker服务器"></a>1.tracker服务器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 1. 安装libfastcommon 模块</span><br><span class="line"># 2. 编译安装 FastDFS</span><br><span class="line"># 3. 修改配置文件tarcker.conf和client.conf(测试上传)</span><br><span class="line"></span><br><span class="line"># vim /etc/fdfs/tracker.conf</span><br><span class="line">    store_lookup=0  #采用轮询策略进行存储，0：轮询 1：始终定向到某个group 2：选择存储空间最大的进行存储</span><br><span class="line"></span><br><span class="line"># 4. 开机启动</span><br></pre></td></tr></table></figure><h3 id="2-storage服务器"><a href="#2-storage服务器" class="headerlink" title="2.storage服务器"></a>2.storage服务器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># 1. 安装libfastcommon 模块</span><br><span class="line"># 2. 编译安装 FastDFS</span><br><span class="line"># 3. 修改配置文件storage.conf</span><br><span class="line"></span><br><span class="line"># storage01 配置</span><br><span class="line"># vim /etc/fdfs/storage.conf</span><br><span class="line">group_name=group1</span><br><span class="line">base_path=/home/fastdfs_storage</span><br><span class="line">store_path0=/home/fastdfs_storage</span><br><span class="line">tracker_server=192.168.75.6:22122</span><br><span class="line">http.server_port=8888</span><br><span class="line"></span><br><span class="line"># storage02 配置</span><br><span class="line"># vim /etc/fdfs/storage.conf</span><br><span class="line">group_name=group2</span><br><span class="line">base_path=/home/fastdfs_storage</span><br><span class="line">store_path0=/home/fastdfs_storage</span><br><span class="line">tracker_server=192.168.75.7:22122</span><br><span class="line">http.server_port=8888</span><br><span class="line"></span><br><span class="line"># 4. 开机启动</span><br><span class="line"># 5. 安装nginx和fastdfs-nginx-module模块</span><br><span class="line"></span><br><span class="line"># storage01 配置：</span><br><span class="line"># vim /etc/fdfs/mod_fastdfs.conf</span><br><span class="line">connect_timeout=10</span><br><span class="line">base_path=/home/fastdfs_storage</span><br><span class="line">url_have_group_name=true</span><br><span class="line">store_path0=/home/fastdfs_storage</span><br><span class="line">tracker_server=192.168.75.6:22122</span><br><span class="line">group_name=group1</span><br><span class="line"></span><br><span class="line"># storage02 配置：</span><br><span class="line"># vim /etc/fdfs/mod_fastdfs.conf</span><br><span class="line">connect_timeout=10</span><br><span class="line">base_path=/home/fastdfs_storage</span><br><span class="line">url_have_group_name=true</span><br><span class="line">store_path0=/home/fastdfs_storage</span><br><span class="line">tracker_server=192.168.75.7:22122</span><br><span class="line">group_name=group2</span><br><span class="line"></span><br><span class="line"># 6. 复制 FastDFS 安装目录的部分配置文件到 /etc/fdfs 目录</span><br><span class="line">cp http.conf mime.types /etc/fdfs/</span><br><span class="line"></span><br><span class="line"># 7. 配置nginx</span><br><span class="line">server &#123;</span><br><span class="line">    listen 8888;  </span><br><span class="line">    server_name localhost; </span><br><span class="line">     </span><br><span class="line">    location ~/group([0-9])/M00 &#123;</span><br><span class="line">        ngx_fastdfs_module;  </span><br><span class="line">    &#125;</span><br><span class="line">    error_page 500 502 503 504 /50x.html;  </span><br><span class="line">    location = /50x.html &#123;  </span><br><span class="line">        root html;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-测试"><a href="#3-测试" class="headerlink" title="3.测试"></a>3.测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/fdfs/client.conf</span><br><span class="line">    base_path=/home/fastdfs_tracker</span><br><span class="line">    tracker_server=192.168.75.5:22122</span><br><span class="line"></span><br><span class="line">/usr/bin/fdfs_upload_file /etc/fdfs/client.conf test.jpg</span><br></pre></td></tr></table></figure><h3 id="4-tracker安装nginx"><a href="#4-tracker安装nginx" class="headerlink" title="4. tracker安装nginx"></a>4. tracker安装nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">http &#123;  </span><br><span class="line">    include mime.types;  </span><br><span class="line">    default_type application/octet-stream;  </span><br><span class="line">    sendfile on;  </span><br><span class="line">    keepalive_timeout 65;</span><br><span class="line">    </span><br><span class="line">    #group1</span><br><span class="line">    upstream fdfs_group1 &#123;</span><br><span class="line">       server 192.168.75.6:8888;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    #group2</span><br><span class="line">    upstream fdfs_group2 &#123;</span><br><span class="line">       server 192.168.75.7:8888;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;  </span><br><span class="line">        listen 8000;  </span><br><span class="line">        server_name localhost;</span><br><span class="line">        </span><br><span class="line">        location /group1/M00 &#123;</span><br><span class="line">           proxy_pass http://fdfs_group1;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location /group2/M00 &#123;</span><br><span class="line">           proxy_pass http://fdfs_group2;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        error_page 500 502 503 504 /50x.html;  </span><br><span class="line">        location = /50x.html &#123;  </span><br><span class="line">            root html;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Apr 07 2020 18:03:33 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;软件下载&quot;&gt;&lt;a href=&quot;#软件下载&quot; class=&quot;headerlink&quot; title=&quot;软件下载&quot;&gt;&lt;/a&gt;软件下载&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 已经事先把所需软件下载好并上传到/usr/local/src目录了&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs-client-java/archive/V1.28.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://openresty.org/download/openresty-1.15.8.3.tar.gz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h1 id=&quot;基础环境设置&quot;&gt;&lt;a href=&quot;#基础环境设置&quot; class=&quot;headerlink&quot; title=&quot;基础环境设置&quot;&gt;&lt;/a&gt;基础环境设置&lt;/h1&gt;&lt;h2 id=&quot;安装依赖组件&quot;&gt;&lt;a href=&quot;#安装依赖组件&quot; class=&quot;headerlink&quot; title=&quot;安装依赖组件&quot;&gt;&lt;/a&gt;安装依赖组件&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum -y install  gcc gcc-c++ libevent&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;yum -y groupinstall &amp;apos;Development Tools&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;
    
    </summary>
    
      <category term="nginx" scheme="https://yongnights.github.io/categories/nginx/"/>
    
      <category term="FastDFS" scheme="https://yongnights.github.io/categories/nginx/FastDFS/"/>
    
    
      <category term="nginx" scheme="https://yongnights.github.io/tags/nginx/"/>
    
      <category term="FastDFS" scheme="https://yongnights.github.io/tags/FastDFS/"/>
    
  </entry>
  
  <entry>
    <title>CentOS7部署FastDFS+nginx模块</title>
    <link href="https://yongnights.github.io/2020/04/02/CentOS7%E9%83%A8%E7%BD%B2FastDFS+nginx%E6%A8%A1%E5%9D%97/"/>
    <id>https://yongnights.github.io/2020/04/02/CentOS7部署FastDFS+nginx模块/</id>
    <published>2020-04-02T01:31:47.162Z</published>
    <updated>2020-04-08T10:04:48.822Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Apr 08 2020 18:05:48 GMT+0800 (GMT+08:00) --><h1 id="软件下载"><a href="#软件下载" class="headerlink" title="软件下载"></a>软件下载</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 已经事先把所需软件下载好并上传到/usr/local/src目录了</span><br><span class="line">https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz</span><br><span class="line">https://github.com/happyfish100/fastdfs-client-java/archive/V1.28.tar.gz</span><br><span class="line">https://openresty.org/download/openresty-1.15.8.3.tar.gz</span><br></pre></td></tr></table></figure><h1 id="基础环境设置"><a href="#基础环境设置" class="headerlink" title="基础环境设置"></a>基础环境设置</h1><h2 id="安装依赖组件"><a href="#安装依赖组件" class="headerlink" title="安装依赖组件"></a>安装依赖组件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum -y install  gcc gcc-c++ libevent</span><br><span class="line">yum -y groupinstall &apos;Development Tools&apos;</span><br></pre></td></tr></table></figure><p><code><a id="more"></a></code></p><h2 id="安装libfastcommon"><a href="#安装libfastcommon" class="headerlink" title="安装libfastcommon"></a>安装libfastcommon</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf libfastcommon-1.0.43.tar.gz</span><br><span class="line">cd libfastcommon-1.0.43</span><br><span class="line">./make.sh</span><br><span class="line">./make.sh install</span><br><span class="line"></span><br><span class="line"># 检查文件是否存在</span><br><span class="line">[root@bogon libfastcommon-1.0.43]# ll /usr/lib64 | grep &quot;libfastcommon.so&quot; </span><br><span class="line">-rwxr-xr-x   1 root root  1035264 Apr  2 10:07 libfastcommon.so</span><br><span class="line">[root@bogon libfastcommon-1.0.43]# ll /usr/lib | grep &quot;libfastcommon.so&quot;  </span><br><span class="line">lrwxrwxrwx   1 root root    27 Apr  2 10:07 libfastcommon.so -&gt; /usr/lib64/libfastcommon.so</span><br></pre></td></tr></table></figure><h2 id="安装fastdfs"><a href="#安装fastdfs" class="headerlink" title="安装fastdfs"></a>安装fastdfs</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf fastdfs-6.06.tar.gz</span><br><span class="line">cd fastdfs-6.06</span><br><span class="line">./make.sh</span><br><span class="line">./make.sh install</span><br><span class="line"></span><br><span class="line"># 安装成功后将解压目录下的conf下的俩文件拷贝到/etc/fdfs/下</span><br><span class="line">cd conf</span><br><span class="line">cp http.conf mime.types /etc/fdfs/</span><br><span class="line">cd /etc/fdfs/</span><br><span class="line">[root@bogon fdfs]# ll</span><br><span class="line">total 68</span><br><span class="line">-rw-r--r-- 1 root root  1909 Apr  2 10:15 client.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root   965 Apr  2 10:16 http.conf</span><br><span class="line">-rw-r--r-- 1 root root 31172 Apr  2 10:16 mime.types</span><br><span class="line">-rw-r--r-- 1 root root 10246 Apr  2 10:15 storage.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root   620 Apr  2 10:15 storage_ids.conf.sample</span><br><span class="line">-rw-r--r-- 1 root root  9138 Apr  2 10:15 tracker.conf.sample</span><br></pre></td></tr></table></figure><h3 id="fdfs-trackerd配置并启动"><a href="#fdfs-trackerd配置并启动" class="headerlink" title="fdfs_trackerd配置并启动"></a>fdfs_trackerd配置并启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp tracker.conf.sample tracker.conf</span><br><span class="line">mkdir -p /opt/&#123;fdfs_tracker,fdfs_storage,fdfs_storage_data&#125;</span><br><span class="line">vim tracker.conf</span><br><span class="line">    base_path = /opt/fdfs_tracker</span><br><span class="line"></span><br><span class="line"># 启动fdfs_trackerd</span><br><span class="line">/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</span><br><span class="line"># 查看端口号，验证启动情况</span><br><span class="line">[root@bogon fdfs]# ps -ef | grep fdfs</span><br><span class="line">root       2119      1  0 10:22 ?        00:00:00 /usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start</span><br><span class="line">[root@bogon fdfs]# ss -tulnp | grep 22122</span><br><span class="line">tcp    LISTEN     0      128       *:22122                 *:*                   users:((&quot;fdfs_trackerd&quot;,pid=2119,fd=5))</span><br><span class="line"></span><br><span class="line"># 命令行选项</span><br><span class="line">Usage: /usr/bin/fdfs_trackerd &lt;config_file&gt; [start|stop|restart]</span><br><span class="line"></span><br><span class="line"># 注意：在/opt/fdfs_data目录下生成两个目录,一个是数据,一个是日志.</span><br><span class="line"># 设置开机自启动</span><br><span class="line">echo &quot;/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf restart&quot; | tee -a /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h3 id="fdfs-storaged配置并启动"><a href="#fdfs-storaged配置并启动" class="headerlink" title="fdfs_storaged配置并启动"></a>fdfs_storaged配置并启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp storage.conf.sample storage.conf</span><br><span class="line">vim storage.conf</span><br><span class="line">    base_path = /opt/fdfs_storage # 注意,这个目录最好有大于50G的磁盘空间</span><br><span class="line">    store_path0 = /opt/fdfs_storage_data # 若配置这个参数，则该目录为实际保存文件的路径</span><br><span class="line">    tracker_server = 192.168.75.5:22122 # 注意：这个参数不能设置127.0.0.1，否则storage注册时会报错：ERROR - file: storage_func.c, line: 1361, conf file &quot;/etc/fdfs/storage.conf&quot;, tracker: &quot;127.0.0.1:22122&quot; is invalid, tracker server ip can&apos;t be 127.0.0.1</span><br><span class="line"># 启动fdfs_storaged</span><br><span class="line">/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</span><br><span class="line">[root@bogon fdfs]# ps -ef | grep &quot;fdfs_storaged&quot;</span><br><span class="line">root       2194      1  7 10:36 ?        00:00:01 /usr/bin/fdfs_storaged /etc/fdfs/storage.conf start</span><br><span class="line">[root@bogon fdfs]# ss -tulnp | grep &quot;fdfs&quot;</span><br><span class="line">tcp    LISTEN     0      128       *:23000                 *:*                   users:((&quot;fdfs_storaged&quot;,pid=2194,fd=5))</span><br><span class="line">tcp    LISTEN     0      128       *:22122                 *:*                   users:((&quot;fdfs_trackerd&quot;,pid=2119,fd=5))</span><br><span class="line"></span><br><span class="line"># 命令行选项</span><br><span class="line">Usage: /usr/bin/fdfs_trackerd &lt;config_file&gt; [start|stop|restart]</span><br><span class="line"># 设置开机自启动</span><br><span class="line">echo &quot;/usr/bin/fdfs_storaged /etc/fdfs/storage.conf restart&quot; | tee -a /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure><h3 id="校验整合"><a href="#校验整合" class="headerlink" title="校验整合"></a>校验整合</h3><p>要确定一下，storage是否注册到了tracker中去<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/fdfs_monitor /etc/fdfs/storage.conf</span><br></pre></td></tr></table></figure><p></p><p>成功后可以看到：ip_addr = 192.168.75.5 ACTIVE</p><h3 id="使用FastDFS自带工具测试"><a href="#使用FastDFS自带工具测试" class="headerlink" title="使用FastDFS自带工具测试"></a>使用FastDFS自带工具测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/fdfs/</span><br><span class="line">cp client.conf.sample client.conf</span><br><span class="line">vim client.conf</span><br><span class="line">    base_path = /opt/fdfs_tracker #tracker服务器文件路径</span><br><span class="line">    tracker_server = 192.168.75.5:22122 #tracker服务器IP地址和端口号</span><br><span class="line">    http.tracker_server_port = 8080 # tracker服务器的http端口号,必须和tracker的设置对应起来</span><br></pre></td></tr></table></figure><p>上传一张图片1.jpg到Centos服务器上的 /tmp 目录下，进行测试，命令如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/fdfs_test /etc/fdfs/client.conf upload /tmp/1.jpg</span><br><span class="line">This is FastDFS client test program v6.06</span><br><span class="line"></span><br><span class="line">Copyright (C) 2008, Happy Fish / YuQing</span><br><span class="line"></span><br><span class="line">FastDFS may be copied only under the terms of the GNU General</span><br><span class="line">Public License V3, which may be found in the FastDFS source kit.</span><br><span class="line">Please visit the FastDFS Home Page http://www.fastken.com/ </span><br><span class="line">for more detail.</span><br><span class="line"></span><br><span class="line">[2020-04-02 10:47:57] DEBUG - base_path=/opt/fdfs_tracker, connect_timeout=5, network_timeout=60, tracker_server_count=1, anti_steal_token=0, anti_steal_secret_key length=0, use_connection_pool=0, g_connection_pool_max_idle_time=3600s, use_storage_id=0, storage server id count: 0</span><br><span class="line"></span><br><span class="line">tracker_query_storage_store_list_without_group: </span><br><span class="line">        server 1. group_name=, ip_addr=192.168.75.5, port=23000</span><br><span class="line"></span><br><span class="line">group_name=group1, ip_addr=192.168.75.5, port=23000</span><br><span class="line">storage_upload_by_filename</span><br><span class="line">group_name=group1, remote_filename=M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">source ip address: 192.168.75.5</span><br><span class="line">file timestamp=2020-04-02 10:47:58</span><br><span class="line">file size=2402082</span><br><span class="line">file crc32=779422649</span><br><span class="line">example file url: http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">storage_upload_slave_by_filename</span><br><span class="line">group_name=group1, remote_filename=M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br><span class="line">source ip address: 192.168.75.5</span><br><span class="line">file timestamp=2020-04-02 10:47:58</span><br><span class="line">file size=2402082</span><br><span class="line">file crc32=779422649</span><br><span class="line">example file url: http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br></pre></td></tr></table></figure><p></p><p>以上图中的文件地址：<a href="http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg对应storage服务器上的/opt/fdfs_storage_data/data/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg文件" target="_blank" rel="noopener">http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg对应storage服务器上的/opt/fdfs_storage_data/data/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg文件</a>;</p><blockquote><p>注意图片路径中的8080端口,这个是tracker的端口，</p></blockquote><p>但是查看该目录，会有四个图片文件:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon 00]# pwd</span><br><span class="line">/opt/fdfs_storage_data/data/00/00</span><br><span class="line">[root@bogon 00]# ll</span><br><span class="line">total 4704</span><br><span class="line">-rw-r--r-- 1 root root 2402082 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg</span><br><span class="line">-rw-r--r-- 1 root root      49 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037_big.jpg-m</span><br><span class="line">-rw-r--r-- 1 root root 2402082 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">-rw-r--r-- 1 root root      49 Apr  2 10:47 wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg-m</span><br></pre></td></tr></table></figure><p></p><h2 id="FastDFS和nginx结合使用"><a href="#FastDFS和nginx结合使用" class="headerlink" title="FastDFS和nginx结合使用"></a>FastDFS和nginx结合使用</h2><h3 id="在tracker上安装-nginx"><a href="#在tracker上安装-nginx" class="headerlink" title="在tracker上安装 nginx"></a>在tracker上安装 nginx</h3><p>在每个tracker上安装nginx的主要目的是做负载均衡及实现高可用。如果只有一台tracker服务器可以不配置nginx.<br>一个tracker对应多个storage，通过nginx对storage负载均衡;</p><h3 id="在storage上安装nginx-openresty"><a href="#在storage上安装nginx-openresty" class="headerlink" title="在storage上安装nginx(openresty)"></a>在storage上安装nginx(openresty)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/src/</span><br><span class="line">tar -zxvf fastdfs-nginx-module-1.22.tar.gz</span><br><span class="line">cd fastdfs-nginx-module-1.22/src</span><br><span class="line">cp mod_fastdfs.conf /etc/fdfs/</span><br><span class="line">vim /etc/fdfs/mod_fastdfs.conf</span><br><span class="line">    base_path=/opt/fdfs_storage</span><br><span class="line">    tracker_server=192.168.75.5:22122</span><br><span class="line">    url_have_group_name = true #url中包含group名称</span><br><span class="line">    store_path0=/opt/fdfs_storage_data #与storage.conf中的路径保持一致</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">yum -y install pcre pcre-devel openssl openssl-devel</span><br><span class="line">cd /usr/local/src</span><br><span class="line">tar -zxvf openresty-1.15.8.3.tar.gz</span><br><span class="line">cd openresty-1.15.8.3</span><br><span class="line">./configure \</span><br><span class="line">    --with-luajit \</span><br><span class="line">    --with-http_stub_status_module \</span><br><span class="line">    --with-http_ssl_module \</span><br><span class="line">    --with-http_realip_module \</span><br><span class="line">    --with-http_gzip_static_module \</span><br><span class="line">    --add-module=/usr/local/src/fastdfs-nginx-module-1.22/src</span><br><span class="line">gmake</span><br><span class="line">gmake install</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">vim /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">    error_log  logs/error.log;</span><br><span class="line">    pid      logs/nginx.pid;</span><br><span class="line">    server&#123;</span><br><span class="line">        server_name  192.168.75.5; </span><br><span class="line">    &#125;</span><br><span class="line">/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line"># 浏览器访问，出现openresty欢迎页面</span><br><span class="line"></span><br><span class="line"># 设置nginx开机启动</span><br><span class="line">echo &quot;/usr/local/openresty/nginx/sbin/nginx -c /usr/local/openresty/nginx/conf/nginx.conf&quot; | tee -a /etc/rc.d/rc.local</span><br><span class="line"></span><br><span class="line">vim /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">    server&#123;</span><br><span class="line">        location /group1/M00/ &#123;</span><br><span class="line">            root /opt/fdfs_storage/data;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">/usr/local/openresty/nginx/sbin/nginx -s reload</span><br><span class="line"></span><br><span class="line"># 参考上面测试的那一步图片url地址：http://192.168.75.5:8080/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">使用nginxf访问的话，实际地址是：http://192.168.75.5/group1/M00/00/00/wKhLBV6FUl6AA0eTACSnIi51C7k037.jpg</span><br><span class="line">需要把tracker使用的8080端口去掉，否则无法访问</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># 进一步完善nginx配置文件</span><br><span class="line">    # 这个server设置的是storage nginx</span><br><span class="line">    server &#123;</span><br><span class="line">        listen       9991;</span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location ~/group1/M00 &#123;</span><br><span class="line">            root /opt/fastdfs_storage/data;</span><br><span class="line">            ngx_fastdfs_module;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    # 若访问不到图片需要配置这个软连接</span><br><span class="line">    # ln -s /opt/fastdfs_storage_data/data/ /opt/fastdfs_storage_data/data/M00</span><br><span class="line">    </span><br><span class="line">    # 这个server设置的是tracker nginx</span><br><span class="line">    upstream fdfs_group1 &#123;</span><br><span class="line">        server 127.0.0.1:9991;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  localhost;</span><br><span class="line">        </span><br><span class="line">        location /group1/M00 &#123;</span><br><span class="line">            proxy_pass http://fdfs_group1;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        error_page   500 502 503 504  /50x.html;</span><br><span class="line">        location = /50x.html &#123;</span><br><span class="line">            root   html;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed Apr 08 2020 18:05:48 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;软件下载&quot;&gt;&lt;a href=&quot;#软件下载&quot; class=&quot;headerlink&quot; title=&quot;软件下载&quot;&gt;&lt;/a&gt;软件下载&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;# 已经事先把所需软件下载好并上传到/usr/local/src目录了&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/libfastcommon/archive/V1.0.43.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs-nginx-module/archive/V1.22.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs/archive/V6.06.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://github.com/happyfish100/fastdfs-client-java/archive/V1.28.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;https://openresty.org/download/openresty-1.15.8.3.tar.gz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h1 id=&quot;基础环境设置&quot;&gt;&lt;a href=&quot;#基础环境设置&quot; class=&quot;headerlink&quot; title=&quot;基础环境设置&quot;&gt;&lt;/a&gt;基础环境设置&lt;/h1&gt;&lt;h2 id=&quot;安装依赖组件&quot;&gt;&lt;a href=&quot;#安装依赖组件&quot; class=&quot;headerlink&quot; title=&quot;安装依赖组件&quot;&gt;&lt;/a&gt;安装依赖组件&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum -y install  gcc gcc-c++ libevent&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;yum -y groupinstall &amp;apos;Development Tools&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;
    
    </summary>
    
      <category term="nginx" scheme="https://yongnights.github.io/categories/nginx/"/>
    
      <category term="FastDFS" scheme="https://yongnights.github.io/categories/nginx/FastDFS/"/>
    
    
      <category term="nginx" scheme="https://yongnights.github.io/tags/nginx/"/>
    
      <category term="FastDFS" scheme="https://yongnights.github.io/tags/FastDFS/"/>
    
  </entry>
  
  <entry>
    <title>FastAPI快速入门</title>
    <link href="https://yongnights.github.io/2020/01/15/fastapi%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
    <id>https://yongnights.github.io/2020/01/15/fastapi快速入门/</id>
    <published>2020-01-15T02:30:32.629Z</published>
    <updated>2020-01-15T02:45:12.585Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Jan 15 2020 18:06:02 GMT+0800 (GMT+08:00) --><p>fastapi是高性能的web框架。他的主要特点是：</p><ul><li>快速编码</li><li>减少人为bug</li><li>直观</li><li>简易</li><li>具有交互式文档</li><li>基于API的开放标准（并与之完全兼容）：OpenAPI（以前称为Swagger）和JSON Schema。</li></ul><p>技术背景：python3.6+、Starlette、Pydantic</p><p>官方文档地址：<a href="https://fastapi.tiangolo.com/" target="_blank" rel="noopener">https://fastapi.tiangolo.com/</a></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install fastapi</span><br><span class="line">pip install uvicorn</span><br></pre></td></tr></table></figure><a id="more"></a><h1 id="quick-start"><a href="#quick-start" class="headerlink" title="quick start"></a>quick start</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># main.py</span><br><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line">@app.get(&quot;/&quot;)</span><br><span class="line">def read_root():</span><br><span class="line">    return &#123;&quot;Hello&quot;: &quot;World&quot;&#125;</span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">def read_item(item_id: int, q: str = None):</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id, &quot;q&quot;: q&#125;</span><br></pre></td></tr></table></figure><p>或者<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># If your code uses async / await, use async def:</span><br><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/&quot;)</span><br><span class="line">async def read_root():</span><br><span class="line">    return &#123;&quot;Hello&quot;: &quot;World&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">async def read_item(item_id: int, q: str = None):</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id, &quot;q&quot;: q&#125;</span><br></pre></td></tr></table></figure><p></p><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uvicorn main:app --reload</span><br></pre></td></tr></table></figure><p>看到如下提示，证明运行成功</p><p><img src="/fastapi快速入门.assets/1.png" alt></p><pre><code>main: 表示app所在文件名, the file main.py (the Python &quot;module&quot;).app：FastAPI实例, the object created inside of main.py with the line app = FastAPI().reload：debug模式，可以自动重启,make the server restart after code changes. Only do this for development.</code></pre><p>试着请求<a href="http://127.0.0.1:8000/items/5?q=somequery，会看到如下返回" target="_blank" rel="noopener">http://127.0.0.1:8000/items/5?q=somequery，会看到如下返回</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;item_id&quot;: 5, &quot;q&quot;: &quot;somequery&quot;&#125;</span><br></pre></td></tr></table></figure><p></p><h1 id="交互文档"><a href="#交互文档" class="headerlink" title="交互文档"></a>交互文档</h1><p>试着打开<a href="http://127.0.0.1:8000/docs" target="_blank" rel="noopener">http://127.0.0.1:8000/docs</a><br><img src="/fastapi快速入门.assets/2.png" alt></p><h1 id="API文档"><a href="#API文档" class="headerlink" title="API文档"></a>API文档</h1><p>试着打开<a href="http://127.0.0.1:8000/redoc" target="_blank" rel="noopener">http://127.0.0.1:8000/redoc</a><br><img src="/fastapi快速入门.assets/3.png" alt></p><h1 id="update"><a href="#update" class="headerlink" title="update"></a>update</h1><p>通过上面的例子，我们已经用fastapi完成了第一个web服务，现在我们再添加一个接口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line">from pydantic import BaseModel</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Item(BaseModel):</span><br><span class="line">    name: str</span><br><span class="line">    price: float</span><br><span class="line">    is_offer: bool = None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/&quot;)</span><br><span class="line">def read_root():</span><br><span class="line">    return &#123;&quot;Hello&quot;: &quot;World&quot;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">def read_item(item_id: int, q: str = None):</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id, &quot;q&quot;: q&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.put(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">def update_item(item_id: int, item: Item):</span><br><span class="line">    return &#123;&quot;item_name&quot;: item.name, &quot;item_id&quot;: item_id&#125;</span><br></pre></td></tr></table></figure><p>此时会发现，服务自动重启了，这是因为我们在启动命令后添加了–reload。再次查看文档，发现同样发生了改变。<br>到此，你已经可以快速的用fastapi搭建起服务了～</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed Jan 15 2020 18:06:02 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;fastapi是高性能的web框架。他的主要特点是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;快速编码&lt;/li&gt;&lt;li&gt;减少人为bug&lt;/li&gt;&lt;li&gt;直观&lt;/li&gt;&lt;li&gt;简易&lt;/li&gt;&lt;li&gt;具有交互式文档&lt;/li&gt;&lt;li&gt;基于API的开放标准（并与之完全兼容）：OpenAPI（以前称为Swagger）和JSON Schema。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;技术背景：python3.6+、Starlette、Pydantic&lt;/p&gt;&lt;p&gt;官方文档地址：&lt;a href=&quot;https://fastapi.tiangolo.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://fastapi.tiangolo.com/&lt;/a&gt;&lt;/p&gt;&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip install fastapi&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;pip install uvicorn&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Python" scheme="https://yongnights.github.io/categories/Python/"/>
    
      <category term="FastAPI" scheme="https://yongnights.github.io/categories/Python/FastAPI/"/>
    
    
      <category term="Python" scheme="https://yongnights.github.io/tags/Python/"/>
    
      <category term="FastAPI" scheme="https://yongnights.github.io/tags/FastAPI/"/>
    
  </entry>
  
  <entry>
    <title>FastAPI教程进阶(一)</title>
    <link href="https://yongnights.github.io/2020/01/15/fastapi%E6%95%99%E7%A8%8B%E8%BF%9B%E9%98%B6%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>https://yongnights.github.io/2020/01/15/fastapi教程进阶（一）/</id>
    <published>2020-01-15T02:30:32.627Z</published>
    <updated>2020-01-15T02:33:29.752Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Wed Jan 15 2020 10:34:46 GMT+0800 (GMT+08:00) --><h1 id="一个简单的栗子"><a href="#一个简单的栗子" class="headerlink" title="一个简单的栗子"></a>一个简单的栗子</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/&quot;)</span><br><span class="line">async def root():</span><br><span class="line">    return &#123;&quot;message&quot;: &quot;Hello World&quot;&#125;</span><br></pre></td></tr></table></figure><blockquote><p>FASTAPI继承Starlette，因此在Starlette中的所有可调用的对象在FASTAPI中可以直接引用</p></blockquote><a id="more"></a><h1 id="编写步骤"><a href="#编写步骤" class="headerlink" title="编写步骤"></a>编写步骤</h1><h2 id="步骤一：导入FastAPI"><a href="#步骤一：导入FastAPI" class="headerlink" title="步骤一：导入FastAPI"></a>步骤一：导入FastAPI</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br></pre></td></tr></table></figure><h2 id="步骤二：创建FastAPI实例"><a href="#步骤二：创建FastAPI实例" class="headerlink" title="步骤二：创建FastAPI实例"></a>步骤二：创建FastAPI实例</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">app = FastAPI()</span><br></pre></td></tr></table></figure><h2 id="步骤三：创建访问路径"><a href="#步骤三：创建访问路径" class="headerlink" title="步骤三：创建访问路径"></a>步骤三：创建访问路径</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">@app.get(&quot;/&quot;)</span><br></pre></td></tr></table></figure><p>这个路径告诉FastAPI，该装饰器下的方法是用来处理路径是“/”的GET请求</p><h2 id="步骤四：定义方法，处理请求"><a href="#步骤四：定义方法，处理请求" class="headerlink" title="步骤四：定义方法，处理请求"></a>步骤四：定义方法，处理请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">async def root():</span><br></pre></td></tr></table></figure><h2 id="步骤五：返回响应信息"><a href="#步骤五：返回响应信息" class="headerlink" title="步骤五：返回响应信息"></a>步骤五：返回响应信息</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">return &#123;&quot;message&quot;: &quot;Hello World&quot;&#125;</span><br></pre></td></tr></table></figure><h2 id="步骤六：运行"><a href="#步骤六：运行" class="headerlink" title="步骤六：运行"></a>步骤六：运行</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uvicorn main:app --reload</span><br></pre></td></tr></table></figure><h1 id="获取路径参数"><a href="#获取路径参数" class="headerlink" title="获取路径参数"></a>获取路径参数</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">async def read_item(item_id):</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id&#125;</span><br></pre></td></tr></table></figure><p>路径中的item_id将会被解析，传递给方法中的item_id。请求<a href="http://127.0.0.1:8000/items/foo会返回如下结果：" target="_blank" rel="noopener">http://127.0.0.1:8000/items/foo会返回如下结果：</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;item_id&quot;:&quot;foo&quot;&#125;</span><br></pre></td></tr></table></figure><p></p><p>也可以在方法中定义参数类型：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">async def read_item(item_id: int):</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id&#125;</span><br></pre></td></tr></table></figure><p></p><p>继续请求<a href="http://127.0.0.1:8000/items/3，会返回" target="_blank" rel="noopener">http://127.0.0.1:8000/items/3，会返回</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;item_id&quot;:3&#125;</span><br></pre></td></tr></table></figure><p></p><p>此时的item_id是int类型的3，而不是string类型，这是因为FastAPI在解析请求时，自动根据声明的类型进行了解析<br>如果请求<a href="http://127.0.0.1:8000/items/foo，此时会返回：" target="_blank" rel="noopener">http://127.0.0.1:8000/items/foo，此时会返回：</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;detail&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;loc&quot;: [</span><br><span class="line">                &quot;path&quot;,</span><br><span class="line">                &quot;item_id&quot;</span><br><span class="line">            ],</span><br><span class="line">            &quot;msg&quot;: &quot;value is not a valid integer&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;type_error.integer&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>这是因为foo并不能转换成int类型。请求<a href="http://127.0.0.1:8000/items/4.2也会出现上述错误" target="_blank" rel="noopener">http://127.0.0.1:8000/items/4.2也会出现上述错误</a></p><blockquote><p>所有的数据类型验证，都是通过Pydantic完成的</p></blockquote><p>如果想对路径参数做一个预定义，可以使用Enum：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from enum import Enum</span><br><span class="line"></span><br><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ModelName(str, Enum):</span><br><span class="line">    alexnet = &quot;alexnet&quot;</span><br><span class="line">    resnet = &quot;resnet&quot;</span><br><span class="line">    lenet = &quot;lenet&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/model/&#123;model_name&#125;&quot;)</span><br><span class="line">async def get_model(model_name: ModelName):</span><br><span class="line">    if model_name == ModelName.alexnet:</span><br><span class="line">        return &#123;&quot;model_name&quot;: model_name, &quot;message&quot;: &quot;Deep Learning FTW!&quot;&#125;</span><br><span class="line">    if model_name.value == &quot;lenet&quot;:</span><br><span class="line">        return &#123;&quot;model_name&quot;: model_name, &quot;message&quot;: &quot;LeCNN all the images&quot;&#125;</span><br><span class="line">    return &#123;&quot;model_name&quot;: model_name, &quot;message&quot;: &quot;Have some residuals&quot;&#125;</span><br></pre></td></tr></table></figure><p></p><p>打开<a href="http://127.0.0.1:8000/docs" target="_blank" rel="noopener">http://127.0.0.1:8000/docs</a>:<br><img src="/fastapi教程进阶（一）.assets/1.png" alt><br>除此之外，假如想接收一个路径参数，它本身就是一个路径，就像/files/{file_path}，而这个file_path是home/johndoe/myfile.txt时，可以写成/files/{file_path:path}：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/files/&#123;file_path:path&#125;&quot;)</span><br><span class="line">async def read_user_me(file_path: str):</span><br><span class="line">    return &#123;&quot;file_path&quot;: file_path&#125;</span><br></pre></td></tr></table></figure><pre><code>OpenAPI本身不支持在路径参数包含路径，但是可以当作Starlette内部的一个使用方法</code></pre><p>此时访问<a href="http://127.0.0.1:8000/files/home/johndoe/myfile.txt，返回：" target="_blank" rel="noopener">http://127.0.0.1:8000/files/home/johndoe/myfile.txt，返回：</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;file_path&quot;:&quot;home/johndoe/myfile.txt&quot;&#125;</span><br></pre></td></tr></table></figure><p></p><p>如果将路径改为/files/{file_path}，会返回：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;detail&quot;:&quot;Not Found&quot;&#125;</span><br></pre></td></tr></table></figure><p></p><h1 id="获取查询参数"><a href="#获取查询参数" class="headerlink" title="获取查询参数"></a>获取查询参数</h1><p>这里依旧是一个例子：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line">fake_items_db = [&#123;&quot;item_name&quot;: &quot;Foo&quot;&#125;, &#123;&quot;item_name&quot;: &quot;Bar&quot;&#125;, &#123;&quot;item_name&quot;: &quot;Baz&quot;&#125;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&quot;)</span><br><span class="line">async def read_item(skip: int = 0, limit: int = 10):</span><br><span class="line">    return fake_items_db[skip : skip + limit]</span><br></pre></td></tr></table></figure><p></p><p>尝试访问<a href="http://127.0.0.1:8000/items/?skip=0&amp;limit=2，返回：" target="_blank" rel="noopener">http://127.0.0.1:8000/items/?skip=0&amp;limit=2，返回：</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#123;&quot;item_name&quot;:&quot;Foo&quot;&#125;,&#123;&quot;item_name&quot;:&quot;Bar&quot;&#125;]</span><br></pre></td></tr></table></figure><p></p><p>尝试访问<a href="http://127.0.0.1:8000/items/，返回：" target="_blank" rel="noopener">http://127.0.0.1:8000/items/，返回：</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#123;&quot;item_name&quot;:&quot;Foo&quot;&#125;,&#123;&quot;item_name&quot;:&quot;Bar&quot;&#125;,&#123;&quot;item_name&quot;:&quot;Baz&quot;&#125;]</span><br></pre></td></tr></table></figure><p></p><p>由于我们在定义方法的时候，分别赋予skip和limit默认值，当不添加querystring时，会使用默认值。当然，我们也可以将默认值赋值为None：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">async def read_item(item_id: str, q: str = None):</span><br><span class="line">    if q:</span><br><span class="line">        return &#123;&quot;item_id&quot;: item_id, &quot;q&quot;: q&#125;</span><br><span class="line">    return &#123;&quot;item_id&quot;: item_id&#125;</span><br></pre></td></tr></table></figure><p></p><p>此时，我们请求<a href="http://127.0.0.1:8000/items/1?q=qqq" target="_blank" rel="noopener">http://127.0.0.1:8000/items/1?q=qqq</a>:<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;item_id&quot;:&quot;1&quot;,&quot;q&quot;:&quot;qqq&quot;&#125;</span><br></pre></td></tr></table></figure><p></p><blockquote><p>值得放心的一点是，FastAPI很聪明，他知道参数来自哪里～</p></blockquote><p>假如，我们不给参数默认值会发生什么情况呢？这里还是一个例子：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from fastapi import FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.get(&quot;/items/&#123;item_id&#125;&quot;)</span><br><span class="line">async def read_user_item(item_id: str, needy: str):</span><br><span class="line">    item = &#123;&quot;item_id&quot;: item_id, &quot;needy&quot;: needy&#125;</span><br><span class="line">    return item</span><br></pre></td></tr></table></figure><p></p><p>继续请求<a href="http://127.0.0.1:8000/items/1，会发现，返回报错：" target="_blank" rel="noopener">http://127.0.0.1:8000/items/1，会发现，返回报错：</a><br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;detail&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;loc&quot;: [</span><br><span class="line">        &quot;query&quot;,</span><br><span class="line">        &quot;needy&quot;</span><br><span class="line">      ],</span><br><span class="line">      &quot;msg&quot;: &quot;field required&quot;,</span><br><span class="line">      &quot;type&quot;: &quot;value_error.missing&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Wed Jan 15 2020 10:34:46 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;一个简单的栗子&quot;&gt;&lt;a href=&quot;#一个简单的栗子&quot; class=&quot;headerlink&quot; title=&quot;一个简单的栗子&quot;&gt;&lt;/a&gt;一个简单的栗子&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;from fastapi import FastAPI&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;app = FastAPI()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;@app.get(&amp;quot;/&amp;quot;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;async def root():&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return &amp;#123;&amp;quot;message&amp;quot;: &amp;quot;Hello World&amp;quot;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;p&gt;FASTAPI继承Starlette，因此在Starlette中的所有可调用的对象在FASTAPI中可以直接引用&lt;/p&gt;&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Python" scheme="https://yongnights.github.io/categories/Python/"/>
    
      <category term="FastAPI" scheme="https://yongnights.github.io/categories/Python/FastAPI/"/>
    
    
      <category term="Python" scheme="https://yongnights.github.io/tags/Python/"/>
    
      <category term="FastAPI" scheme="https://yongnights.github.io/tags/FastAPI/"/>
    
  </entry>
  
  <entry>
    <title>Jenkins 使用 SonarQube 扫描 Coding</title>
    <link href="https://yongnights.github.io/2020/01/14/Jenkins%20%E4%BD%BF%E7%94%A8%20SonarQube%20%E6%89%AB%E6%8F%8F%20Coding/"/>
    <id>https://yongnights.github.io/2020/01/14/Jenkins 使用 SonarQube 扫描 Coding/</id>
    <published>2020-01-14T08:25:14.197Z</published>
    <updated>2020-01-14T08:53:49.242Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jan 14 2020 16:55:04 GMT+0800 (GMT+08:00) --><p>系统环境：</p><ul><li>Jenkins 版本：2.176</li><li>SonarQube 版本：7.4.0</li></ul><h1 id="一、SonarQube-介绍"><a href="#一、SonarQube-介绍" class="headerlink" title="一、SonarQube 介绍"></a>一、SonarQube 介绍</h1><h2 id="1、SonarQube-简介"><a href="#1、SonarQube-简介" class="headerlink" title="1、SonarQube 简介"></a>1、SonarQube 简介</h2><p>SonarQube 是一个用于代码质量管理的开源平台，用于管理源代码的质量。同时 SonarQube 还对大量的持续集成工具提供了接口支持，可以很方便地在持续集成中使用 SonarQube。此外， SonarQube 的插件还可以对 Java 以外的其他编程语言提供支持，对国际化以及报告文档化也有良好的支持。</p><h2 id="2、SonarQube工作原理"><a href="#2、SonarQube工作原理" class="headerlink" title="2、SonarQube工作原理"></a>2、SonarQube工作原理</h2><p>SonarQube 并不是简单地将各种质量检测工具的结果直接展现给客户，而是通过不同的插件算法来对这些结果进行再加工，最终以量化的方式来衡量代码质量，从而方便地对不同规模和种类的工程进行相应的代码质量管理。</p><h2 id="3、SonarQube-特性"><a href="#3、SonarQube-特性" class="headerlink" title="3、SonarQube 特性"></a>3、SonarQube 特性</h2><pre><code>多语言的平台： 支持超过20种编程语言，包括Java、Python、C#、C/C++、JavaScript等常用语言。自定义规则： 用户可根据不同项目自定义Quality Profile以及Quality Gates。丰富的插件： SonarQube 拥有丰富的插件，从而拥有强大的可扩展性。持续集成： 通过对某项目的持续扫描，可以对该项目的代码质量做长期的把控，并且预防新增代码中的不严谨和冗余。质量门： 在扫描代码后可以通过对“质量门”的比对判定此次“构建”的结果是否通过，质量门可以由用户定义，由多维度判定是否通过。</code></pre><h2 id="4、需要注意的代码质量问题"><a href="#4、需要注意的代码质量问题" class="headerlink" title="4、需要注意的代码质量问题"></a>4、需要注意的代码质量问题</h2><pre><code>(1)、不遵循代码标准： SonarQube可以通过PMD,CheckStyle,Findbugs等等代码规则检测工具规 范代码编写。(2)、糟糕的复杂度分布： 文件、类、方法等，如果复杂度过高将难以改变，这会使得开发人员难以理解它们且如果没有自动化的单元测试，对于程序中的任何组件的改变都将可能导致需要全面的回归测试。(3)、注释不足或者过多： 没有注释将使代码可读性变差，特别是当不可避免地出现人员变动 时，程序的可读性将大幅下降而过多的注释又会使得开发人员将精力过多地花费在阅读注释上，亦违背初衷。(4)、缺乏单元测试： SonarQube 可以很方便地统计并展示单元测试覆盖率。(5)、潜在的缺陷： –SonarQube 可以通过PMD,CheckStyle,Findbugs等等代码规则检测工具检 测出潜在的缺陷。(6)、重复： 显然程序中包含大量复制粘贴的代码是质量低下的，SonarQube 源码中重复严重的地方。(7)、糟糕的设计</code></pre><a id="more"></a><h1 id="二、一般执行流程"><a href="#二、一般执行流程" class="headerlink" title="二、一般执行流程"></a>二、一般执行流程</h1><p>在项目中一般流程为：</p><pre><code>(1)、项目人员开发代码。(2)、将代码推送到持久化仓库，如 Git。(3)、Jenkins 进行代码拉取，然后利用 SonarQube 扫描器进行扫描分析代码信息。(4)、将分析结果等信息上传至 SonarQube Server 服务器进行分类处理。(5)、SonarQube 将分析结果等信息持久化到数据库，如 Mysql。(6)、开发人员访问 SonarQube UI 界面访问，查看扫描出的结果信息进行项目优化。</code></pre><p>这里只描述 Jenkins 如何与 SonarQube 集成</p><pre><code>执行过程流程图</code></pre><p><img src="/Jenkins_SonarQube/jenkins-sona-1002.jpg" alt></p><h1 id="三、SonarQuke-配置"><a href="#三、SonarQuke-配置" class="headerlink" title="三、SonarQuke 配置"></a>三、SonarQuke 配置</h1><h2 id="1、禁用SCM传感器"><a href="#1、禁用SCM传感器" class="headerlink" title="1、禁用SCM传感器"></a>1、禁用SCM传感器</h2><pre><code>点击 配置—SCM—Disable the SCM Sensor 将其关闭。</code></pre><p><img src="/Jenkins_SonarQube/jenkins-sona-1003.jpg" alt></p><h2 id="2、安装-JAVA-分析插件"><a href="#2、安装-JAVA-分析插件" class="headerlink" title="2、安装 JAVA 分析插件"></a>2、安装 JAVA 分析插件</h2><p>由于这里要分析的项目是 JAVA 项目，所以需要确保安装 Java 语言分析插件，如果是别的类型的项目，可以类似安装相关分析插件即可。</p><ul><li>点击 配置—应用市场—插件 搜索 SonarJava 插件安装</li></ul><blockquote><p>如果忘记安装，可能会导致 Jenkins 编译过程中提示没有语言插件的异常错误信息,确保一定要安装。<br><img src="/Jenkins_SonarQube/jenkins-sona-1004.jpg" alt></p></blockquote><h2 id="3、生成-Token"><a href="#3、生成-Token" class="headerlink" title="3、生成 Token"></a>3、生成 Token</h2><p>这里生成验证用的 Token 字符串，用于 Jenkins 在执行流水线时候将待检测信息发送到 SonarQube 时候用于的安全验证。</p><ul><li>点击 头像—我的账号—安全—生成令牌 生成验证的 Token。</li></ul><blockquote><p>因为此 Token 不会显示第二次，所以这里记住此 Token。<br><img src="/Jenkins_SonarQube/jenkins-sona-1005.jpg" alt></p></blockquote><h1 id="四、Jenkins-安装插件"><a href="#四、Jenkins-安装插件" class="headerlink" title="四、Jenkins 安装插件"></a>四、Jenkins 安装插件</h1><h2 id="1、需要安装的插件介绍"><a href="#1、需要安装的插件介绍" class="headerlink" title="1、需要安装的插件介绍"></a>1、需要安装的插件介绍</h2><p>Jenkins 先提前安装好可能需要用到的插件，这里需要用到一下插件：</p><ul><li>Maven Integration</li></ul><p>Maven 插件，用于编译 Maven 项目和安装 Maven 工具到任务中。</p><ul><li>Pipeline Utility Steps</li></ul><blockquote><p>参考：<a href="https://jenkins.io/doc/pipeline/steps/pipeline-utility-steps/" target="_blank" rel="noopener">https://jenkins.io/doc/pipeline/steps/pipeline-utility-steps/</a></p></blockquote><p>用于在 Pipeline 执行过程中操作文件“读/写”的插件，这里用其创建 Sonar properties 配置文件。</p><ul><li>SonarQube Scanner</li></ul><blockquote><p>参考：<a href="https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Jenkins" target="_blank" rel="noopener">https://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Jenkins</a></p></blockquote><p>SonarQube 是一种用于连续检查代码质量的开源平台，该插件可轻松与 SonarQube 集成。</p><h2 id="2、安装-SonarQube-Scanner-插件"><a href="#2、安装-SonarQube-Scanner-插件" class="headerlink" title="2、安装 SonarQube Scanner 插件"></a>2、安装 SonarQube Scanner 插件</h2><p>打开 系统管理—插件管理—可选插件 输入 sonarqube 进行插件筛选，如下如方式进行安装。<br><img src="/Jenkins_SonarQube/jenkins-sona-1006.jpg" alt><br>关于安装 Pipeline Utility Steps 与 Maven Integration 插件和上面类似，请自行安装即可，这里不过多描述。</p><h1 id="五、Jenkins-配置插件"><a href="#五、Jenkins-配置插件" class="headerlink" title="五、Jenkins 配置插件"></a>五、Jenkins 配置插件</h1><h2 id="1、连接-SonarQube-配置"><a href="#1、连接-SonarQube-配置" class="headerlink" title="1、连接 SonarQube 配置"></a>1、连接 SonarQube 配置</h2><p>打开 系统管理—系统设置—SonarQube servers 配置下面属性<br><img src="/Jenkins_SonarQube/jenkins-sona-1007.jpg" alt><br>参数说明：</p><ul><li>Name： 用于 Jenklins Pipeline 中构建环境指定的名称，在 Pipeline 脚本中会用到，自定义即可。</li><li>Server URL： SonarQube 地址。</li><li>Server authentication token： 用于连接 SonarQube 的 Token，将上面 SonarQube 中生成的 Token 输入即可。</li></ul><h2 id="2、配置-SonarQube-Scanner-插件"><a href="#2、配置-SonarQube-Scanner-插件" class="headerlink" title="2、配置 SonarQube Scanner 插件"></a>2、配置 SonarQube Scanner 插件</h2><p>打开 系统管理—全局工具配置—SonarQube Scanner 输入 Name，选择最新版本点击自动安装即可<br><img src="/Jenkins_SonarQube/jenkins-sona-1008.jpg" alt></p><h2 id="3、配置-Maven-插件"><a href="#3、配置-Maven-插件" class="headerlink" title="3、配置 Maven 插件"></a>3、配置 Maven 插件</h2><p>打开 系统管理—全局工具配置—Maven 输入 Name，选择最新版本点击自动安装即可<br><img src="/Jenkins_SonarQube/jenkins-sona-1009.jpg" alt></p><h1 id="六、创建流水线项目写-Pipeline-脚本"><a href="#六、创建流水线项目写-Pipeline-脚本" class="headerlink" title="六、创建流水线项目写 Pipeline 脚本"></a>六、创建流水线项目写 Pipeline 脚本</h1><h2 id="1、创建流水线任务"><a href="#1、创建流水线任务" class="headerlink" title="1、创建流水线任务"></a>1、创建流水线任务</h2><p><img src="/Jenkins_SonarQube/jenkins-sona-1010.jpg" alt></p><h2 id="2、设置-SonarQube-配置文件"><a href="#2、设置-SonarQube-配置文件" class="headerlink" title="2、设置 SonarQube 配置文件"></a>2、设置 SonarQube 配置文件</h2><p>(1)、Sonar 配置文件说明</p><p>在使用 SonarQube 来进行代码扫描时候需要一个名称为 sonar-project.properties 的配置文件。该文件设置了项目的一些属性用于 SonarQube 扫描的属性。</p><p>例如，设置项目在 Sonar 面板中的唯一标识 Key，项目名称及其版本，要扫描项目的语言类型等等。</p><blockquote><p>sonar-project.properties<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sonar.projectKey=key:value</span><br><span class="line">sonar.projectName=ProjectName</span><br><span class="line">sonar.projectVersion=1.0.0</span><br><span class="line">sonar.sources=src</span><br><span class="line">sonar.language=java</span><br><span class="line">sonar.sourceEncoding=UTF-8</span><br><span class="line">sonar.java.binaries=target/classes</span><br><span class="line">sonar.java.source=1.8</span><br><span class="line">sonar.java.target=1.8</span><br></pre></td></tr></table></figure><p></p></blockquote><p>配置参数：</p><ul><li>sonar.projectKey： 项目在 SonarQube 的唯一标识，不能重复</li><li>sonar.projectName=ProjectName： 项目名称</li><li>sonar.projectVersion： 项目版本</li><li>sonar.language： 项目语言，例如 Java、C#、PHP 等</li><li>sonar.sourceEncoding： 编码方式</li><li>sonar.sources： 项目源代码目录</li><li>sonar.java.binaries： 编译后 class 文件目录</li></ul><p>(2)、Sonar 配置文件存放位置</p><p>这个文件可以放在源代码根目录中，也可是设置到 Jenkins 变量。</p><p>① ————————方式一：放置到源代码———————————————–</p><p>直接在源代码中放置文件 sonar-project.properties，然后在此配置文件中设置这些配置参数。<br><img src="/Jenkins_SonarQube/jenkins-sona-1011.jpg" alt><br>② ————————方式二：设置到变量并在 Jenkins 编译时候创建————————</p><p>可以设置文本到环境变量中，在变量文本中设置哪些配置参数，之后在执行 Pipeline 脚本时候利用 “Pipeline Utility Steps” 插件的创建文件方法创建 sonar-project.properties 文件。</p><p>在 Jenkins sonar-qube-coding 任务—&gt;配置—&gt;参数化构建过程—&gt;添加参数—&gt;文本参数 输入 Sonar 配置。</p><ul><li>变量名称：sonar_project_properties</li><li>变量内容：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sonar.sources=src</span><br><span class="line">sonar.language=java</span><br><span class="line">sonar.sourceEncoding=UTF-8</span><br><span class="line">sonar.java.binaries=target/classes</span><br><span class="line">sonar.java.source=1.8</span><br><span class="line">sonar.java.target=1.8</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>注意:这里不设置 sonar.projectKey、sonar.projectName、sonar.projectVersion 这三个参数，将三个参数在执行 Pipeline 脚本的时候设置。<br><img src="/Jenkins_SonarQube/jenkins-sona-1012.jpg" alt><br>这里为了配置更灵活方便，所以采用将 SonarQube 配置设置到环境变量</p></blockquote><h2 id="3、创建-Pipeline-脚本"><a href="#3、创建-Pipeline-脚本" class="headerlink" title="3、创建 Pipeline 脚本"></a>3、创建 Pipeline 脚本</h2><p>配置 Jenkins 任务，创建脚本并加入到 “流水线” 配置项中<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">// 设置超时时间为10分钟，如果未成功则结束任务</span><br><span class="line">timeout(time: 600, unit: &apos;SECONDS&apos;) &#123;</span><br><span class="line">    node () &#123;</span><br><span class="line">        stage(&apos;Git 拉取阶段&apos;)&#123;</span><br><span class="line">            // Git 拉取代码</span><br><span class="line">            git branch: &quot;master&quot; ,changelog: true , url: &quot;https://github.com/a324670547/springboot-helloworld&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;Maven 编译阶段&apos;) &#123;</span><br><span class="line">            // 设置 Maven 工具,引用先前全局工具配置中设置工具的名称</span><br><span class="line">            def m3 = tool name: &apos;maven&apos;</span><br><span class="line">            // 执行 Maven 命令</span><br><span class="line">            sh &quot;$&#123;m3&#125;/bin/mvn -B -e clean install -Dmaven.test.skip=true&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;SonarQube 扫描阶段&apos;)&#123;</span><br><span class="line">            // 读取maven变量</span><br><span class="line">            pom = readMavenPom file: &quot;./pom.xml&quot;</span><br><span class="line">            // 创建SonarQube配置文件</span><br><span class="line">            writeFile file: &apos;sonar-project.properties&apos;, </span><br><span class="line">                      text: &quot;&quot;&quot;sonar.projectKey=$&#123;pom.artifactId&#125;:$&#123;pom.version&#125;\n&quot;&quot;&quot;+</span><br><span class="line">                            &quot;&quot;&quot;sonar.projectName=$&#123;pom.artifactId&#125;\n&quot;&quot;&quot;+</span><br><span class="line">                            &quot;&quot;&quot;sonar.projectVersion=$&#123;pom.version&#125;\n&quot;&quot;&quot;+</span><br><span class="line">                            &quot;&quot;&quot;$&#123;sonar_project_properties&#125;&quot;&quot;&quot;</span><br><span class="line">            // 设置 SonarQube 代码扫描工具,引用先前全局工具配置中设置工具的名称</span><br><span class="line">            def sonarqubeScanner = tool name: &apos;sonar-scanner&apos;</span><br><span class="line">            // 设置 SonarQube 环境,其中参数设置为之前系统设置中SonarQuke服务器配置的 Name</span><br><span class="line">            withSonarQubeEnv(&apos;jenkins&apos;) &#123;</span><br><span class="line">                // 执行代码扫描</span><br><span class="line">                sh &quot;$&#123;sonarqubeScanner&#125;/bin/sonar-scanner&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p><img src="/Jenkins_SonarQube/jenkins-sona-1013.jpg" alt></p><h1 id="七、执行-Jenkins-任务"><a href="#七、执行-Jenkins-任务" class="headerlink" title="七、执行 Jenkins 任务"></a>七、执行 Jenkins 任务</h1><h2 id="1、执行-Jenkins-Pipeline-任务"><a href="#1、执行-Jenkins-Pipeline-任务" class="headerlink" title="1、执行 Jenkins Pipeline 任务"></a>1、执行 Jenkins Pipeline 任务</h2><p>点击 Build with Parameters 执行 Jenkins 任务<br><img src="/Jenkins_SonarQube/jenkins-sona-1014.jpg" alt></p><h2 id="2、查看任务执行日志"><a href="#2、查看任务执行日志" class="headerlink" title="2、查看任务执行日志"></a>2、查看任务执行日志</h2><p>查看日志信息为：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">[Pipeline] &#123; (Git 拉取阶段)</span><br><span class="line">[Pipeline] echo</span><br><span class="line">Git 阶段</span><br><span class="line"> &gt; git rev-parse --is-inside-work-tree # timeout=10</span><br><span class="line">Fetching changes from the remote Git repository</span><br><span class="line"> &gt; git config remote.origin.url https://github.com/a324670547/springboot-helloworld # timeout=10</span><br><span class="line">Fetching upstream changes from https://github.com/a324670547/springboot-helloworld</span><br><span class="line"> &gt; git --version # timeout=10</span><br><span class="line"> &gt; git fetch --tags --progress https://github.com/a324670547/springboot-helloworld </span><br><span class="line">Commit message: &quot;修改jenkinsfile&quot;</span><br><span class="line"> &gt; git rev-list --no-walk a34691106075d58bc99d9dcc06f5eadcc03ca759 # timeout=10</span><br><span class="line">[Pipeline] &#123; (Maven 编译阶段)</span><br><span class="line">[Pipeline] tool</span><br><span class="line">+ /var/jenkins_home/tools/hudson.tasks.Maven_MavenInstallation/maven/bin/mvn -B -e clean install -Dmaven.test.skip=true</span><br><span class="line">[INFO] Error stacktraces are turned on.</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ------------------&lt; club.mydlq:springboot-helloworld &gt;------------------</span><br><span class="line">[INFO] Building springboot-helloworld 0.0.1</span><br><span class="line">[INFO] --------------------------------[ jar ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-clean-plugin:3.1.0:clean (default-clean) @ springboot-helloworld ---</span><br><span class="line">[INFO] Deleting /var/jenkins_home/workspace/sonar-qube-coding/target</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:3.1.0:resources (default-resources) @ springboot-helloworld ---</span><br><span class="line">[INFO] Using &apos;UTF-8&apos; encoding to copy filtered resources.</span><br><span class="line">[INFO] Copying 1 resource</span><br><span class="line">[INFO] Copying 0 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.8.0:compile (default-compile) @ springboot-helloworld ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[INFO] Compiling 2 source files to /var/jenkins_home/workspace/sonar-qube-coding/target/classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:3.1.0:testResources (default-testResources) @ springboot-helloworld ---</span><br><span class="line">[INFO] Not copying test resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.8.0:testCompile (default-testCompile) @ springboot-helloworld ---</span><br><span class="line">[INFO] Not compiling test sources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.22.1:test (default-test) @ springboot-helloworld ---</span><br><span class="line">[INFO] Tests are skipped.</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:3.1.1:jar (default-jar) @ springboot-helloworld ---</span><br><span class="line">[INFO] Building jar: /var/jenkins_home/workspace/sonar-qube-coding/target/springboot-helloworld-0.0.1.jar</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- spring-boot-maven-plugin:2.1.4.RELEASE:repackage (repackage) @ springboot-helloworld ---</span><br><span class="line">[INFO] Replacing main artifact with repackaged archive</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-install-plugin:2.5.2:install (default-install) @ springboot-helloworld ---</span><br><span class="line">[INFO] Installing /var/jenkins_home/workspace/sonar-qube-coding/target/springboot-helloworld-0.0.1.jar to /root/.m2/repository/club/mydlq/springboot-helloworld/0.0.1/springboot-helloworld-0.0.1.jar</span><br><span class="line">[INFO] Installing /var/jenkins_home/workspace/sonar-qube-coding/pom.xml to /root/.m2/repository/club/mydlq/springboot-helloworld/0.0.1/springboot-helloworld-0.0.1.pom</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time:  3.695 s</span><br><span class="line">[INFO] Finished at: 2019-05-09T17:59:45Z</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[Pipeline] &#125;</span><br><span class="line">[Pipeline] &#123; (SonarQube 扫描阶段)</span><br><span class="line">[Pipeline] readMavenPom</span><br><span class="line">[Pipeline] writeFile</span><br><span class="line">[Pipeline] tool</span><br><span class="line">[Pipeline] withSonarQubeEnv</span><br><span class="line">Injecting SonarQube environment variables using the configuration: jenkins</span><br><span class="line">[Pipeline] &#123;</span><br><span class="line">[Pipeline] sh</span><br><span class="line">+ /var/jenkins_home/tools/hudson.plugins.sonar.SonarRunnerInstallation/sonar-scanner/bin/sonar-scanner</span><br><span class="line">INFO: Scanner configuration file: /var/jenkins_home/tools/hudson.plugins.sonar.SonarRunnerInstallation/sonar-scanner/conf/sonar-scanner.properties</span><br><span class="line">INFO: Project root configuration file: /var/jenkins_home/workspace/sonar-qube-coding/sonar-project.properties</span><br><span class="line">INFO: SonarQube Scanner 3.3.0.1492</span><br><span class="line">INFO: Java 1.8.0_212 Oracle Corporation (64-bit)</span><br><span class="line">INFO: Linux 3.10.0-957.1.3.el7.x86_64 amd64</span><br><span class="line">INFO: User cache: /root/.sonar/cache</span><br><span class="line">INFO: SonarQube server 7.4.0</span><br><span class="line">INFO: Default locale: &quot;en&quot;, source code encoding: &quot;UTF-8&quot;</span><br><span class="line">INFO: Publish mode</span><br><span class="line">INFO: Load global settings</span><br><span class="line">INFO: Load global settings (done) | time=89ms</span><br><span class="line">INFO: Server id: D549D2A8-AWpYoogtP1ytl0VN9Fsr</span><br><span class="line">INFO: User cache: /root/.sonar/cache</span><br><span class="line">INFO: Load/download plugins</span><br><span class="line">INFO: Load plugins index</span><br><span class="line">INFO: Load plugins index (done) | time=31ms</span><br><span class="line">INFO: Plugin [l10nzh] defines &apos;l10nen&apos; as base plugin. This metadata can be removed from manifest of l10n plugins since version 5.2.</span><br><span class="line">INFO: Load/download plugins (done) | time=38ms</span><br><span class="line">INFO: Loaded core extensions: </span><br><span class="line">INFO: Process project properties</span><br><span class="line">INFO: Load project repositories</span><br><span class="line">INFO: Load project repositories (done) | time=11ms</span><br><span class="line">INFO: Load quality profiles</span><br><span class="line">INFO: Load quality profiles (done) | time=32ms</span><br><span class="line">INFO: Load active rules</span><br><span class="line">INFO: Load active rules (done) | time=201ms</span><br><span class="line">INFO: Load metrics repository</span><br><span class="line">INFO: Load metrics repository (done) | time=24ms</span><br><span class="line">INFO: Project key: springboot-helloworld:0.0.1</span><br><span class="line">INFO: Project base dir: /var/jenkins_home/workspace/sonar-qube-coding</span><br><span class="line">INFO: -------------  Scan springboot-helloworld</span><br><span class="line">INFO: Base dir: /var/jenkins_home/workspace/sonar-qube-coding</span><br><span class="line">INFO: Working dir: /var/jenkins_home/workspace/sonar-qube-coding/.scannerwork</span><br><span class="line">INFO: Source paths: src</span><br><span class="line">INFO: Source encoding: UTF-8, default locale: en</span><br><span class="line">INFO: Load server rules</span><br><span class="line">INFO: Load server rules (done) | time=109ms</span><br><span class="line">INFO: Language is forced to java</span><br><span class="line">INFO: Index files</span><br><span class="line">WARN: File &apos;/var/jenkins_home/workspace/sonar-qube-coding/src/main/resources/application.yaml&apos; is ignored because it doesn&apos;t belong to the forced language &apos;java&apos;</span><br><span class="line">INFO: 2 files indexed</span><br><span class="line">INFO: Quality profile for java: Sonar way</span><br><span class="line">INFO: Sensor JavaSquidSensor [java]</span><br><span class="line">INFO: Configured Java source version (sonar.java.source): 8</span><br><span class="line">INFO: JavaClasspath initialization</span><br><span class="line">WARN: Bytecode of dependencies was not provided for analysis of source files, you might end up with less precise results. Bytecode can be provided using sonar.java.libraries property.</span><br><span class="line">INFO: JavaClasspath initialization (done) | time=8ms</span><br><span class="line">INFO: JavaTestClasspath initialization</span><br><span class="line">INFO: JavaTestClasspath initialization (done) | time=0ms</span><br><span class="line">INFO: Java Main Files AST scan</span><br><span class="line">INFO: 2 source files to be analyzed</span><br><span class="line">INFO: 2/2 source files have been analyzed</span><br><span class="line">INFO: Java Main Files AST scan (done) | time=609ms</span><br><span class="line">INFO: Java Test Files AST scan</span><br><span class="line">INFO: 0 source files to be analyzed</span><br><span class="line">INFO: Java Test Files AST scan (done) | time=1ms</span><br><span class="line">INFO: Sensor JavaSquidSensor [java] (done) | time=1334ms</span><br><span class="line">INFO: Sensor SurefireSensor [java]</span><br><span class="line">INFO: 0/0 source files have been analyzed</span><br><span class="line">INFO: parsing [/var/jenkins_home/workspace/sonar-qube-coding/target/surefire-reports]</span><br><span class="line">INFO: Sensor SurefireSensor [java] (done) | time=55ms</span><br><span class="line">INFO: Sensor JaCoCoSensor [java]</span><br><span class="line">INFO: Sensor JaCoCoSensor [java] (done) | time=2ms</span><br><span class="line">INFO: Sensor JavaXmlSensor [java]</span><br><span class="line">INFO: Sensor JavaXmlSensor [java] (done) | time=0ms</span><br><span class="line">INFO: Sensor Zero Coverage Sensor</span><br><span class="line">INFO: Sensor Zero Coverage Sensor (done) | time=8ms</span><br><span class="line">INFO: Sensor Java CPD Block Indexer</span><br><span class="line">INFO: Sensor Java CPD Block Indexer (done) | time=10ms</span><br><span class="line">INFO: SCM Publisher is disabled</span><br><span class="line">INFO: 2 files had no CPD blocks</span><br><span class="line">INFO: Calculating CPD for 0 files</span><br><span class="line">INFO: CPD calculation finished</span><br><span class="line">INFO: Analysis report generated in 114ms, dir size=13 KB</span><br><span class="line">INFO: Analysis reports compressed in 39ms, zip size=6 KB</span><br><span class="line">INFO: Analysis report uploaded in 671ms</span><br><span class="line">INFO: ANALYSIS SUCCESSFUL, you can browse http://10.2.5.143:9000/dashboard?id=springboot-helloworld%3A0.0.1</span><br><span class="line">INFO: Note that you will be able to access the updated dashboard once the server has processed the submitted analysis report</span><br><span class="line">INFO: More about the report processing at http://10.2.5.143:9000/api/ce/task?id=AWqdwF0moB4s4osu4wHu</span><br><span class="line">INFO: Task total time: 3.412 s</span><br><span class="line">INFO: ------------------------------------------------------------------------</span><br><span class="line">INFO: EXECUTION SUCCESS</span><br><span class="line">INFO: ------------------------------------------------------------------------</span><br><span class="line">INFO: Total time: 4.469s</span><br><span class="line">INFO: Final Memory: 10M/158M</span><br><span class="line">INFO: ------------------------------------------------------------------------</span><br><span class="line">......</span><br><span class="line">Finished: SUCCESS</span><br></pre></td></tr></table></figure><p></p><p>八、SonarQube 查看代码扫描结果</p><p>登录 SonarQube 平台，查看代码扫描结果<br><img src="/Jenkins_SonarQube/jenkins-sona-1015.jpg" alt></p><p>转载地址：<a href="http://www.mydlq.club/article/11/" target="_blank" rel="noopener">http://www.mydlq.club/article/11/</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Tue Jan 14 2020 16:55:04 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;系统环境：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Jenkins 版本：2.176&lt;/li&gt;&lt;li&gt;SonarQube 版本：7.4.0&lt;/li&gt;&lt;/ul&gt;&lt;h1 id=&quot;一、SonarQube-介绍&quot;&gt;&lt;a href=&quot;#一、SonarQube-介绍&quot; class=&quot;headerlink&quot; title=&quot;一、SonarQube 介绍&quot;&gt;&lt;/a&gt;一、SonarQube 介绍&lt;/h1&gt;&lt;h2 id=&quot;1、SonarQube-简介&quot;&gt;&lt;a href=&quot;#1、SonarQube-简介&quot; class=&quot;headerlink&quot; title=&quot;1、SonarQube 简介&quot;&gt;&lt;/a&gt;1、SonarQube 简介&lt;/h2&gt;&lt;p&gt;SonarQube 是一个用于代码质量管理的开源平台，用于管理源代码的质量。同时 SonarQube 还对大量的持续集成工具提供了接口支持，可以很方便地在持续集成中使用 SonarQube。此外， SonarQube 的插件还可以对 Java 以外的其他编程语言提供支持，对国际化以及报告文档化也有良好的支持。&lt;/p&gt;&lt;h2 id=&quot;2、SonarQube工作原理&quot;&gt;&lt;a href=&quot;#2、SonarQube工作原理&quot; class=&quot;headerlink&quot; title=&quot;2、SonarQube工作原理&quot;&gt;&lt;/a&gt;2、SonarQube工作原理&lt;/h2&gt;&lt;p&gt;SonarQube 并不是简单地将各种质量检测工具的结果直接展现给客户，而是通过不同的插件算法来对这些结果进行再加工，最终以量化的方式来衡量代码质量，从而方便地对不同规模和种类的工程进行相应的代码质量管理。&lt;/p&gt;&lt;h2 id=&quot;3、SonarQube-特性&quot;&gt;&lt;a href=&quot;#3、SonarQube-特性&quot; class=&quot;headerlink&quot; title=&quot;3、SonarQube 特性&quot;&gt;&lt;/a&gt;3、SonarQube 特性&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;多语言的平台： 支持超过20种编程语言，包括Java、Python、C#、C/C++、JavaScript等常用语言。
自定义规则： 用户可根据不同项目自定义Quality Profile以及Quality Gates。
丰富的插件： SonarQube 拥有丰富的插件，从而拥有强大的可扩展性。
持续集成： 通过对某项目的持续扫描，可以对该项目的代码质量做长期的把控，并且预防新增代码中的不严谨和冗余。
质量门： 在扫描代码后可以通过对“质量门”的比对判定此次“构建”的结果是否通过，质量门可以由用户定义，由多维度判定是否通过。
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;4、需要注意的代码质量问题&quot;&gt;&lt;a href=&quot;#4、需要注意的代码质量问题&quot; class=&quot;headerlink&quot; title=&quot;4、需要注意的代码质量问题&quot;&gt;&lt;/a&gt;4、需要注意的代码质量问题&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;(1)、不遵循代码标准： SonarQube可以通过PMD,CheckStyle,Findbugs等等代码规则检测工具规 范代码编写。
(2)、糟糕的复杂度分布： 文件、类、方法等，如果复杂度过高将难以改变，这会使得开发人员难以理解它们且如果没有自动化的单元测试，对于程序中的任何组件的改变都将可能导致需要全面的回归测试。
(3)、注释不足或者过多： 没有注释将使代码可读性变差，特别是当不可避免地出现人员变动 时，程序的可读性将大幅下降而过多的注释又会使得开发人员将精力过多地花费在阅读注释上，亦违背初衷。
(4)、缺乏单元测试： SonarQube 可以很方便地统计并展示单元测试覆盖率。
(5)、潜在的缺陷： –SonarQube 可以通过PMD,CheckStyle,Findbugs等等代码规则检测工具检 测出潜在的缺陷。
(6)、重复： 显然程序中包含大量复制粘贴的代码是质量低下的，SonarQube 源码中重复严重的地方。
(7)、糟糕的设计
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Jenkins" scheme="https://yongnights.github.io/categories/Jenkins/"/>
    
      <category term="SonarQube" scheme="https://yongnights.github.io/categories/Jenkins/SonarQube/"/>
    
    
      <category term="Jenkins" scheme="https://yongnights.github.io/tags/Jenkins/"/>
    
      <category term="SonarQube" scheme="https://yongnights.github.io/tags/SonarQube/"/>
    
  </entry>
  
  <entry>
    <title>Linux yum安装PostgreSQL9.6</title>
    <link href="https://yongnights.github.io/2020/01/13/Linux%20yum%E5%AE%89%E8%A3%85PostgreSQL9.6/"/>
    <id>https://yongnights.github.io/2020/01/13/Linux yum安装PostgreSQL9.6/</id>
    <published>2020-01-13T06:49:57.590Z</published>
    <updated>2020-01-13T06:50:29.540Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Jan 13 2020 14:59:26 GMT+0800 (GMT+08:00) --><p>PostgreSQL10版本的主从安装配置在 <a href="https://www.cnblogs.com/virtulreal/p/11675841.html" target="_blank" rel="noopener">https://www.cnblogs.com/virtulreal/p/11675841.html</a></p><h2 id="一、下载安装"><a href="#一、下载安装" class="headerlink" title="一、下载安装"></a>一、下载安装</h2><h3 id="1、创建PostgreSQL9-6的yum源文件"><a href="#1、创建PostgreSQL9-6的yum源文件" class="headerlink" title="1、创建PostgreSQL9.6的yum源文件"></a>1、创建PostgreSQL9.6的yum源文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm</span><br></pre></td></tr></table></figure><h3 id="2、安装PostgreSQL客户端"><a href="#2、安装PostgreSQL客户端" class="headerlink" title="2、安装PostgreSQL客户端"></a>2、安装PostgreSQL客户端</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install postgresql96</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="3、安装PostgreSQL服务端"><a href="#3、安装PostgreSQL服务端" class="headerlink" title="3、安装PostgreSQL服务端"></a>3、安装PostgreSQL服务端</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install postgresql96-server</span><br></pre></td></tr></table></figure><h3 id="4、安装PostgreSQL拓展包-可选"><a href="#4、安装PostgreSQL拓展包-可选" class="headerlink" title="4、安装PostgreSQL拓展包(可选)"></a>4、安装PostgreSQL拓展包(可选)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install postgresql96-devel.x86_64</span><br></pre></td></tr></table></figure><h3 id="5、安装PostgreSQL的附加模块（可选）"><a href="#5、安装PostgreSQL的附加模块（可选）" class="headerlink" title="5、安装PostgreSQL的附加模块（可选）"></a>5、安装PostgreSQL的附加模块（可选）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install postgresql96-contrib.x86_64</span><br></pre></td></tr></table></figure><h2 id="二、配置初始化"><a href="#二、配置初始化" class="headerlink" title="二、配置初始化"></a>二、配置初始化</h2><h3 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/pgsql-9.6/bin/postgresql96-setup initdb</span><br></pre></td></tr></table></figure><h3 id="启动postgresql服务，并设置为开机自动启动"><a href="#启动postgresql服务，并设置为开机自动启动" class="headerlink" title="启动postgresql服务，并设置为开机自动启动"></a>启动postgresql服务，并设置为开机自动启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl enable postgresql-9.6</span><br><span class="line">$ systemctl start postgresql-9.6</span><br></pre></td></tr></table></figure><h2 id="postgres用户初始配置"><a href="#postgres用户初始配置" class="headerlink" title="postgres用户初始配置"></a>postgres用户初始配置</h2><h3 id="安装完成后，操作系统会自动创建一个postgres用户用来管理数据库，为其初始化密码-输入命令后连输2次密码-："><a href="#安装完成后，操作系统会自动创建一个postgres用户用来管理数据库，为其初始化密码-输入命令后连输2次密码-：" class="headerlink" title="安装完成后，操作系统会自动创建一个postgres用户用来管理数据库，为其初始化密码(输入命令后连输2次密码)："></a>安装完成后，操作系统会自动创建一个postgres用户用来管理数据库，为其初始化密码(输入命令后连输2次密码)：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ passwd postgres</span><br></pre></td></tr></table></figure><h2 id="数据库初始配置"><a href="#数据库初始配置" class="headerlink" title="数据库初始配置"></a>数据库初始配置</h2><h3 id="使用数据库自带的postgres用户登录数据库-并为其赋予密码"><a href="#使用数据库自带的postgres用户登录数据库-并为其赋予密码" class="headerlink" title="使用数据库自带的postgres用户登录数据库,并为其赋予密码"></a>使用数据库自带的postgres用户登录数据库,并为其赋予密码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ su - postgres</span><br><span class="line">$ psql -U postgres</span><br><span class="line">alter user postgres with password &apos;你的密码&apos;;</span><br></pre></td></tr></table></figure><h2 id="配置远程连接"><a href="#配置远程连接" class="headerlink" title="配置远程连接"></a>配置远程连接</h2><blockquote><p>可能在/var/lib/pgsql/9.6/data下，可以</p></blockquote><h3 id="1、使用find-name-‘pg-hba-conf’查找到pg-hba-conf，修改pg-hba-conf"><a href="#1、使用find-name-‘pg-hba-conf’查找到pg-hba-conf，修改pg-hba-conf" class="headerlink" title="1、使用find / -name ‘pg_hba.conf’查找到pg_hba.conf，修改pg_hba.conf"></a>1、使用find / -name ‘pg_hba.conf’查找到pg_hba.conf，修改pg_hba.conf</h3><blockquote><p>在最后添加允许访问IP段（全网段可访问）<br>host all all 0.0.0.0/0 md5</p></blockquote><h3 id="2、使用find-name-‘postgresql-conf’找到-postgresql-conf"><a href="#2、使用find-name-‘postgresql-conf’找到-postgresql-conf" class="headerlink" title="2、使用find / -name ‘postgresql.conf’找到 postgresql.conf"></a>2、使用find / -name ‘postgresql.conf’找到 postgresql.conf</h3><blockquote><p>找到用户参数listen_address(取消掉注释),改成下面样式:</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">listen_address = &apos;*&apos;</span><br></pre></td></tr></table></figure><blockquote><p>启用密码验证</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#password_encryption = on 修改为 password_encryption = on</span><br></pre></td></tr></table></figure><h3 id="3、重启数据库"><a href="#3、重启数据库" class="headerlink" title="3、重启数据库"></a>3、重启数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl restart postgresql-9.6</span><br></pre></td></tr></table></figure><blockquote><p>备注:使用Navicat For PostgreSql来连接</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Jan 13 2020 14:59:26 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;PostgreSQL10版本的主从安装配置在 &lt;a href=&quot;https://www.cnblogs.com/virtulreal/p/11675841.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.cnblogs.com/virtulreal/p/11675841.html&lt;/a&gt;&lt;/p&gt;&lt;h2 id=&quot;一、下载安装&quot;&gt;&lt;a href=&quot;#一、下载安装&quot; class=&quot;headerlink&quot; title=&quot;一、下载安装&quot;&gt;&lt;/a&gt;一、下载安装&lt;/h2&gt;&lt;h3 id=&quot;1、创建PostgreSQL9-6的yum源文件&quot;&gt;&lt;a href=&quot;#1、创建PostgreSQL9-6的yum源文件&quot; class=&quot;headerlink&quot; title=&quot;1、创建PostgreSQL9.6的yum源文件&quot;&gt;&lt;/a&gt;1、创建PostgreSQL9.6的yum源文件&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ yum install https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 id=&quot;2、安装PostgreSQL客户端&quot;&gt;&lt;a href=&quot;#2、安装PostgreSQL客户端&quot; class=&quot;headerlink&quot; title=&quot;2、安装PostgreSQL客户端&quot;&gt;&lt;/a&gt;2、安装PostgreSQL客户端&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ yum install postgresql96&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="PostgreSQL" scheme="https://yongnights.github.io/categories/PostgreSQL/"/>
    
    
      <category term="PostgreSQL" scheme="https://yongnights.github.io/tags/PostgreSQL/"/>
    
  </entry>
  
  <entry>
    <title>配置 Nginx 反向代理 WebSocket</title>
    <link href="https://yongnights.github.io/2020/01/13/%E9%85%8D%E7%BD%AE%20Nginx%20%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%20WebSocket/"/>
    <id>https://yongnights.github.io/2020/01/13/配置 Nginx 反向代理 WebSocket/</id>
    <published>2020-01-13T06:46:58.717Z</published>
    <updated>2020-01-13T06:47:34.484Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Jan 13 2020 14:59:26 GMT+0800 (GMT+08:00) --><p>用Nginx给网站做反向代理和负载均衡是广泛使用的一种Web服务器部署技术。不仅能够保证后端服务器的隐蔽性，还可以提高网站部署灵活性。</p><p>今天我们来讲一下，如何用Nginx给WebSocket服务器实现反向代理和负载均衡。</p><h3 id="什么是反向代理和负载均衡"><a href="#什么是反向代理和负载均衡" class="headerlink" title="什么是反向代理和负载均衡"></a>什么是反向代理和负载均衡</h3><ul><li>反向代理(Reverse Proxy)方式是指以代理服务器来接受Internet上的连接请求，然后将请求转发给内部网络上的服务器。并将内部服务器上得到的结果返回给Internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。</li><li>负载均衡(Load Balancing)建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。</li></ul><a id="more"></a><h3 id="什么是WebSocket"><a href="#什么是WebSocket" class="headerlink" title="什么是WebSocket"></a>什么是WebSocket</h3><p>WebSocket协议相比较于HTTP协议成功握手后可以多次进行通讯，直到连接被关闭。但是WebSocket中的握手和HTTP中的握手兼容，它使用HTTP中的Upgrade协议头将连接从HTTP升级到WebSocket。这使得WebSocket程序可以更容易的使用现已存在的基础设施。</p><p>WebSocket工作在HTTP的80和443端口并使用前缀<code>ws://</code>或者<code>wss://</code>进行协议标注，在建立连接时使用HTTP/1.1的101状态码进行协议切换，当前标准不支持两个客户端之间不借助HTTP直接建立Websocket连接。</p><p>更多Websocket的介绍可参考「<a href="http://t.cn/RaT8tNb" target="_blank" rel="noopener">WebSocket教程</a>」一文。</p><h3 id="创建基于Node的WebSocket服务"><a href="#创建基于Node的WebSocket服务" class="headerlink" title="创建基于Node的WebSocket服务"></a>创建基于Node的WebSocket服务</h3><p>Nginx在官方博客上给出了一个实践样例「<a href="https://www.nginx.com/blog/websocket-nginx/" target="_blank" rel="noopener">Using Nginx as a Websocket Proxy</a>」，我们以这个例子来演示WebSocket的交互过程。</p><p>这个例子中将会使用到nodejs的一个WebSocket的ws模块。</p><h4 id="安装node-js和npm"><a href="#安装node-js和npm" class="headerlink" title="安装node.js和npm"></a>安装node.js和npm</h4><ul><li>Debian/Ubuntu</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install nodejs npm</span><br></pre></td></tr></table></figure><ul><li>RHEL/CentOS</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install nodejs npm</span><br></pre></td></tr></table></figure><h4 id="创建nodejs软链"><a href="#创建nodejs软链" class="headerlink" title="创建nodejs软链"></a>创建nodejs软链</h4><p>在Ubuntu上创建一个名叫node软链。Centos默认为node，不用在单独创建了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 如果不创建，后面运行wscat时Ubuntu环境中会报错。</span><br><span class="line">$ ln -s /usr/bin/nodejs /usr/bin/node</span><br></pre></td></tr></table></figure><h4 id="安装ws和wscat模块"><a href="#安装ws和wscat模块" class="headerlink" title="安装ws和wscat模块"></a>安装ws和wscat模块</h4><p><code>ws</code>是nodejs的WebSocket实现，我们借助它来搭建简单的WebSocket Echo Server。<code>wscat</code>是一个可执行的WebSocket客户端，用来调试WebSocket服务是否正常。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install ws wscat</span><br></pre></td></tr></table></figure><p>如果访问官方仓库比较慢的话，可用淘宝提供的镜像服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm --registry=https://registry.npm.taobao.org install ws wscat</span><br></pre></td></tr></table></figure><h4 id="创建一个简单的服务端"><a href="#创建一个简单的服务端" class="headerlink" title="创建一个简单的服务端"></a>创建一个简单的服务端</h4><p>这个简单的服务端实现的是向客户端返回客户端发送的消息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ vim server.js</span><br><span class="line"></span><br><span class="line">console.log(&quot;Server started&quot;);</span><br><span class="line">var Msg = &apos;&apos;;</span><br><span class="line">var WebSocketServer = require(&apos;ws&apos;).Server</span><br><span class="line">    , wss = new WebSocketServer(&#123;port: 8010&#125;);</span><br><span class="line">    wss.on(&apos;connection&apos;, function(ws) &#123;</span><br><span class="line">        ws.on(&apos;message&apos;, function(message) &#123;</span><br><span class="line">        console.log(&apos;Received from client: %s&apos;, message);</span><br><span class="line">        ws.send(&apos;Server received from client: &apos; + message);</span><br><span class="line">    &#125;);</span><br><span class="line"> &#125;);</span><br></pre></td></tr></table></figure><p>运行这个简单的<code>echo</code>服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ node server.js</span><br><span class="line">Server started</span><br></pre></td></tr></table></figure><p>验证服务端是否正常启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ netstat  -tlunp|grep 8010</span><br><span class="line">tcp6       0      0 :::8010                 :::*                    LISTEN      23864/nodejs</span><br></pre></td></tr></table></figure><h4 id="使用wscat做为客户端测试"><a href="#使用wscat做为客户端测试" class="headerlink" title="使用wscat做为客户端测试"></a>使用wscat做为客户端测试</h4><p><code>wscat</code>命令默认安装当前用户目录<code>node_modules/wscat/</code>目录，我这里的位置是<code>/root/node_modules/wscat/bin/wscat</code>。</p><p>输入任意内容进行测试，得到相同返回则说明运行正常。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cd /root/node_modules/wscat/bin/</span><br><span class="line">$ ./wscat --connect ws://127.0.0.1:8010</span><br><span class="line"></span><br><span class="line">connected (press CTRL+C to quit)</span><br><span class="line">&gt; Hello</span><br><span class="line">&lt; Server received from client: Hello</span><br><span class="line"></span><br><span class="line">&gt; Welcome to www.hi-linux.com</span><br><span class="line">&lt; Server received from client: Welcome to www.hi-linux.com</span><br></pre></td></tr></table></figure><h3 id="使用Nginx对WebSocket进行反向代理"><a href="#使用Nginx对WebSocket进行反向代理" class="headerlink" title="使用Nginx对WebSocket进行反向代理"></a>使用Nginx对WebSocket进行反向代理</h3><h4 id="安装Nginx"><a href="#安装Nginx" class="headerlink" title="安装Nginx"></a>安装Nginx</h4><ul><li>下载对应软件包</li></ul><p>Nginx从1.3.13版本就开始支持WebSocket了，并且可以为WebSocket应用程序做反向代理和负载均衡。这里Nginx选用1.9.2版本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd /root</span><br><span class="line">$ wget &apos;http://nginx.org/download/nginx-1.9.2.tar.gz&apos;</span><br></pre></td></tr></table></figure><ul><li>编译安装Nginx</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install libreadline-dev libncurses5-dev libpcre3-dev libssl-dev perl make build-essential</span><br><span class="line">$ tar xzvf nginx-1.9.2.tar.gz</span><br><span class="line">$ cd nginx-1.9.2</span><br><span class="line">$ ./configure</span><br><span class="line">$ make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h4 id="配置Nginx"><a href="#配置Nginx" class="headerlink" title="配置Nginx"></a>配置Nginx</h4><ul><li>修改Nginx主配置文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">$ vim /usr/local/nginx/conf/nginx.conf</span><br><span class="line"></span><br><span class="line"># 在http上下文中增加如下配置，确保Nginx能处理正常http请求。</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line"></span><br><span class="line">  map $http_upgrade $connection_upgrade &#123;</span><br><span class="line">    default upgrade;</span><br><span class="line">    &apos;&apos;   close;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  upstream websocket &#123;</span><br><span class="line">    #ip_hash;</span><br><span class="line">    server localhost:8010;  </span><br><span class="line">    server localhost:8011;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"># 以下配置是在server上下文中添加，location指用于websocket连接的path。</span><br><span class="line"></span><br><span class="line">  server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name localhost;</span><br><span class="line">    access_log /var/log/nginx/yourdomain.log;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">      proxy_pass http://websocket;</span><br><span class="line">      proxy_read_timeout 300s;</span><br><span class="line"></span><br><span class="line">      proxy_set_header Host $host;</span><br><span class="line">      proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line"></span><br><span class="line">      proxy_http_version 1.1;</span><br><span class="line">      proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">      proxy_set_header Connection $connection_upgrade;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最重要的就是在反向代理的配置中增加了如下两行，其它的部分和普通的HTTP反向代理没有任何差别。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">proxy_set_header Connection $connection_upgrade;</span><br></pre></td></tr></table></figure><p>这里面的关键部分在于HTTP的请求中多了如下头部：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Upgrade: websocket</span><br><span class="line">Connection: Upgrade</span><br></pre></td></tr></table></figure><p>这两个字段表示请求服务器升级协议为WebSocket。服务器处理完请求后，响应如下报文：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 状态码为101</span><br><span class="line">HTTP/1.1 101 Switching Protocols</span><br><span class="line">Upgrade: websocket</span><br><span class="line">Connection: upgrade</span><br></pre></td></tr></table></figure><p>告诉客户端已成功切换协议，升级为Websocket协议。握手成功之后，服务器端和客户端便角色对等，就像普通的Socket一样，能够双向通信。不再进行HTTP的交互，而是开始WebSocket的数据帧协议实现数据交换。</p><p>这里使用<code>map</code>指令可以将变量组合成为新的变量，会根据客户端传来的连接中是否带有Upgrade头来决定是否给源站传递Connection头，这样做的方法比直接全部传递upgrade更加优雅。</p><p>默认情况下，连接将会在无数据传输60秒后关闭，<code>proxy_read_timeout</code>参数可以延长这个时间或者源站通过定期发送ping帧以保持连接并确认连接是否还在使用。</p><ul><li>启动Nginx</li></ul><p>Nginx会默认安装到<code>/usr/local/nginx</code>目录下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd /usr/local/nginx/sbin</span><br><span class="line">$ ./nginx -c /usr/local/nginx/conf/nginx.conf</span><br></pre></td></tr></table></figure><p>如果你想以Systemd服务的方式更方便的管理Nginx，可参考「<a href="https://www.hi-linux.com/posts/1084.html" target="_blank" rel="noopener">基于Upsync模块实现Nginx动态配置</a>」 一文。</p><ul><li>测试通过Nginx访问WebSocket服务</li></ul><p>上面的配置会使NGINX监听80端口，并把接收到的任何请求传递给后端的WebSocket服务器。我们可以使用<code>wscat</code>作为客户端来测试一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cd /root/node_modules/wscat/bin/</span><br><span class="line">$ ./wscat --connect ws://192.168.2.210</span><br><span class="line">connected (press CTRL+C to quit)</span><br><span class="line">&gt; Hello Nginx</span><br><span class="line">&lt; Server received from client: Hello Nginx</span><br><span class="line">&gt; Welcome to www.hi-linux.com</span><br><span class="line">&lt; Server received from client: Welcome to www.hi-linux.com</span><br></pre></td></tr></table></figure><ul><li>反向代理服务器在支持WebSocket时面临的挑战</li></ul><p>WebSocket是端对端的，所以当一个代理服务器从客户端拦截一个Upgrade请求，它需要去发送它自己的Upgrade请求到后端服务器，也包括合适的头。</p><p>因为WebSocket是一个长连接，不像HTTP那样是典型的短连接，所以反向代理服务器需要允许连接保持着打开，而不是在它们看起来空闲时就将它们关闭。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Jan 13 2020 14:59:26 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;用Nginx给网站做反向代理和负载均衡是广泛使用的一种Web服务器部署技术。不仅能够保证后端服务器的隐蔽性，还可以提高网站部署灵活性。&lt;/p&gt;&lt;p&gt;今天我们来讲一下，如何用Nginx给WebSocket服务器实现反向代理和负载均衡。&lt;/p&gt;&lt;h3 id=&quot;什么是反向代理和负载均衡&quot;&gt;&lt;a href=&quot;#什么是反向代理和负载均衡&quot; class=&quot;headerlink&quot; title=&quot;什么是反向代理和负载均衡&quot;&gt;&lt;/a&gt;什么是反向代理和负载均衡&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;反向代理(Reverse Proxy)方式是指以代理服务器来接受Internet上的连接请求，然后将请求转发给内部网络上的服务器。并将内部服务器上得到的结果返回给Internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。&lt;/li&gt;&lt;li&gt;负载均衡(Load Balancing)建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="Nginx" scheme="https://yongnights.github.io/categories/Nginx/"/>
    
      <category term="WebSocket" scheme="https://yongnights.github.io/categories/Nginx/WebSocket/"/>
    
    
      <category term="Nginx" scheme="https://yongnights.github.io/tags/Nginx/"/>
    
      <category term="WebSocket" scheme="https://yongnights.github.io/tags/WebSocket/"/>
    
  </entry>
  
  <entry>
    <title>harbor helm仓库使用</title>
    <link href="https://yongnights.github.io/2020/01/13/harbor%20helm%E4%BB%93%E5%BA%93%E4%BD%BF%E7%94%A8/"/>
    <id>https://yongnights.github.io/2020/01/13/harbor helm仓库使用/</id>
    <published>2020-01-13T06:41:13.429Z</published>
    <updated>2020-01-13T06:41:56.756Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Jan 13 2020 14:59:26 GMT+0800 (GMT+08:00) --><p>harbor helm仓库使用</p><p>官方文档地址：<a href="https://github.com/goharbor/harbor" target="_blank" rel="noopener">https://github.com/goharbor/harbor</a></p><p>Monocular 从1.0 开始专注于helm 的UI展示，对于部署以及维护已经去掉了，官方也提供了相关的说明以及推荐了几个可选的部署工具，从使用以及架构上来说kubeapps 就是Monocular + helm 操作的集合，比Monocular早期版本有好多提升</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><ul><li>下载离线安装包<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/goharbor/harbor/releases/download/v1.9.3/harbor-offline-installer-v1.9.3.tgz</span><br></pre></td></tr></table></figure></li></ul><a id="more"></a><ul><li>配置harbor</li></ul><blockquote><p>主要是harbor.cfg文件<br>目前主要配置hostname和port ,使用自己服务器的ip，修改默认端口号<br></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hostname: 192.168.75.100</span><br><span class="line">http:</span><br><span class="line">  <span class="comment"># port for http, default is 80. If https enabled, this port will redirect to https port</span></span><br><span class="line">  port: 10000</span><br></pre></td></tr></table></figure><p></p></blockquote><ul><li><p>生成docker-compose file</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先安装docker-compose，地址：https://github.com/docker/compose/releases</span></span><br><span class="line"><span class="comment"># 需要docker-compose(1.18.0+)版本</span></span><br><span class="line">curl -L https://github.com/docker/compose/releases/download/1.25.0/docker-compose-`uname -s`-`uname -m` -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看docker-compose版本</span></span><br><span class="line">[root@ks-allinone harbor]<span class="comment"># docker-compose version</span></span><br><span class="line">docker-compose version 1.25.0, build 0a186604</span><br><span class="line">docker-py version: 4.1.0</span><br><span class="line">CPython version: 3.7.4</span><br><span class="line">OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019</span><br><span class="line"></span><br><span class="line">./install.sh   --with-clair --with-chartmuseum</span><br></pre></td></tr></table></figure></li><li><p>使用<br>地址：<a href="http://192.168.75.100:10000" target="_blank" rel="noopener">http://192.168.75.100:10000</a><br>账号：admin<br>默认密码：Harbor12345</p></li><li><p>其他操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装helm</span></span><br><span class="line">curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装push 插件</span></span><br><span class="line">helm init </span><br><span class="line">helm plugin install https://github.com/chartmuseum/helm-push</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看安装的插件</span></span><br><span class="line">helm plugin list</span><br><span class="line">NAME    VERSION DESCRIPTION                      </span><br><span class="line">push    0.7.1   Push chart package to ChartMuseum</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加harbor helm 私服</span></span><br><span class="line"><span class="comment"># 首先需要创建项目myrepo(当前设计的模式为public)</span></span><br><span class="line"><span class="comment"># chartrepo是必备的,不可缺少，不然就会推送到默认的library上面去了</span></span><br><span class="line"></span><br><span class="line">helm repo add --username=admin --password=Harbor12345 myrepo http://192.168.75.100:10000/chartrepo/myrepo</span><br><span class="line"><span class="string">"myrepo"</span> has been added to your repositories</span><br><span class="line"></span><br><span class="line"><span class="comment"># or 添加特定仓库</span></span><br><span class="line">helm repo add --username=admin --password=Harbor12345 myrepo https://xx.xx.xx.xx/chartrepo/myproject</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建demo</span></span><br><span class="line">helm create app</span><br><span class="line"></span><br><span class="line">Creating app</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推送到harbor,push</span></span><br><span class="line">helm push --username=admin --password=Harbor12345 app myrepo</span><br><span class="line">Pushing app-0.1.0.tgz to myrepo...</span><br><span class="line">Done.</span><br></pre></td></tr></table></figure></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Jan 13 2020 14:59:26 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;harbor helm仓库使用&lt;/p&gt;&lt;p&gt;官方文档地址：&lt;a href=&quot;https://github.com/goharbor/harbor&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/goharbor/harbor&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Monocular 从1.0 开始专注于helm 的UI展示，对于部署以及维护已经去掉了，官方也提供了相关的说明以及推荐了几个可选的部署工具，从使用以及架构上来说kubeapps 就是Monocular + helm 操作的集合，比Monocular早期版本有好多提升&lt;/p&gt;&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;下载离线安装包&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget https://github.com/goharbor/harbor/releases/download/v1.9.3/harbor-offline-installer-v1.9.3.tgz&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="Harbor" scheme="https://yongnights.github.io/categories/Harbor/"/>
    
      <category term="Helm" scheme="https://yongnights.github.io/categories/Harbor/Helm/"/>
    
    
      <category term="Harbor" scheme="https://yongnights.github.io/tags/Harbor/"/>
    
      <category term="Helm" scheme="https://yongnights.github.io/tags/Helm/"/>
    
  </entry>
  
  <entry>
    <title>Dockfile文件解析</title>
    <link href="https://yongnights.github.io/2020/01/13/Dockfile%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90/"/>
    <id>https://yongnights.github.io/2020/01/13/Dockfile文件解析/</id>
    <published>2020-01-13T06:32:51.240Z</published>
    <updated>2020-01-13T06:33:34.412Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Jan 13 2020 14:59:26 GMT+0800 (GMT+08:00) --><h1 id="1-Dockerfile内容基础知识"><a href="#1-Dockerfile内容基础知识" class="headerlink" title="1. Dockerfile内容基础知识"></a>1. Dockerfile内容基础知识</h1><ul><li>每条保留字指令都必须为大写字母且后面要跟随至少一个参数</li><li>指令按照从上到下，顺序执行</li><li>#表示注释</li><li>每条指令都会创建一个新的镜像层，并对镜像进行提交</li></ul><h1 id="2-Docker执行Dockerfile的大致流程"><a href="#2-Docker执行Dockerfile的大致流程" class="headerlink" title="2. Docker执行Dockerfile的大致流程"></a>2. Docker执行Dockerfile的大致流程</h1><ul><li>docker从基础镜像运行一个容器</li><li>执行一条指令并对容器作出修改</li><li>执行类似docker commit的操作提交一个新的镜像层</li><li>docker再基于刚提交的镜像运行一个新容器</li><li>执行dockerfile中的下一条指令直到所有指令都执行完成</li></ul><a id="more"></a><h1 id="3-DockerFile体系结构-保留字指令"><a href="#3-DockerFile体系结构-保留字指令" class="headerlink" title="3. DockerFile体系结构(保留字指令)"></a>3. DockerFile体系结构(保留字指令)</h1><ul><li>FROM：基础镜像，当前新镜像是基于哪个镜像的</li><li>MAINTAINER：镜像维护者的姓名和邮箱地址</li><li>RUN：容器构建时需要运行的命令</li><li>EXPOSE：当前容器对外暴露出的端口</li><li>WORKDIR：指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点</li><li>ENV：用来在构建镜像过程中设置环境变量 (ENV MY_PATH /usr/mytest)</li><li>ADD：将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar压缩包</li><li>COPY：类似ADD，拷贝文件和目录到镜像中。将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置 (COPY src dest)(COPY [“src”, “dest”])</li><li>VOLUME：容器数据卷，用于数据保存和持久化工作</li><li>CMD：指定一个容器启动时要运行的命令。可以有多个 CMD 指令，但只有最后一个生效，CMD 会被 docker run 之后的参数替换</li><li>ENTRYPOINT：指定一个容器启动时要运行的命令，ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数</li><li>ONBUILD：当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的onbuild被触发</li></ul><h1 id="4-示例内容"><a href="#4-示例内容" class="headerlink" title="4. 示例内容"></a>4. 示例内容</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">FROM         centos</span><br><span class="line">MAINTAINER    zzyy&lt;zzyybs@126.com&gt;</span><br><span class="line">#把宿主机当前上下文的c.txt拷贝到容器/usr/local/路径下</span><br><span class="line">COPY c.txt /usr/local/cincontainer.txt</span><br><span class="line">#把java与tomcat添加到容器中</span><br><span class="line">ADD jdk-8u171-linux-x64.tar.gz /usr/local/</span><br><span class="line">ADD apache-tomcat-9.0.8.tar.gz /usr/local/</span><br><span class="line">#安装vim编辑器</span><br><span class="line">RUN yum -y install vim</span><br><span class="line">#设置工作访问时候的WORKDIR路径，登录落脚点</span><br><span class="line">ENV MYPATH /usr/local</span><br><span class="line">WORKDIR $MYPATH</span><br><span class="line">#配置java与tomcat环境变量</span><br><span class="line">ENV JAVA_HOME /usr/local/jdk1.8.0_171</span><br><span class="line">ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">ENV CATALINA_HOME /usr/local/apache-tomcat-9.0.8</span><br><span class="line">ENV CATALINA_BASE /usr/local/apache-tomcat-9.0.8</span><br><span class="line">ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin</span><br><span class="line">#容器运行时监听的端口</span><br><span class="line">EXPOSE  8080</span><br><span class="line">#启动时运行tomcat</span><br><span class="line"># ENTRYPOINT [&quot;/usr/local/apache-tomcat-9.0.8/bin/startup.sh&quot; ]</span><br><span class="line"># CMD [&quot;/usr/local/apache-tomcat-9.0.8/bin/catalina.sh&quot;,&quot;run&quot;]</span><br><span class="line">CMD /usr/local/apache-tomcat-9.0.8/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-9.0.8/bin/logs/catalina.out</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Jan 13 2020 14:59:26 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;1-Dockerfile内容基础知识&quot;&gt;&lt;a href=&quot;#1-Dockerfile内容基础知识&quot; class=&quot;headerlink&quot; title=&quot;1. Dockerfile内容基础知识&quot;&gt;&lt;/a&gt;1. Dockerfile内容基础知识&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;每条保留字指令都必须为大写字母且后面要跟随至少一个参数&lt;/li&gt;&lt;li&gt;指令按照从上到下，顺序执行&lt;/li&gt;&lt;li&gt;#表示注释&lt;/li&gt;&lt;li&gt;每条指令都会创建一个新的镜像层，并对镜像进行提交&lt;/li&gt;&lt;/ul&gt;&lt;h1 id=&quot;2-Docker执行Dockerfile的大致流程&quot;&gt;&lt;a href=&quot;#2-Docker执行Dockerfile的大致流程&quot; class=&quot;headerlink&quot; title=&quot;2. Docker执行Dockerfile的大致流程&quot;&gt;&lt;/a&gt;2. Docker执行Dockerfile的大致流程&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;docker从基础镜像运行一个容器&lt;/li&gt;&lt;li&gt;执行一条指令并对容器作出修改&lt;/li&gt;&lt;li&gt;执行类似docker commit的操作提交一个新的镜像层&lt;/li&gt;&lt;li&gt;docker再基于刚提交的镜像运行一个新容器&lt;/li&gt;&lt;li&gt;执行dockerfile中的下一条指令直到所有指令都执行完成&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
      <category term="Docker" scheme="https://yongnights.github.io/categories/Docker/"/>
    
    
      <category term="Docker" scheme="https://yongnights.github.io/tags/Docker/"/>
    
  </entry>
  
</feed>
